{"cells":[{"cell_type":"markdown","metadata":{"id":"hSJCDeRPn89q"},"source":["# 0.&nbsp;들어가며"]},{"cell_type":"markdown","metadata":{"id":"RaQ73w479qdq"},"source":["## 0-1. 사전안내\n","- 텍스트 셀에 써있는 지침 반드시 잘 읽고 따르기\n","- 코드 셀의 주석 부분은 궁금하면 참고로 읽어보기"]},{"cell_type":"markdown","metadata":{"id":"sca6VgTzoGDO"},"source":["## 0-2. 데이터 준비\n","- roboflow에서 아래와 같은 형식으로 데이터를 다운받아 드라이브에 옮기기  \n","  - 훈련 데이터: Other - Tensorflow TFRecord\n","  - 테스트 데이터: XML - Pascar VOC"]},{"cell_type":"markdown","metadata":{"id":"LiK39Hce2EVV"},"source":["# 1.&nbsp;환경 설정 및 라이브러리 설치"]},{"cell_type":"markdown","metadata":{"id":"WigsNWfZ8LgF"},"source":["## 1-1. TensorFlow Object Detection API 설치"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22416,"status":"ok","timestamp":1733207234580,"user":{"displayName":"정현우","userId":"03215566591887948765"},"user_tz":-540},"id":"FSVgcMELyd15","outputId":"afa1ffbf-978a-426d-a007-5bbf9a0e1b17"},"outputs":[{"output_type":"stream","name":"stdout","text":["Found existing installation: Cython 3.0.11\n","Uninstalling Cython-3.0.11:\n","  Successfully uninstalled Cython-3.0.11\n","Cloning into 'models'...\n","remote: Enumerating objects: 4305, done.\u001b[K\n","remote: Counting objects: 100% (4305/4305), done.\u001b[K\n","remote: Compressing objects: 100% (3320/3320), done.\u001b[K\n","remote: Total 4305 (delta 1210), reused 2166 (delta 912), pack-reused 0 (from 0)\u001b[K\n","Receiving objects: 100% (4305/4305), 53.16 MiB | 10.00 MiB/s, done.\n","Resolving deltas: 100% (1210/1210), done.\n"]}],"source":["# TensorFlow 모델 레포지토리를 GitHub에서 클론\n","# (TensorFlow Object Detection API 설치를 위해 필요)\n","!pip uninstall Cython -y  # \"No module named 'object_detection'\" 오류를 임시로 해결하기 위해 Cython을 제거\n","!git clone --depth 1 https://github.com/tensorflow/models  # TensorFlow 모델 소스 코드를 가져옴 (최신 커밋만 클론)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gxTHk6MzyiW_"},"outputs":[],"source":["# 모델 설정 파일을 models/research 폴더로 복사 및 프로토콜 버퍼 파일 컴파일\n","\n","# Bash 셸 명령어 실행\n","%%bash\n","cd models/research/\n","\n","# Object Detection API에서 사용하는 .proto 파일을 컴파일하여 Python 코드로 변환\n","protoc object_detection/protos/*.proto --python_out=."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"p_2k5LHr2Lgb"},"outputs":[],"source":["# setup.py 파일 수정: TensorFlow 모델 레포지토리를 TF v2.8.0에 맞춰 설치\n","import re  # 정규 표현식을 사용하기 위한 모듈\n","\n","# 기존 setup.py 파일의 내용을 읽어옴\n","with open('/content/models/research/object_detection/packages/tf2/setup.py') as f:\n","    s = f.read()  # setup.py 파일 내용을 문자열로 읽기\n","\n","# 수정된 내용을 새로운 setup.py 파일에 작성\n","with open('/content/models/research/setup.py', 'w') as f:\n","    # \"tf-models-official>=2.5.1\" 문자열을 \"tf-models-official==2.8.0\"으로 변경\n","    # TensorFlow 버전 호환성을 위해 특정 버전으로 고정\n","    s = re.sub('tf-models-official>=2.5.1', 'tf-models-official==2.8.0', s)\n","    f.write(s)  # 수정된 내용을 새로운 setup.py 파일에 저장\n"]},{"cell_type":"markdown","metadata":{"id":"OZ8NFihJ2RGT"},"source":["- 아래 셀 실행 시 발생하는 **의존성 오류는 무시**\n","  \n","- 중간에 '**세션 다시 시작**' 팝업이 뜰 경우  \n","세션 다시 시작 클릭 -> 아래 셀을 한 번 더 실행"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":270090,"status":"ok","timestamp":1733207752546,"user":{"displayName":"정현우","userId":"03215566591887948765"},"user_tz":-540},"id":"4xbF16Rv2N9o","outputId":"87127901-5d26-435b-f06e-88a1246f3121"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: pyyaml==5.3 in /usr/local/lib/python3.10/dist-packages (5.3)\n","Processing ./models/research\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: avro-python3 in /usr/local/lib/python3.10/dist-packages (from object_detection==0.1) (1.10.2)\n","Requirement already satisfied: apache-beam in /usr/local/lib/python3.10/dist-packages (from object_detection==0.1) (2.61.0)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from object_detection==0.1) (11.0.0)\n","Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from object_detection==0.1) (5.3.0)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from object_detection==0.1) (3.8.0)\n","Requirement already satisfied: Cython in /usr/local/lib/python3.10/dist-packages (from object_detection==0.1) (3.0.11)\n","Requirement already satisfied: contextlib2 in /usr/local/lib/python3.10/dist-packages (from object_detection==0.1) (21.6.0)\n","Requirement already satisfied: tf-slim in /usr/local/lib/python3.10/dist-packages (from object_detection==0.1) (1.1.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from object_detection==0.1) (1.16.0)\n","Requirement already satisfied: pycocotools in /usr/local/lib/python3.10/dist-packages (from object_detection==0.1) (2.0.8)\n","Requirement already satisfied: lvis in /usr/local/lib/python3.10/dist-packages (from object_detection==0.1) (0.5.3)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from object_detection==0.1) (1.13.1)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from object_detection==0.1) (2.2.2)\n","Requirement already satisfied: tf-models-official==2.8.0 in /usr/local/lib/python3.10/dist-packages (from object_detection==0.1) (2.8.0)\n","Requirement already satisfied: tensorflow_io in /usr/local/lib/python3.10/dist-packages (from object_detection==0.1) (0.23.1)\n","Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (from object_detection==0.1) (2.8.0)\n","Requirement already satisfied: pyparsing==2.4.7 in /usr/local/lib/python3.10/dist-packages (from object_detection==0.1) (2.4.7)\n","Requirement already satisfied: sacrebleu<=2.2.0 in /usr/local/lib/python3.10/dist-packages (from object_detection==0.1) (2.2.0)\n","Requirement already satisfied: gin-config in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.8.0->object_detection==0.1) (0.5.0)\n","Requirement already satisfied: google-api-python-client>=1.6.7 in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.8.0->object_detection==0.1) (2.151.0)\n","Requirement already satisfied: kaggle>=1.3.9 in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.8.0->object_detection==0.1) (1.6.17)\n","Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.8.0->object_detection==0.1) (1.26.4)\n","Requirement already satisfied: oauth2client in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.8.0->object_detection==0.1) (4.1.3)\n","Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.8.0->object_detection==0.1) (4.10.0.84)\n","Requirement already satisfied: psutil>=5.4.3 in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.8.0->object_detection==0.1) (5.9.5)\n","Requirement already satisfied: py-cpuinfo>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.8.0->object_detection==0.1) (9.0.0)\n","Requirement already satisfied: pyyaml<6.0,>=5.1 in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.8.0->object_detection==0.1) (5.3)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.8.0->object_detection==0.1) (0.2.0)\n","Requirement already satisfied: seqeval in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.8.0->object_detection==0.1) (1.2.2)\n","Requirement already satisfied: tensorflow-addons in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.8.0->object_detection==0.1) (0.23.0)\n","Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.8.0->object_detection==0.1) (4.9.7)\n","Requirement already satisfied: tensorflow-hub>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.8.0->object_detection==0.1) (0.16.1)\n","Requirement already satisfied: tensorflow-model-optimization>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.8.0->object_detection==0.1) (0.8.0)\n","Requirement already satisfied: tensorflow-text~=2.8.0 in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.8.0->object_detection==0.1) (2.8.2)\n","Requirement already satisfied: tensorflow~=2.8.0 in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.8.0->object_detection==0.1) (2.8.1)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->object_detection==0.1) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->object_detection==0.1) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->object_detection==0.1) (2024.2)\n","Requirement already satisfied: portalocker in /usr/local/lib/python3.10/dist-packages (from sacrebleu<=2.2.0->object_detection==0.1) (3.0.0)\n","Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacrebleu<=2.2.0->object_detection==0.1) (2024.9.11)\n","Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu<=2.2.0->object_detection==0.1) (0.9.0)\n","Requirement already satisfied: colorama in /usr/local/lib/python3.10/dist-packages (from sacrebleu<=2.2.0->object_detection==0.1) (0.4.6)\n","Requirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from tf-slim->object_detection==0.1) (1.4.0)\n","Requirement already satisfied: crcmod<2.0,>=1.7 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object_detection==0.1) (1.7)\n","Requirement already satisfied: orjson<4,>=3.9.7 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object_detection==0.1) (3.10.11)\n","Requirement already satisfied: dill<0.3.2,>=0.3.1.1 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object_detection==0.1) (0.3.1.1)\n","Requirement already satisfied: cloudpickle~=2.2.1 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object_detection==0.1) (2.2.1)\n","Requirement already satisfied: fastavro<2,>=0.23.6 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object_detection==0.1) (1.9.7)\n","Requirement already satisfied: fasteners<1.0,>=0.3 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object_detection==0.1) (0.19)\n","Requirement already satisfied: grpcio!=1.48.0,!=1.59.*,!=1.60.*,!=1.61.*,!=1.62.0,!=1.62.1,<1.66.0,<2,>=1.33.1 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object_detection==0.1) (1.65.5)\n","Requirement already satisfied: hdfs<3.0.0,>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object_detection==0.1) (2.7.3)\n","Requirement already satisfied: httplib2<0.23.0,>=0.8 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object_detection==0.1) (0.22.0)\n","Requirement already satisfied: jsonschema<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object_detection==0.1) (4.23.0)\n","Requirement already satisfied: jsonpickle<4.0.0,>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object_detection==0.1) (3.4.2)\n","Requirement already satisfied: objsize<0.8.0,>=0.6.1 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object_detection==0.1) (0.7.0)\n","Requirement already satisfied: packaging>=22.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object_detection==0.1) (24.2)\n","Requirement already satisfied: pymongo<5.0.0,>=3.8.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object_detection==0.1) (4.10.1)\n","Requirement already satisfied: proto-plus<2,>=1.7.1 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object_detection==0.1) (1.25.0)\n","Requirement already satisfied: protobuf!=4.0.*,!=4.21.*,!=4.22.0,!=4.23.*,!=4.24.*,<6.0.0.dev0,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object_detection==0.1) (4.25.5)\n","Requirement already satisfied: pydot<2,>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object_detection==0.1) (1.4.2)\n","Requirement already satisfied: redis<6,>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object_detection==0.1) (5.2.0)\n","Requirement already satisfied: requests<3.0.0,>=2.24.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object_detection==0.1) (2.32.3)\n","Requirement already satisfied: sortedcontainers>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object_detection==0.1) (2.4.0)\n","Requirement already satisfied: typing-extensions>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object_detection==0.1) (4.12.2)\n","Requirement already satisfied: zstandard<1,>=0.18.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object_detection==0.1) (0.23.0)\n","Requirement already satisfied: pyarrow<17.0.0,>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object_detection==0.1) (16.1.0)\n","Requirement already satisfied: pyarrow-hotfix<1 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object_detection==0.1) (0.6)\n","Requirement already satisfied: cycler>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from lvis->object_detection==0.1) (0.12.1)\n","Requirement already satisfied: kiwisolver>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from lvis->object_detection==0.1) (1.4.7)\n","Requirement already satisfied: opencv-python>=4.1.0.25 in /usr/local/lib/python3.10/dist-packages (from lvis->object_detection==0.1) (4.10.0.84)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->object_detection==0.1) (1.3.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->object_detection==0.1) (4.55.0)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem==0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow_io->object_detection==0.1) (0.23.1)\n","Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.6.7->tf-models-official==2.8.0->object_detection==0.1) (2.27.0)\n","Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.6.7->tf-models-official==2.8.0->object_detection==0.1) (0.2.0)\n","Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.6.7->tf-models-official==2.8.0->object_detection==0.1) (2.19.2)\n","Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.6.7->tf-models-official==2.8.0->object_detection==0.1) (4.1.1)\n","Requirement already satisfied: docopt in /usr/local/lib/python3.10/dist-packages (from hdfs<3.0.0,>=2.1.0->apache-beam->object_detection==0.1) (0.6.2)\n","Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam->object_detection==0.1) (24.2.0)\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam->object_detection==0.1) (2024.10.1)\n","Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam->object_detection==0.1) (0.35.1)\n","Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam->object_detection==0.1) (0.21.0)\n","Requirement already satisfied: certifi>=2023.7.22 in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official==2.8.0->object_detection==0.1) (2024.8.30)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official==2.8.0->object_detection==0.1) (4.66.6)\n","Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official==2.8.0->object_detection==0.1) (8.0.4)\n","Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official==2.8.0->object_detection==0.1) (2.2.3)\n","Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official==2.8.0->object_detection==0.1) (6.2.0)\n","Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from pymongo<5.0.0,>=3.8.0->apache-beam->object_detection==0.1) (2.7.0)\n","Requirement already satisfied: async-timeout>=4.0.3 in /usr/local/lib/python3.10/dist-packages (from redis<6,>=5.0.0->apache-beam->object_detection==0.1) (4.0.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam->object_detection==0.1) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam->object_detection==0.1) (3.10)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.8.0->tf-models-official==2.8.0->object_detection==0.1) (1.6.3)\n","Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.8.0->tf-models-official==2.8.0->object_detection==0.1) (24.3.25)\n","Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.8.0->tf-models-official==2.8.0->object_detection==0.1) (0.6.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.8.0->tf-models-official==2.8.0->object_detection==0.1) (0.2.0)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.8.0->tf-models-official==2.8.0->object_detection==0.1) (3.12.1)\n","Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.8.0->tf-models-official==2.8.0->object_detection==0.1) (1.1.2)\n","Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.8.0->tf-models-official==2.8.0->object_detection==0.1) (18.1.1)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.8.0->tf-models-official==2.8.0->object_detection==0.1) (3.4.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.8.0->tf-models-official==2.8.0->object_detection==0.1) (75.1.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.8.0->tf-models-official==2.8.0->object_detection==0.1) (2.5.0)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.8.0->tf-models-official==2.8.0->object_detection==0.1) (1.16.0)\n","Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.8.0->tf-models-official==2.8.0->object_detection==0.1) (2.8.0)\n","Requirement already satisfied: tensorflow-estimator<2.9,>=2.8 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.8.0->tf-models-official==2.8.0->object_detection==0.1) (2.8.0)\n","Requirement already satisfied: tf-keras>=2.14.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow-hub>=0.6.0->tf-models-official==2.8.0->object_detection==0.1) (2.15.0)\n","Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow-model-optimization>=0.4.1->tf-models-official==2.8.0->object_detection==0.1) (0.1.8)\n","Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.10/dist-packages (from oauth2client->tf-models-official==2.8.0->object_detection==0.1) (0.6.1)\n","Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.10/dist-packages (from oauth2client->tf-models-official==2.8.0->object_detection==0.1) (0.4.1)\n","Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from oauth2client->tf-models-official==2.8.0->object_detection==0.1) (4.9)\n","Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.10/dist-packages (from seqeval->tf-models-official==2.8.0->object_detection==0.1) (1.5.2)\n","Requirement already satisfied: typeguard<3.0.0,>=2.7 in /usr/local/lib/python3.10/dist-packages (from tensorflow-addons->tf-models-official==2.8.0->object_detection==0.1) (2.13.3)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official==2.8.0->object_detection==0.1) (8.1.7)\n","Requirement already satisfied: immutabledict in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official==2.8.0->object_detection==0.1) (4.2.1)\n","Requirement already satisfied: promise in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official==2.8.0->object_detection==0.1) (2.3)\n","Requirement already satisfied: simple-parsing in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official==2.8.0->object_detection==0.1) (0.1.6)\n","Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official==2.8.0->object_detection==0.1) (1.13.1)\n","Requirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official==2.8.0->object_detection==0.1) (0.10.2)\n","Requirement already satisfied: array-record>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official==2.8.0->object_detection==0.1) (0.5.1)\n","Requirement already satisfied: etils>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.6.0; python_version < \"3.11\"->tensorflow-datasets->tf-models-official==2.8.0->object_detection==0.1) (1.10.0)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow~=2.8.0->tf-models-official==2.8.0->object_detection==0.1) (0.45.0)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.6.0; python_version < \"3.11\"->tensorflow-datasets->tf-models-official==2.8.0->object_detection==0.1) (2024.10.0)\n","Requirement already satisfied: importlib_resources in /usr/local/lib/python3.10/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.6.0; python_version < \"3.11\"->tensorflow-datasets->tf-models-official==2.8.0->object_detection==0.1) (6.4.5)\n","Requirement already satisfied: zipp in /usr/local/lib/python3.10/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.6.0; python_version < \"3.11\"->tensorflow-datasets->tf-models-official==2.8.0->object_detection==0.1) (3.21.0)\n","Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client>=1.6.7->tf-models-official==2.8.0->object_detection==0.1) (1.66.0)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client>=1.6.7->tf-models-official==2.8.0->object_detection==0.1) (5.5.0)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official==2.8.0->object_detection==0.1) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official==2.8.0->object_detection==0.1) (3.5.0)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official==2.8.0->object_detection==0.1) (0.4.6)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official==2.8.0->object_detection==0.1) (3.7)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official==2.8.0->object_detection==0.1) (0.6.1)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official==2.8.0->object_detection==0.1) (1.8.1)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official==2.8.0->object_detection==0.1) (3.1.3)\n","Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle>=1.3.9->tf-models-official==2.8.0->object_detection==0.1) (0.5.1)\n","Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle>=1.3.9->tf-models-official==2.8.0->object_detection==0.1) (1.3)\n","Requirement already satisfied: docstring-parser<1.0,>=0.15 in /usr/local/lib/python3.10/dist-packages (from simple-parsing->tensorflow-datasets->tf-models-official==2.8.0->object_detection==0.1) (0.16)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official==2.8.0->object_detection==0.1) (1.3.1)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=0.11.15->tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official==2.8.0->object_detection==0.1) (3.0.2)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official==2.8.0->object_detection==0.1) (3.2.2)\n","Building wheels for collected packages: object_detection\n","  Building wheel for object_detection (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for object_detection: filename=object_detection-0.1-py3-none-any.whl size=1697355 sha256=56758a3ab9a068ca4bc542d2eb172e77e9e8c1ffadce54639ed63ff7257e3ea8\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-_aphb2ug/wheels/53/dd/70/2de274d6c443c69d367bd6a5606f95e5a6df61aacf1435ec0d\n","Successfully built object_detection\n","Installing collected packages: object_detection\n","  Attempting uninstall: object_detection\n","    Found existing installation: object_detection 0.1\n","    Uninstalling object_detection-0.1:\n","      Successfully uninstalled object_detection-0.1\n","Successfully installed object_detection-0.1\n","Collecting tensorflow==2.8.0\n","  Using cached tensorflow-2.8.0-cp310-cp310-manylinux2010_x86_64.whl.metadata (2.9 kB)\n","Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (1.6.3)\n","Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (24.3.25)\n","Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (0.6.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (0.2.0)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (3.12.1)\n","Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (1.1.2)\n","Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (18.1.1)\n","Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (1.26.4)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (3.4.0)\n","Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (4.25.5)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (75.1.0)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (1.16.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (2.5.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (4.12.2)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (1.16.0)\n","Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (2.8.0)\n","Collecting tf-estimator-nightly==2.8.0.dev2021122109 (from tensorflow==2.8.0)\n","  Using cached tf_estimator_nightly-2.8.0.dev2021122109-py2.py3-none-any.whl.metadata (1.2 kB)\n","Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (2.8.0)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (0.23.1)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (1.65.5)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow==2.8.0) (0.45.0)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.0) (2.27.0)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.0) (0.4.6)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.0) (3.7)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.0) (2.32.3)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.0) (0.6.1)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.0) (1.8.1)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.0) (3.1.3)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (5.5.0)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (0.4.1)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (1.3.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (2024.8.30)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=0.11.15->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (3.0.2)\n","Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (0.6.1)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (3.2.2)\n","Downloading tensorflow-2.8.0-cp310-cp310-manylinux2010_x86_64.whl (497.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m497.6/497.6 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tf_estimator_nightly-2.8.0.dev2021122109-py2.py3-none-any.whl (462 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m462.5/462.5 kB\u001b[0m \u001b[31m33.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: tf-estimator-nightly, tensorflow\n","  Attempting uninstall: tensorflow\n","    Found existing installation: tensorflow 2.8.1\n","    Uninstalling tensorflow-2.8.1:\n","      Successfully uninstalled tensorflow-2.8.1\n","Successfully installed tensorflow-2.8.0 tf-estimator-nightly-2.8.0.dev2021122109\n","Requirement already satisfied: tensorflow_io==0.23.1 in /usr/local/lib/python3.10/dist-packages (0.23.1)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem==0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow_io==0.23.1) (0.23.1)\n","--2024-12-03 06:32:08--  https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/cuda-ubuntu1804.pin\n","Resolving developer.download.nvidia.com (developer.download.nvidia.com)... 152.195.19.142\n","Connecting to developer.download.nvidia.com (developer.download.nvidia.com)|152.195.19.142|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 190 [application/octet-stream]\n","Saving to: ‘cuda-ubuntu1804.pin’\n","\n","cuda-ubuntu1804.pin 100%[===================>]     190  --.-KB/s    in 0s      \n","\n","2024-12-03 06:32:08 (5.49 MB/s) - ‘cuda-ubuntu1804.pin’ saved [190/190]\n","\n","--2024-12-03 06:32:08--  http://developer.download.nvidia.com/compute/cuda/11.0.2/local_installers/cuda-repo-ubuntu1804-11-0-local_11.0.2-450.51.05-1_amd64.deb\n","Resolving developer.download.nvidia.com (developer.download.nvidia.com)... 152.195.19.142\n","Connecting to developer.download.nvidia.com (developer.download.nvidia.com)|152.195.19.142|:80... connected.\n","HTTP request sent, awaiting response... 301 Moved Permanently\n","Location: https://developer.download.nvidia.com/compute/cuda/11.0.2/local_installers/cuda-repo-ubuntu1804-11-0-local_11.0.2-450.51.05-1_amd64.deb [following]\n","--2024-12-03 06:32:08--  https://developer.download.nvidia.com/compute/cuda/11.0.2/local_installers/cuda-repo-ubuntu1804-11-0-local_11.0.2-450.51.05-1_amd64.deb\n","Connecting to developer.download.nvidia.com (developer.download.nvidia.com)|152.195.19.142|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 2273753684 (2.1G) [application/x-deb]\n","Saving to: ‘cuda-repo-ubuntu1804-11-0-local_11.0.2-450.51.05-1_amd64.deb’\n","\n","cuda-repo-ubuntu180 100%[===================>]   2.12G   229MB/s    in 17s     \n","\n","2024-12-03 06:32:25 (131 MB/s) - ‘cuda-repo-ubuntu1804-11-0-local_11.0.2-450.51.05-1_amd64.deb’ saved [2273753684/2273753684]\n","\n","Selecting previously unselected package cuda-repo-ubuntu1804-11-0-local.\n","(Reading database ... 123630 files and directories currently installed.)\n","Preparing to unpack cuda-repo-ubuntu1804-11-0-local_11.0.2-450.51.05-1_amd64.deb ...\n","Unpacking cuda-repo-ubuntu1804-11-0-local (11.0.2-450.51.05-1) ...\n","Setting up cuda-repo-ubuntu1804-11-0-local (11.0.2-450.51.05-1) ...\n","\n","The public CUDA GPG key does not appear to be installed.\n","To install the key, run this command:\n","sudo apt-key add /var/cuda-repo-ubuntu1804-11-0-local/7fa2af80.pub\n","\n","Warning: apt-key is deprecated. Manage keyring files in trusted.gpg.d instead (see apt-key(8)).\n","OK\n","Get:1 file:/var/cuda-repo-ubuntu1804-11-0-local  InRelease\n","Ign:1 file:/var/cuda-repo-ubuntu1804-11-0-local  InRelease\n","Get:2 file:/var/cuda-repo-ubuntu1804-11-0-local  Release [564 B]\n","Get:2 file:/var/cuda-repo-ubuntu1804-11-0-local  Release [564 B]\n","Get:3 file:/var/cuda-repo-ubuntu1804-11-0-local  Release.gpg [836 B]\n","Get:3 file:/var/cuda-repo-ubuntu1804-11-0-local  Release.gpg [836 B]\n","Get:4 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n","Get:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n","Get:6 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n","Hit:7 http://archive.ubuntu.com/ubuntu jammy InRelease\n","Get:8 file:/var/cuda-repo-ubuntu1804-11-0-local  Packages [23.9 kB]\n","Get:9 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n","Get:10 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n","Get:11 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [1,185 kB]\n","Get:12 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n","Hit:13 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n","Get:14 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,619 kB]\n","Hit:15 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n","Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,513 kB]\n","Hit:17 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n","Get:18 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [2,738 kB]\n","Get:19 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,224 kB]\n","Get:20 http://archive.ubuntu.com/ubuntu jammy-backports/universe amd64 Packages [33.8 kB]\n","Get:21 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,514 kB]\n","Get:22 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,454 kB]\n","Fetched 20.7 MB in 2s (8,563 kB/s)\n","Reading package lists... Done\n","W: file:/var/cuda-repo-ubuntu1804-11-0-local/Release.gpg: Key is stored in legacy trusted.gpg keyring (/etc/apt/trusted.gpg), see the DEPRECATION section in apt-key(8) for details.\n","W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n","Reading package lists... Done\n","Building dependency tree... Done\n","Reading state information... Done\n","The following additional packages will be installed:\n","  cuda-command-line-tools-11-0 cuda-compiler-11-0 cuda-cudart-11-0\n","  cuda-cudart-dev-11-0 cuda-cuobjdump-11-0 cuda-cupti-11-0 cuda-cupti-dev-11-0\n","  cuda-documentation-11-0 cuda-driver-dev-11-0 cuda-gdb-11-0\n","  cuda-libraries-11-0 cuda-libraries-dev-11-0 cuda-memcheck-11-0\n","  cuda-nsight-11-0 cuda-nsight-compute-11-0 cuda-nsight-systems-11-0\n","  cuda-nvcc-11-0 cuda-nvdisasm-11-0 cuda-nvml-dev-11-0 cuda-nvprof-11-0\n","  cuda-nvprune-11-0 cuda-nvrtc-11-0 cuda-nvrtc-dev-11-0 cuda-nvtx-11-0\n","  cuda-nvvp-11-0 cuda-samples-11-0 cuda-sanitizer-11-0 cuda-tools-11-0\n","  cuda-visual-tools-11-0 default-jre default-jre-headless fonts-dejavu-core\n","  fonts-dejavu-extra freeglut3 freeglut3-dev libatk-wrapper-java\n","  libatk-wrapper-java-jni libcublas-11-0 libcublas-dev-11-0 libcufft-11-0\n","  libcufft-dev-11-0 libcurand-11-0 libcurand-dev-11-0 libcusolver-11-0\n","  libcusolver-dev-11-0 libcusparse-11-0 libcusparse-dev-11-0 libegl-dev\n","  libfontenc1 libgl-dev libgl1-mesa-dev libgles-dev libgles1 libglu1-mesa\n","  libglu1-mesa-dev libglvnd-core-dev libglvnd-dev libglx-dev libice-dev\n","  libnpp-11-0 libnpp-dev-11-0 libnvjpeg-11-0 libnvjpeg-dev-11-0 libopengl-dev\n","  libsm-dev libxcb-cursor0 libxcb-icccm4 libxcb-image0 libxcb-keysyms1\n","  libxcb-render-util0 libxcb-util1 libxcb-xinerama0 libxcb-xinput0 libxcb-xkb1\n","  libxfixes-dev libxi-dev libxkbcommon-x11-0 libxkbfile1 libxmu-dev\n","  libxmu-headers libxt-dev libxtst6 libxxf86dga1 nsight-systems-2024.5.1\n","  openjdk-11-jre x11-utils\n","Suggested packages:\n","  libice-doc libsm-doc libxt-doc mesa-utils\n","The following NEW packages will be installed:\n","  cuda-command-line-tools-11-0 cuda-compiler-11-0 cuda-cudart-11-0\n","  cuda-cudart-dev-11-0 cuda-cuobjdump-11-0 cuda-cupti-11-0 cuda-cupti-dev-11-0\n","  cuda-documentation-11-0 cuda-driver-dev-11-0 cuda-gdb-11-0\n","  cuda-libraries-11-0 cuda-libraries-dev-11-0 cuda-memcheck-11-0\n","  cuda-nsight-11-0 cuda-nsight-compute-11-0 cuda-nsight-systems-11-0\n","  cuda-nvcc-11-0 cuda-nvdisasm-11-0 cuda-nvml-dev-11-0 cuda-nvprof-11-0\n","  cuda-nvprune-11-0 cuda-nvrtc-11-0 cuda-nvrtc-dev-11-0 cuda-nvtx-11-0\n","  cuda-nvvp-11-0 cuda-samples-11-0 cuda-sanitizer-11-0 cuda-toolkit-11-0\n","  cuda-tools-11-0 cuda-visual-tools-11-0 default-jre default-jre-headless\n","  fonts-dejavu-core fonts-dejavu-extra freeglut3 freeglut3-dev\n","  libatk-wrapper-java libatk-wrapper-java-jni libcublas-11-0\n","  libcublas-dev-11-0 libcufft-11-0 libcufft-dev-11-0 libcurand-11-0\n","  libcurand-dev-11-0 libcusolver-11-0 libcusolver-dev-11-0 libcusparse-11-0\n","  libcusparse-dev-11-0 libegl-dev libfontenc1 libgl-dev libgl1-mesa-dev\n","  libgles-dev libgles1 libglu1-mesa libglu1-mesa-dev libglvnd-core-dev\n","  libglvnd-dev libglx-dev libice-dev libnpp-11-0 libnpp-dev-11-0\n","  libnvjpeg-11-0 libnvjpeg-dev-11-0 libopengl-dev libsm-dev libxcb-cursor0\n","  libxcb-icccm4 libxcb-image0 libxcb-keysyms1 libxcb-render-util0 libxcb-util1\n","  libxcb-xinerama0 libxcb-xinput0 libxcb-xkb1 libxfixes-dev libxi-dev\n","  libxkbcommon-x11-0 libxkbfile1 libxmu-dev libxmu-headers libxt-dev libxtst6\n","  libxxf86dga1 nsight-systems-2024.5.1 openjdk-11-jre x11-utils\n","0 upgraded, 87 newly installed, 0 to remove and 59 not upgraded.\n","Need to get 361 MB/1,943 MB of archives.\n","After this operation, 4,022 MB of additional disk space will be used.\n","Get:1 file:/var/cuda-repo-ubuntu1804-11-0-local  cuda-cudart-11-0 11.0.194-1 [129 kB]\n","Get:2 file:/var/cuda-repo-ubuntu1804-11-0-local  cuda-driver-dev-11-0 11.0.194-1 [25.0 kB]\n","Get:3 file:/var/cuda-repo-ubuntu1804-11-0-local  cuda-cudart-dev-11-0 11.0.194-1 [1,662 kB]\n","Get:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  nsight-systems-2024.5.1 2024.5.1.113-245134619542v0 [356 MB]\n","Get:5 http://archive.ubuntu.com/ubuntu jammy/universe amd64 freeglut3 amd64 2.8.1-6 [74.0 kB]\n","Get:6 file:/var/cuda-repo-ubuntu1804-11-0-local  cuda-nvcc-11-0 11.0.194-1 [21.1 MB]\n","Get:7 file:/var/cuda-repo-ubuntu1804-11-0-local  cuda-cupti-11-0 11.0.194-1 [10.5 MB]\n","Get:8 http://archive.ubuntu.com/ubuntu jammy/main amd64 libglx-dev amd64 1.4.0-1 [14.1 kB]\n","Get:9 file:/var/cuda-repo-ubuntu1804-11-0-local  cuda-cupti-dev-11-0 11.0.194-1 [2,276 kB]\n","Get:10 http://archive.ubuntu.com/ubuntu jammy/main amd64 libgl-dev amd64 1.4.0-1 [101 kB]\n","Get:11 http://archive.ubuntu.com/ubuntu jammy/main amd64 libglvnd-core-dev amd64 1.4.0-1 [12.7 kB]\n","Get:12 http://archive.ubuntu.com/ubuntu jammy/main amd64 libegl-dev amd64 1.4.0-1 [18.0 kB]\n","Get:13 http://archive.ubuntu.com/ubuntu jammy/main amd64 libgles1 amd64 1.4.0-1 [11.5 kB]\n","Get:14 http://archive.ubuntu.com/ubuntu jammy/main amd64 libgles-dev amd64 1.4.0-1 [49.4 kB]\n","Get:15 http://archive.ubuntu.com/ubuntu jammy/main amd64 libopengl-dev amd64 1.4.0-1 [3,400 B]\n","Get:16 http://archive.ubuntu.com/ubuntu jammy/main amd64 libglvnd-dev amd64 1.4.0-1 [3,162 B]\n","Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgl1-mesa-dev amd64 23.2.1-1ubuntu3.1~22.04.2 [6,842 B]\n","Get:18 http://archive.ubuntu.com/ubuntu jammy/main amd64 libglu1-mesa amd64 9.0.2-1 [145 kB]\n","Get:19 http://archive.ubuntu.com/ubuntu jammy/main amd64 libglu1-mesa-dev amd64 9.0.2-1 [231 kB]\n","Get:20 http://archive.ubuntu.com/ubuntu jammy/main amd64 libice-dev amd64 2:1.0.10-1build2 [51.4 kB]\n","Get:21 http://archive.ubuntu.com/ubuntu jammy/main amd64 libsm-dev amd64 2:1.2.3-1build2 [18.1 kB]\n","Get:22 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxt-dev amd64 1:1.2.1-1 [396 kB]\n","Get:23 http://archive.ubuntu.com/ubuntu jammy/universe amd64 freeglut3-dev amd64 2.8.1-6 [126 kB]\n","Get:24 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxmu-headers all 2:1.1.3-3 [54.1 kB]\n","Get:25 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxmu-dev amd64 2:1.1.3-3 [54.6 kB]\n","Get:26 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxfixes-dev amd64 1:6.0.0-1 [12.2 kB]\n","Get:27 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxi-dev amd64 2:1.8-1build1 [193 kB]\n","Get:28 http://archive.ubuntu.com/ubuntu jammy/main amd64 default-jre-headless amd64 2:1.11-72build2 [3,042 B]\n","Get:29 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxtst6 amd64 2:1.2.3-1build4 [13.4 kB]\n","Get:30 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 openjdk-11-jre amd64 11.0.25+9-1ubuntu1~22.04 [216 kB]\n","Get:31 http://archive.ubuntu.com/ubuntu jammy/main amd64 default-jre amd64 2:1.11-72build2 [896 B]\n","Get:32 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcb-xinerama0 amd64 1.14-3ubuntu3 [5,414 B]\n","Get:33 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcb-icccm4 amd64 0.4.1-1.1build2 [11.5 kB]\n","Get:34 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcb-util1 amd64 0.4.0-1build2 [11.4 kB]\n","Get:35 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcb-image0 amd64 0.4.0-2 [11.5 kB]\n","Get:36 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcb-keysyms1 amd64 0.4.0-1build3 [8,746 B]\n","Get:37 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcb-render-util0 amd64 0.3.9-1build3 [10.3 kB]\n","Get:38 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcb-xkb1 amd64 1.14-3ubuntu3 [32.8 kB]\n","Get:39 file:/var/cuda-repo-ubuntu1804-11-0-local  cuda-nvdisasm-11-0 11.0.194-1 [27.3 MB]\n","Get:40 file:/var/cuda-repo-ubuntu1804-11-0-local  cuda-cuobjdump-11-0 11.0.194-1 [103 kB]\n","Get:41 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxkbcommon-x11-0 amd64 1.4.0-1 [14.4 kB]\n","Get:42 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcb-xinput0 amd64 1.14-3ubuntu3 [34.3 kB]\n","Get:43 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libxcb-cursor0 amd64 0.1.1-4ubuntu1 [10.5 kB]\n","Get:44 file:/var/cuda-repo-ubuntu1804-11-0-local  cuda-gdb-11-0 11.0.194-1 [3,891 kB]\n","Get:45 file:/var/cuda-repo-ubuntu1804-11-0-local  cuda-memcheck-11-0 11.0.194-1 [144 kB]\n","Get:46 file:/var/cuda-repo-ubuntu1804-11-0-local  cuda-nvprof-11-0 11.0.194-1 [1,911 kB]\n","Get:47 file:/var/cuda-repo-ubuntu1804-11-0-local  cuda-nvtx-11-0 11.0.167-1 [51.1 kB]\n","Get:48 http://archive.ubuntu.com/ubuntu jammy/main amd64 fonts-dejavu-core all 2.37-2build1 [1,041 kB]\n","Get:49 http://archive.ubuntu.com/ubuntu jammy/main amd64 fonts-dejavu-extra all 2.37-2build1 [2,041 kB]\n","Get:50 http://archive.ubuntu.com/ubuntu jammy/main amd64 libfontenc1 amd64 1:1.1.4-1build3 [14.7 kB]\n","Get:51 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxkbfile1 amd64 1:1.1.0-1build3 [71.8 kB]\n","Get:52 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxxf86dga1 amd64 2:1.1.5-0ubuntu3 [12.6 kB]\n","Get:53 http://archive.ubuntu.com/ubuntu jammy/main amd64 x11-utils amd64 7.7+5build2 [206 kB]\n","Get:54 http://archive.ubuntu.com/ubuntu jammy/main amd64 libatk-wrapper-java all 0.38.0-5build1 [53.1 kB]\n","Get:55 http://archive.ubuntu.com/ubuntu jammy/main amd64 libatk-wrapper-java-jni amd64 0.38.0-5build1 [49.0 kB]\n","Get:56 file:/var/cuda-repo-ubuntu1804-11-0-local  cuda-sanitizer-11-0 11.0.194-1 [7,220 kB]\n","Get:57 file:/var/cuda-repo-ubuntu1804-11-0-local  cuda-command-line-tools-11-0 11.0.2-1 [2,474 B]\n","Get:58 file:/var/cuda-repo-ubuntu1804-11-0-local  cuda-nvprune-11-0 11.0.167-1 [53.1 kB]\n","Get:59 file:/var/cuda-repo-ubuntu1804-11-0-local  cuda-compiler-11-0 11.0.2-1 [2,416 B]\n","Get:60 file:/var/cuda-repo-ubuntu1804-11-0-local  cuda-nvrtc-11-0 11.0.194-1 [6,521 kB]\n","Get:61 file:/var/cuda-repo-ubuntu1804-11-0-local  cuda-nvrtc-dev-11-0 11.0.194-1 [22.1 kB]\n","Get:62 file:/var/cuda-repo-ubuntu1804-11-0-local  libcusolver-11-0 10.5.0.218-1 [277 MB]\n","Get:63 file:/var/cuda-repo-ubuntu1804-11-0-local  libcusolver-dev-11-0 10.5.0.218-1 [17.6 MB]\n","Get:64 file:/var/cuda-repo-ubuntu1804-11-0-local  libcublas-11-0 11.1.0.229-1 [118 MB]\n","Get:65 file:/var/cuda-repo-ubuntu1804-11-0-local  libcublas-dev-11-0 11.1.0.229-1 [120 MB]\n","Get:66 file:/var/cuda-repo-ubuntu1804-11-0-local  libcufft-11-0 10.2.0.218-1 [94.1 MB]\n","Get:67 file:/var/cuda-repo-ubuntu1804-11-0-local  libcufft-dev-11-0 10.2.0.218-1 [172 MB]\n","Get:68 file:/var/cuda-repo-ubuntu1804-11-0-local  libcurand-11-0 10.2.1.218-1 [39.2 MB]\n","Get:69 file:/var/cuda-repo-ubuntu1804-11-0-local  libcurand-dev-11-0 10.2.1.218-1 [39.2 MB]\n","Get:70 file:/var/cuda-repo-ubuntu1804-11-0-local  libcusparse-11-0 11.1.0.218-1 [71.2 MB]\n","Get:71 file:/var/cuda-repo-ubuntu1804-11-0-local  libcusparse-dev-11-0 11.1.0.218-1 [71.4 MB]\n","Get:72 file:/var/cuda-repo-ubuntu1804-11-0-local  libnpp-11-0 11.1.0.218-1 [56.6 MB]\n","Get:73 file:/var/cuda-repo-ubuntu1804-11-0-local  libnpp-dev-11-0 11.1.0.218-1 [57.4 MB]\n","Get:74 file:/var/cuda-repo-ubuntu1804-11-0-local  libnvjpeg-11-0 11.1.0.218-1 [1,391 kB]\n","Get:75 file:/var/cuda-repo-ubuntu1804-11-0-local  libnvjpeg-dev-11-0 11.1.0.218-1 [1,321 kB]\n","Get:76 file:/var/cuda-repo-ubuntu1804-11-0-local  cuda-samples-11-0 11.0.194-1 [68.1 MB]\n","Get:77 file:/var/cuda-repo-ubuntu1804-11-0-local  cuda-documentation-11-0 11.0.207-1 [59.6 MB]\n","Get:78 file:/var/cuda-repo-ubuntu1804-11-0-local  cuda-libraries-11-0 11.0.2-1 [2,490 B]\n","Get:79 file:/var/cuda-repo-ubuntu1804-11-0-local  cuda-libraries-dev-11-0 11.0.2-1 [2,514 B]\n","Get:80 file:/var/cuda-repo-ubuntu1804-11-0-local  cuda-nsight-11-0 11.0.194-1 [119 MB]\n","Get:81 file:/var/cuda-repo-ubuntu1804-11-0-local  cuda-nsight-compute-11-0 11.0.2-1 [3,718 B]\n","Get:82 file:/var/cuda-repo-ubuntu1804-11-0-local  cuda-nsight-systems-11-0 11.0.2-1 [3,280 B]\n","Get:83 file:/var/cuda-repo-ubuntu1804-11-0-local  cuda-nvml-dev-11-0 11.0.167-1 [71.9 kB]\n","Get:84 file:/var/cuda-repo-ubuntu1804-11-0-local  cuda-nvvp-11-0 11.0.194-1 [115 MB]\n","Get:85 file:/var/cuda-repo-ubuntu1804-11-0-local  cuda-visual-tools-11-0 11.0.2-1 [2,942 B]\n","Get:86 file:/var/cuda-repo-ubuntu1804-11-0-local  cuda-tools-11-0 11.0.2-1 [2,380 B]\n","Get:87 file:/var/cuda-repo-ubuntu1804-11-0-local  cuda-toolkit-11-0 11.0.2-1 [2,728 B]\n","Fetched 361 MB in 16s (22.2 MB/s)\n","debconf: unable to initialize frontend: Dialog\n","debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 87.)\n","debconf: falling back to frontend: Readline\n","debconf: unable to initialize frontend: Readline\n","debconf: (This frontend requires a controlling tty.)\n","debconf: falling back to frontend: Teletype\n","dpkg-preconfigure: unable to re-open stdin: \n","Selecting previously unselected package cuda-cudart-11-0.\n","(Reading database ... 123717 files and directories currently installed.)\n","Preparing to unpack .../00-cuda-cudart-11-0_11.0.194-1_amd64.deb ...\n","Unpacking cuda-cudart-11-0 (11.0.194-1) ...\n","Selecting previously unselected package cuda-driver-dev-11-0.\n","Preparing to unpack .../01-cuda-driver-dev-11-0_11.0.194-1_amd64.deb ...\n","Unpacking cuda-driver-dev-11-0 (11.0.194-1) ...\n","Selecting previously unselected package cuda-cudart-dev-11-0.\n","Preparing to unpack .../02-cuda-cudart-dev-11-0_11.0.194-1_amd64.deb ...\n","Unpacking cuda-cudart-dev-11-0 (11.0.194-1) ...\n","Selecting previously unselected package cuda-nvcc-11-0.\n","Preparing to unpack .../03-cuda-nvcc-11-0_11.0.194-1_amd64.deb ...\n","Unpacking cuda-nvcc-11-0 (11.0.194-1) ...\n","Selecting previously unselected package cuda-cupti-11-0.\n","Preparing to unpack .../04-cuda-cupti-11-0_11.0.194-1_amd64.deb ...\n","Unpacking cuda-cupti-11-0 (11.0.194-1) ...\n","Selecting previously unselected package cuda-cupti-dev-11-0.\n","Preparing to unpack .../05-cuda-cupti-dev-11-0_11.0.194-1_amd64.deb ...\n","Unpacking cuda-cupti-dev-11-0 (11.0.194-1) ...\n","Selecting previously unselected package cuda-nvdisasm-11-0.\n","Preparing to unpack .../06-cuda-nvdisasm-11-0_11.0.194-1_amd64.deb ...\n","Unpacking cuda-nvdisasm-11-0 (11.0.194-1) ...\n","Selecting previously unselected package cuda-cuobjdump-11-0.\n","Preparing to unpack .../07-cuda-cuobjdump-11-0_11.0.194-1_amd64.deb ...\n","Unpacking cuda-cuobjdump-11-0 (11.0.194-1) ...\n","Selecting previously unselected package cuda-gdb-11-0.\n","Preparing to unpack .../08-cuda-gdb-11-0_11.0.194-1_amd64.deb ...\n","Unpacking cuda-gdb-11-0 (11.0.194-1) ...\n","Selecting previously unselected package cuda-memcheck-11-0.\n","Preparing to unpack .../09-cuda-memcheck-11-0_11.0.194-1_amd64.deb ...\n","Unpacking cuda-memcheck-11-0 (11.0.194-1) ...\n","Selecting previously unselected package cuda-nvprof-11-0.\n","Preparing to unpack .../10-cuda-nvprof-11-0_11.0.194-1_amd64.deb ...\n","Unpacking cuda-nvprof-11-0 (11.0.194-1) ...\n","Selecting previously unselected package cuda-nvtx-11-0.\n","Preparing to unpack .../11-cuda-nvtx-11-0_11.0.167-1_amd64.deb ...\n","Unpacking cuda-nvtx-11-0 (11.0.167-1) ...\n","Selecting previously unselected package cuda-sanitizer-11-0.\n","Preparing to unpack .../12-cuda-sanitizer-11-0_11.0.194-1_amd64.deb ...\n","Unpacking cuda-sanitizer-11-0 (11.0.194-1) ...\n","Selecting previously unselected package cuda-command-line-tools-11-0.\n","Preparing to unpack .../13-cuda-command-line-tools-11-0_11.0.2-1_amd64.deb ...\n","Unpacking cuda-command-line-tools-11-0 (11.0.2-1) ...\n","Selecting previously unselected package cuda-nvprune-11-0.\n","Preparing to unpack .../14-cuda-nvprune-11-0_11.0.167-1_amd64.deb ...\n","Unpacking cuda-nvprune-11-0 (11.0.167-1) ...\n","Selecting previously unselected package cuda-compiler-11-0.\n","Preparing to unpack .../15-cuda-compiler-11-0_11.0.2-1_amd64.deb ...\n","Unpacking cuda-compiler-11-0 (11.0.2-1) ...\n","Selecting previously unselected package freeglut3:amd64.\n","Preparing to unpack .../16-freeglut3_2.8.1-6_amd64.deb ...\n","Unpacking freeglut3:amd64 (2.8.1-6) ...\n","Selecting previously unselected package libglx-dev:amd64.\n","Preparing to unpack .../17-libglx-dev_1.4.0-1_amd64.deb ...\n","Unpacking libglx-dev:amd64 (1.4.0-1) ...\n","Selecting previously unselected package libgl-dev:amd64.\n","Preparing to unpack .../18-libgl-dev_1.4.0-1_amd64.deb ...\n","Unpacking libgl-dev:amd64 (1.4.0-1) ...\n","Selecting previously unselected package libglvnd-core-dev:amd64.\n","Preparing to unpack .../19-libglvnd-core-dev_1.4.0-1_amd64.deb ...\n","Unpacking libglvnd-core-dev:amd64 (1.4.0-1) ...\n","Selecting previously unselected package libegl-dev:amd64.\n","Preparing to unpack .../20-libegl-dev_1.4.0-1_amd64.deb ...\n","Unpacking libegl-dev:amd64 (1.4.0-1) ...\n","Selecting previously unselected package libgles1:amd64.\n","Preparing to unpack .../21-libgles1_1.4.0-1_amd64.deb ...\n","Unpacking libgles1:amd64 (1.4.0-1) ...\n","Selecting previously unselected package libgles-dev:amd64.\n","Preparing to unpack .../22-libgles-dev_1.4.0-1_amd64.deb ...\n","Unpacking libgles-dev:amd64 (1.4.0-1) ...\n","Selecting previously unselected package libopengl-dev:amd64.\n","Preparing to unpack .../23-libopengl-dev_1.4.0-1_amd64.deb ...\n","Unpacking libopengl-dev:amd64 (1.4.0-1) ...\n","Selecting previously unselected package libglvnd-dev:amd64.\n","Preparing to unpack .../24-libglvnd-dev_1.4.0-1_amd64.deb ...\n","Unpacking libglvnd-dev:amd64 (1.4.0-1) ...\n","Selecting previously unselected package libgl1-mesa-dev:amd64.\n","Preparing to unpack .../25-libgl1-mesa-dev_23.2.1-1ubuntu3.1~22.04.2_amd64.deb ...\n","Unpacking libgl1-mesa-dev:amd64 (23.2.1-1ubuntu3.1~22.04.2) ...\n","Selecting previously unselected package libglu1-mesa:amd64.\n","Preparing to unpack .../26-libglu1-mesa_9.0.2-1_amd64.deb ...\n","Unpacking libglu1-mesa:amd64 (9.0.2-1) ...\n","Selecting previously unselected package libglu1-mesa-dev:amd64.\n","Preparing to unpack .../27-libglu1-mesa-dev_9.0.2-1_amd64.deb ...\n","Unpacking libglu1-mesa-dev:amd64 (9.0.2-1) ...\n","Selecting previously unselected package libice-dev:amd64.\n","Preparing to unpack .../28-libice-dev_2%3a1.0.10-1build2_amd64.deb ...\n","Unpacking libice-dev:amd64 (2:1.0.10-1build2) ...\n","Selecting previously unselected package libsm-dev:amd64.\n","Preparing to unpack .../29-libsm-dev_2%3a1.2.3-1build2_amd64.deb ...\n","Unpacking libsm-dev:amd64 (2:1.2.3-1build2) ...\n","Selecting previously unselected package libxt-dev:amd64.\n","Preparing to unpack .../30-libxt-dev_1%3a1.2.1-1_amd64.deb ...\n","Unpacking libxt-dev:amd64 (1:1.2.1-1) ...\n","Selecting previously unselected package freeglut3-dev:amd64.\n","Preparing to unpack .../31-freeglut3-dev_2.8.1-6_amd64.deb ...\n","Unpacking freeglut3-dev:amd64 (2.8.1-6) ...\n","Selecting previously unselected package libxmu-headers.\n","Preparing to unpack .../32-libxmu-headers_2%3a1.1.3-3_all.deb ...\n","Unpacking libxmu-headers (2:1.1.3-3) ...\n","Selecting previously unselected package libxmu-dev:amd64.\n","Preparing to unpack .../33-libxmu-dev_2%3a1.1.3-3_amd64.deb ...\n","Unpacking libxmu-dev:amd64 (2:1.1.3-3) ...\n","Selecting previously unselected package libxfixes-dev:amd64.\n","Preparing to unpack .../34-libxfixes-dev_1%3a6.0.0-1_amd64.deb ...\n","Unpacking libxfixes-dev:amd64 (1:6.0.0-1) ...\n","Selecting previously unselected package libxi-dev:amd64.\n","Preparing to unpack .../35-libxi-dev_2%3a1.8-1build1_amd64.deb ...\n","Unpacking libxi-dev:amd64 (2:1.8-1build1) ...\n","Selecting previously unselected package cuda-nvrtc-11-0.\n","Preparing to unpack .../36-cuda-nvrtc-11-0_11.0.194-1_amd64.deb ...\n","Unpacking cuda-nvrtc-11-0 (11.0.194-1) ...\n","Selecting previously unselected package cuda-nvrtc-dev-11-0.\n","Preparing to unpack .../37-cuda-nvrtc-dev-11-0_11.0.194-1_amd64.deb ...\n","Unpacking cuda-nvrtc-dev-11-0 (11.0.194-1) ...\n","Selecting previously unselected package libcusolver-11-0.\n","Preparing to unpack .../38-libcusolver-11-0_10.5.0.218-1_amd64.deb ...\n","Unpacking libcusolver-11-0 (10.5.0.218-1) ...\n","Selecting previously unselected package libcusolver-dev-11-0.\n","Preparing to unpack .../39-libcusolver-dev-11-0_10.5.0.218-1_amd64.deb ...\n","Unpacking libcusolver-dev-11-0 (10.5.0.218-1) ...\n","Selecting previously unselected package libcublas-11-0.\n","Preparing to unpack .../40-libcublas-11-0_11.1.0.229-1_amd64.deb ...\n","Unpacking libcublas-11-0 (11.1.0.229-1) ...\n","Selecting previously unselected package libcublas-dev-11-0.\n","Preparing to unpack .../41-libcublas-dev-11-0_11.1.0.229-1_amd64.deb ...\n","Unpacking libcublas-dev-11-0 (11.1.0.229-1) ...\n","Selecting previously unselected package libcufft-11-0.\n","Preparing to unpack .../42-libcufft-11-0_10.2.0.218-1_amd64.deb ...\n","Unpacking libcufft-11-0 (10.2.0.218-1) ...\n","Selecting previously unselected package libcufft-dev-11-0.\n","Preparing to unpack .../43-libcufft-dev-11-0_10.2.0.218-1_amd64.deb ...\n","Unpacking libcufft-dev-11-0 (10.2.0.218-1) ...\n","Selecting previously unselected package libcurand-11-0.\n","Preparing to unpack .../44-libcurand-11-0_10.2.1.218-1_amd64.deb ...\n","Unpacking libcurand-11-0 (10.2.1.218-1) ...\n","Selecting previously unselected package libcurand-dev-11-0.\n","Preparing to unpack .../45-libcurand-dev-11-0_10.2.1.218-1_amd64.deb ...\n","Unpacking libcurand-dev-11-0 (10.2.1.218-1) ...\n","Selecting previously unselected package libcusparse-11-0.\n","Preparing to unpack .../46-libcusparse-11-0_11.1.0.218-1_amd64.deb ...\n","Unpacking libcusparse-11-0 (11.1.0.218-1) ...\n","Selecting previously unselected package libcusparse-dev-11-0.\n","Preparing to unpack .../47-libcusparse-dev-11-0_11.1.0.218-1_amd64.deb ...\n","Unpacking libcusparse-dev-11-0 (11.1.0.218-1) ...\n","Selecting previously unselected package libnpp-11-0.\n","Preparing to unpack .../48-libnpp-11-0_11.1.0.218-1_amd64.deb ...\n","Unpacking libnpp-11-0 (11.1.0.218-1) ...\n","Selecting previously unselected package libnpp-dev-11-0.\n","Preparing to unpack .../49-libnpp-dev-11-0_11.1.0.218-1_amd64.deb ...\n","Unpacking libnpp-dev-11-0 (11.1.0.218-1) ...\n","Selecting previously unselected package libnvjpeg-11-0.\n","Preparing to unpack .../50-libnvjpeg-11-0_11.1.0.218-1_amd64.deb ...\n","Unpacking libnvjpeg-11-0 (11.1.0.218-1) ...\n","Selecting previously unselected package libnvjpeg-dev-11-0.\n","Preparing to unpack .../51-libnvjpeg-dev-11-0_11.1.0.218-1_amd64.deb ...\n","Unpacking libnvjpeg-dev-11-0 (11.1.0.218-1) ...\n","Selecting previously unselected package cuda-samples-11-0.\n","Preparing to unpack .../52-cuda-samples-11-0_11.0.194-1_amd64.deb ...\n","Unpacking cuda-samples-11-0 (11.0.194-1) ...\n","Selecting previously unselected package cuda-documentation-11-0.\n","Preparing to unpack .../53-cuda-documentation-11-0_11.0.207-1_amd64.deb ...\n","Unpacking cuda-documentation-11-0 (11.0.207-1) ...\n","Selecting previously unselected package cuda-libraries-11-0.\n","Preparing to unpack .../54-cuda-libraries-11-0_11.0.2-1_amd64.deb ...\n","Unpacking cuda-libraries-11-0 (11.0.2-1) ...\n","Selecting previously unselected package cuda-libraries-dev-11-0.\n","Preparing to unpack .../55-cuda-libraries-dev-11-0_11.0.2-1_amd64.deb ...\n","Unpacking cuda-libraries-dev-11-0 (11.0.2-1) ...\n","Selecting previously unselected package default-jre-headless.\n","Preparing to unpack .../56-default-jre-headless_2%3a1.11-72build2_amd64.deb ...\n","Unpacking default-jre-headless (2:1.11-72build2) ...\n","Selecting previously unselected package libxtst6:amd64.\n","Preparing to unpack .../57-libxtst6_2%3a1.2.3-1build4_amd64.deb ...\n","Unpacking libxtst6:amd64 (2:1.2.3-1build4) ...\n","Selecting previously unselected package openjdk-11-jre:amd64.\n","Preparing to unpack .../58-openjdk-11-jre_11.0.25+9-1ubuntu1~22.04_amd64.deb ...\n","Unpacking openjdk-11-jre:amd64 (11.0.25+9-1ubuntu1~22.04) ...\n","Selecting previously unselected package default-jre.\n","Preparing to unpack .../59-default-jre_2%3a1.11-72build2_amd64.deb ...\n","Unpacking default-jre (2:1.11-72build2) ...\n","Selecting previously unselected package cuda-nsight-11-0.\n","Preparing to unpack .../60-cuda-nsight-11-0_11.0.194-1_amd64.deb ...\n","Unpacking cuda-nsight-11-0 (11.0.194-1) ...\n","Selecting previously unselected package cuda-nsight-compute-11-0.\n","Preparing to unpack .../61-cuda-nsight-compute-11-0_11.0.2-1_amd64.deb ...\n","Unpacking cuda-nsight-compute-11-0 (11.0.2-1) ...\n","Selecting previously unselected package libxcb-xinerama0:amd64.\n","Preparing to unpack .../62-libxcb-xinerama0_1.14-3ubuntu3_amd64.deb ...\n","Unpacking libxcb-xinerama0:amd64 (1.14-3ubuntu3) ...\n","Selecting previously unselected package libxcb-icccm4:amd64.\n","Preparing to unpack .../63-libxcb-icccm4_0.4.1-1.1build2_amd64.deb ...\n","Unpacking libxcb-icccm4:amd64 (0.4.1-1.1build2) ...\n","Selecting previously unselected package libxcb-util1:amd64.\n","Preparing to unpack .../64-libxcb-util1_0.4.0-1build2_amd64.deb ...\n","Unpacking libxcb-util1:amd64 (0.4.0-1build2) ...\n","Selecting previously unselected package libxcb-image0:amd64.\n","Preparing to unpack .../65-libxcb-image0_0.4.0-2_amd64.deb ...\n","Unpacking libxcb-image0:amd64 (0.4.0-2) ...\n","Selecting previously unselected package libxcb-keysyms1:amd64.\n","Preparing to unpack .../66-libxcb-keysyms1_0.4.0-1build3_amd64.deb ...\n","Unpacking libxcb-keysyms1:amd64 (0.4.0-1build3) ...\n","Selecting previously unselected package libxcb-render-util0:amd64.\n","Preparing to unpack .../67-libxcb-render-util0_0.3.9-1build3_amd64.deb ...\n","Unpacking libxcb-render-util0:amd64 (0.3.9-1build3) ...\n","Selecting previously unselected package libxcb-xkb1:amd64.\n","Preparing to unpack .../68-libxcb-xkb1_1.14-3ubuntu3_amd64.deb ...\n","Unpacking libxcb-xkb1:amd64 (1.14-3ubuntu3) ...\n","Selecting previously unselected package libxkbcommon-x11-0:amd64.\n","Preparing to unpack .../69-libxkbcommon-x11-0_1.4.0-1_amd64.deb ...\n","Unpacking libxkbcommon-x11-0:amd64 (1.4.0-1) ...\n","Selecting previously unselected package libxcb-xinput0:amd64.\n","Preparing to unpack .../70-libxcb-xinput0_1.14-3ubuntu3_amd64.deb ...\n","Unpacking libxcb-xinput0:amd64 (1.14-3ubuntu3) ...\n","Selecting previously unselected package libxcb-cursor0:amd64.\n","Preparing to unpack .../71-libxcb-cursor0_0.1.1-4ubuntu1_amd64.deb ...\n","Unpacking libxcb-cursor0:amd64 (0.1.1-4ubuntu1) ...\n","Selecting previously unselected package nsight-systems-2024.5.1.\n","Preparing to unpack .../72-nsight-systems-2024.5.1_2024.5.1.113-245134619542v0_amd64.deb ...\n","Unpacking nsight-systems-2024.5.1 (2024.5.1.113-245134619542v0) ...\n","Selecting previously unselected package cuda-nsight-systems-11-0.\n","Preparing to unpack .../73-cuda-nsight-systems-11-0_11.0.2-1_amd64.deb ...\n","Unpacking cuda-nsight-systems-11-0 (11.0.2-1) ...\n","Selecting previously unselected package cuda-nvml-dev-11-0.\n","Preparing to unpack .../74-cuda-nvml-dev-11-0_11.0.167-1_amd64.deb ...\n","Unpacking cuda-nvml-dev-11-0 (11.0.167-1) ...\n","Selecting previously unselected package cuda-nvvp-11-0.\n","Preparing to unpack .../75-cuda-nvvp-11-0_11.0.194-1_amd64.deb ...\n","Unpacking cuda-nvvp-11-0 (11.0.194-1) ...\n","Selecting previously unselected package cuda-visual-tools-11-0.\n","Preparing to unpack .../76-cuda-visual-tools-11-0_11.0.2-1_amd64.deb ...\n","Unpacking cuda-visual-tools-11-0 (11.0.2-1) ...\n","Selecting previously unselected package cuda-tools-11-0.\n","Preparing to unpack .../77-cuda-tools-11-0_11.0.2-1_amd64.deb ...\n","Unpacking cuda-tools-11-0 (11.0.2-1) ...\n","Selecting previously unselected package cuda-toolkit-11-0.\n","Preparing to unpack .../78-cuda-toolkit-11-0_11.0.2-1_amd64.deb ...\n","Unpacking cuda-toolkit-11-0 (11.0.2-1) ...\n","Selecting previously unselected package fonts-dejavu-core.\n","Preparing to unpack .../79-fonts-dejavu-core_2.37-2build1_all.deb ...\n","Unpacking fonts-dejavu-core (2.37-2build1) ...\n","Selecting previously unselected package fonts-dejavu-extra.\n","Preparing to unpack .../80-fonts-dejavu-extra_2.37-2build1_all.deb ...\n","Unpacking fonts-dejavu-extra (2.37-2build1) ...\n","Selecting previously unselected package libfontenc1:amd64.\n","Preparing to unpack .../81-libfontenc1_1%3a1.1.4-1build3_amd64.deb ...\n","Unpacking libfontenc1:amd64 (1:1.1.4-1build3) ...\n","Selecting previously unselected package libxkbfile1:amd64.\n","Preparing to unpack .../82-libxkbfile1_1%3a1.1.0-1build3_amd64.deb ...\n","Unpacking libxkbfile1:amd64 (1:1.1.0-1build3) ...\n","Selecting previously unselected package libxxf86dga1:amd64.\n","Preparing to unpack .../83-libxxf86dga1_2%3a1.1.5-0ubuntu3_amd64.deb ...\n","Unpacking libxxf86dga1:amd64 (2:1.1.5-0ubuntu3) ...\n","Selecting previously unselected package x11-utils.\n","Preparing to unpack .../84-x11-utils_7.7+5build2_amd64.deb ...\n","Unpacking x11-utils (7.7+5build2) ...\n","Selecting previously unselected package libatk-wrapper-java.\n","Preparing to unpack .../85-libatk-wrapper-java_0.38.0-5build1_all.deb ...\n","Unpacking libatk-wrapper-java (0.38.0-5build1) ...\n","Selecting previously unselected package libatk-wrapper-java-jni:amd64.\n","Preparing to unpack .../86-libatk-wrapper-java-jni_0.38.0-5build1_amd64.deb ...\n","Unpacking libatk-wrapper-java-jni:amd64 (0.38.0-5build1) ...\n","Setting up libcurand-11-0 (10.2.1.218-1) ...\n","Setting up libcublas-11-0 (11.1.0.229-1) ...\n","Setting up libxmu-headers (2:1.1.3-3) ...\n","Setting up cuda-nvtx-11-0 (11.0.167-1) ...\n","Setting up freeglut3:amd64 (2.8.1-6) ...\n","Setting up default-jre-headless (2:1.11-72build2) ...\n","Setting up libglvnd-core-dev:amd64 (1.4.0-1) ...\n","Setting up libxcb-xinput0:amd64 (1.14-3ubuntu3) ...\n","Setting up libcusolver-11-0 (10.5.0.218-1) ...\n","Setting up libice-dev:amd64 (2:1.0.10-1build2) ...\n","Setting up cuda-driver-dev-11-0 (11.0.194-1) ...\n","Setting up libsm-dev:amd64 (2:1.2.3-1build2) ...\n","Setting up cuda-nsight-compute-11-0 (11.0.2-1) ...\n","Setting up libxtst6:amd64 (2:1.2.3-1build4) ...\n","Setting up cuda-memcheck-11-0 (11.0.194-1) ...\n","Setting up libxcb-keysyms1:amd64 (0.4.0-1build3) ...\n","Setting up libxxf86dga1:amd64 (2:1.1.5-0ubuntu3) ...\n","Setting up libxcb-render-util0:amd64 (0.3.9-1build3) ...\n","Setting up openjdk-11-jre:amd64 (11.0.25+9-1ubuntu1~22.04) ...\n","Setting up libxcb-icccm4:amd64 (0.4.1-1.1build2) ...\n","Setting up default-jre (2:1.11-72build2) ...\n","Setting up cuda-nvprune-11-0 (11.0.167-1) ...\n","Setting up libnvjpeg-11-0 (11.1.0.218-1) ...\n","Setting up libxcb-util1:amd64 (0.4.0-1build2) ...\n","Setting up cuda-cudart-11-0 (11.0.194-1) ...\n","Setting up libxcb-xkb1:amd64 (1.14-3ubuntu3) ...\n","Setting up libxcb-image0:amd64 (0.4.0-2) ...\n","Setting up libxfixes-dev:amd64 (1:6.0.0-1) ...\n","Setting up cuda-nvprof-11-0 (11.0.194-1) ...\n","Setting up libfontenc1:amd64 (1:1.1.4-1build3) ...\n","Setting up libxcb-xinerama0:amd64 (1.14-3ubuntu3) ...\n","Setting up libxt-dev:amd64 (1:1.2.1-1) ...\n","Setting up cuda-nvml-dev-11-0 (11.0.167-1) ...\n","Setting up libxcb-cursor0:amd64 (0.1.1-4ubuntu1) ...\n","Setting up libgles1:amd64 (1.4.0-1) ...\n","Setting up libcusparse-11-0 (11.1.0.218-1) ...\n","Setting up libxkbcommon-x11-0:amd64 (1.4.0-1) ...\n","Setting up fonts-dejavu-core (2.37-2build1) ...\n","Setting up cuda-cuobjdump-11-0 (11.0.194-1) ...\n","Setting up libcufft-11-0 (10.2.0.218-1) ...\n","Setting up cuda-cudart-dev-11-0 (11.0.194-1) ...\n","Setting up cuda-nvrtc-11-0 (11.0.194-1) ...\n","Setting up cuda-sanitizer-11-0 (11.0.194-1) ...\n","Setting up fonts-dejavu-extra (2.37-2build1) ...\n","Setting up libcufft-dev-11-0 (10.2.0.218-1) ...\n","Setting up libnpp-11-0 (11.1.0.218-1) ...\n","Setting up libcusolver-dev-11-0 (10.5.0.218-1) ...\n","Setting up libglx-dev:amd64 (1.4.0-1) ...\n","Setting up libglu1-mesa:amd64 (9.0.2-1) ...\n","Setting up libxkbfile1:amd64 (1:1.1.0-1build3) ...\n","Setting up cuda-nvdisasm-11-0 (11.0.194-1) ...\n","Setting up libopengl-dev:amd64 (1.4.0-1) ...\n","Setting up libxi-dev:amd64 (2:1.8-1build1) ...\n","Setting up libcublas-dev-11-0 (11.1.0.229-1) ...\n","Setting up libgl-dev:amd64 (1.4.0-1) ...\n","Setting up libcusparse-dev-11-0 (11.1.0.218-1) ...\n","Setting up cuda-nvvp-11-0 (11.0.194-1) ...\n","Setting up libcurand-dev-11-0 (10.2.1.218-1) ...\n","Setting up libnpp-dev-11-0 (11.1.0.218-1) ...\n","Setting up cuda-libraries-11-0 (11.0.2-1) ...\n","Setting up cuda-gdb-11-0 (11.0.194-1) ...\n","Setting up cuda-nvrtc-dev-11-0 (11.0.194-1) ...\n","Setting up nsight-systems-2024.5.1 (2024.5.1.113-245134619542v0) ...\n","update-alternatives: using /opt/nvidia/nsight-systems/2024.5.1/target-linux-x64/nsys to provide /usr/local/bin/nsys (nsys) in auto mode\n","update-alternatives: using /opt/nvidia/nsight-systems/2024.5.1/host-linux-x64/nsys-ui to provide /usr/local/bin/nsys-ui (nsys-ui) in auto mode\n","Setting up libegl-dev:amd64 (1.4.0-1) ...\n","Setting up cuda-nsight-11-0 (11.0.194-1) ...\n","Setting up libnvjpeg-dev-11-0 (11.1.0.218-1) ...\n","Setting up libxmu-dev:amd64 (2:1.1.3-3) ...\n","Setting up cuda-nvcc-11-0 (11.0.194-1) ...\n","Setting up libglu1-mesa-dev:amd64 (9.0.2-1) ...\n","Setting up cuda-libraries-dev-11-0 (11.0.2-1) ...\n","Setting up cuda-cupti-11-0 (11.0.194-1) ...\n","Setting up x11-utils (7.7+5build2) ...\n","Setting up libatk-wrapper-java (0.38.0-5build1) ...\n","Setting up libgles-dev:amd64 (1.4.0-1) ...\n","Setting up cuda-nsight-systems-11-0 (11.0.2-1) ...\n","Setting up cuda-visual-tools-11-0 (11.0.2-1) ...\n","Setting up cuda-compiler-11-0 (11.0.2-1) ...\n","Setting up libglvnd-dev:amd64 (1.4.0-1) ...\n","Setting up libatk-wrapper-java-jni:amd64 (0.38.0-5build1) ...\n","Setting up cuda-cupti-dev-11-0 (11.0.194-1) ...\n","Setting up libgl1-mesa-dev:amd64 (23.2.1-1ubuntu3.1~22.04.2) ...\n","Setting up cuda-command-line-tools-11-0 (11.0.2-1) ...\n","Setting up freeglut3-dev:amd64 (2.8.1-6) ...\n","Setting up cuda-tools-11-0 (11.0.2-1) ...\n","Setting up cuda-samples-11-0 (11.0.194-1) ...\n","Setting up cuda-documentation-11-0 (11.0.207-1) ...\n","Setting up cuda-toolkit-11-0 (11.0.2-1) ...\n","Processing triggers for hicolor-icon-theme (0.17-2) ...\n","Processing triggers for libc-bin (2.35-0ubuntu3.4) ...\n","/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n","\n","Processing triggers for man-db (2.10.2-1) ...\n","Processing triggers for fontconfig (2.13.1-4.2ubuntu5) ...\n"]}],"source":["# Object Detection API 설치 (참고: 이 코드 블록 실행에 약 10분 정도 소요될 수 있음)\n","\n","# PyYAML 라이브러리 관련 문제 해결\n","# Colab 환경에서 PyYAML v5.4.1을 설치할 수 없으므로 PyYAML v5.3 버전을 설치\n","!pip install pyyaml==5.3\n","\n","# Object Detection API를 설치\n","# 연구(research) 폴더에 있는 Python 패키지를 설치하여 사용할 준비\n","!pip install /content/models/research/\n","\n","# TensorFlow 버전을 2.8.0으로 다운그레이드\n","# Colab 환경에서 TensorFlow v2.10과의 호환성 문제(2022년 10월 기준)가 있어 v2.8.0으로 변경\n","!pip install tensorflow==2.8.0\n","\n","# TensorFlow v2.8.0과 호환되는 CUDA v11.0 설치\n","# TensorFlow v2.8.0은 CUDA v11.0과 호환되므로 이를 설치하여 GPU 가속을 지원\n","!pip install tensorflow_io==0.23.1  # TensorFlow와 호환되는 I/O 라이브러리 설치\n","\n","# CUDA v11.0 관련 패키지를 다운로드하고 설치\n","!wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/cuda-ubuntu1804.pin\n","!mv cuda-ubuntu1804.pin /etc/apt/preferences.d/cuda-repository-pin-600\n","\n","# CUDA v11.0 설치 파일을 다운로드\n","!wget http://developer.download.nvidia.com/compute/cuda/11.0.2/local_installers/cuda-repo-ubuntu1804-11-0-local_11.0.2-450.51.05-1_amd64.deb\n","\n","# CUDA 설치 파일을 dpkg 명령어로 설치\n","!dpkg -i cuda-repo-ubuntu1804-11-0-local_11.0.2-450.51.05-1_amd64.deb\n","\n","# CUDA의 공개 키를 추가하여 패키지를 인증\n","!apt-key add /var/cuda-repo-ubuntu1804-11-0-local/7fa2af80.pub\n","\n","# 시스템 패키지 업데이트 및 CUDA 툴킷 v11.0 설치\n","!apt-get update && sudo apt-get install cuda-toolkit-11-0\n","\n","# CUDA 라이브러리 경로를 환경 변수에 추가\n","!export LD_LIBRARY_PATH=/usr/local/cuda-11.0/lib64:$LD_LIBRARY_PATH"]},{"cell_type":"markdown","metadata":{"id":"nv7g8Gyj3f-2"},"source":["- 아래 셀 실행 시 발생하는 오류는 무시"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":643},"executionInfo":{"elapsed":9914,"status":"ok","timestamp":1733207762453,"user":{"displayName":"정현우","userId":"03215566591887948765"},"user_tz":-540},"id":"753tBoqh3b9e","outputId":"65105e53-c99a-4ef2-d61b-38dcb2a3ee90"},"outputs":[{"output_type":"stream","name":"stdout","text":["Found existing installation: protobuf 4.25.5\n","Uninstalling protobuf-4.25.5:\n","  Successfully uninstalled protobuf-4.25.5\n","Collecting protobuf==3.20.1\n","  Downloading protobuf-3.20.1-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (698 bytes)\n","Downloading protobuf-3.20.1-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: protobuf\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","apache-beam 2.61.0 requires protobuf!=4.0.*,!=4.21.*,!=4.22.0,!=4.23.*,!=4.24.*,<6.0.0.dev0,>=3.20.3, but you have protobuf 3.20.1 which is incompatible.\n","google-ai-generativelanguage 0.6.10 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.20.1 which is incompatible.\n","google-api-core 2.19.2 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0.dev0,>=3.19.5, but you have protobuf 3.20.1 which is incompatible.\n","google-cloud-aiplatform 1.71.1 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.20.1 which is incompatible.\n","google-cloud-bigquery-connection 1.16.1 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.20.1 which is incompatible.\n","google-cloud-bigquery-storage 2.27.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.20.1 which is incompatible.\n","google-cloud-bigtable 2.27.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.20.1 which is incompatible.\n","google-cloud-datastore 2.20.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.20.1 which is incompatible.\n","google-cloud-firestore 2.19.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.20.1 which is incompatible.\n","google-cloud-functions 1.18.1 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.20.1 which is incompatible.\n","google-cloud-iam 2.16.1 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.20.1 which is incompatible.\n","google-cloud-language 2.15.1 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.20.1 which is incompatible.\n","google-cloud-pubsub 2.27.1 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.20.1 which is incompatible.\n","google-cloud-resource-manager 1.13.1 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.20.1 which is incompatible.\n","google-cloud-translate 3.17.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.20.1 which is incompatible.\n","googleapis-common-protos 1.66.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0.dev0,>=3.20.2, but you have protobuf 3.20.1 which is incompatible.\n","grpc-google-iam-v1 0.13.1 requires protobuf!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.20.1 which is incompatible.\n","grpcio-status 1.62.3 requires protobuf>=4.21.6, but you have protobuf 3.20.1 which is incompatible.\n","pandas-gbq 0.24.0 requires google-auth-oauthlib>=0.7.0, but you have google-auth-oauthlib 0.4.6 which is incompatible.\n","tensorflow-metadata 1.13.1 requires protobuf<5,>=3.20.3, but you have protobuf 3.20.1 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed protobuf-3.20.1\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["google"]},"id":"312f0305e5734157aa1e0bc724eaf937"}},"metadata":{}}],"source":["# Protobuf 패키지 문제 해결을 위한 설치 과정\n","\n","!pip uninstall -y protobuf  # Protobuf 패키지를 제거 (-y 옵션으로 사용자 확인 없이 제거).\n","!pip install protobuf==3.20.1  # Protobuf 버전을 3.20.1로 다시 설치"]},{"cell_type":"markdown","metadata":{"id":"9eHNXn0C3rLH"},"source":["- 아래 셀을 통해 강제로 세션 종료  \n","그 다음 셀로 넘어가서 계속 진행하면 됨"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qKP04Meu3pBc"},"outputs":[],"source":["import os\n","\n","# 현재 실행 중인 프로세스를 강제로 종료\n","os.kill(os.getpid(), 9)  # os.getpid()로 현재 프로세스 ID를 가져오고, 신호 9(SIGKILL)로 해당 프로세스를 종료"]},{"cell_type":"markdown","metadata":{"id":"eFdiIGP23xt6"},"source":["- 아래 셀 출력 값이 다음과 같다면 성공\n","```\n","Name: protobuf  \n","Version: 3.20.1\n","```\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5931,"status":"ok","timestamp":1733207777020,"user":{"displayName":"정현우","userId":"03215566591887948765"},"user_tz":-540},"id":"9atrEWW93w1Y","outputId":"b4ae1f93-000d-4275-9c56-8f9e2b081c12"},"outputs":[{"output_type":"stream","name":"stdout","text":["Name: protobuf\n","Version: 3.20.1\n","Summary: Protocol Buffers\n","Home-page: https://developers.google.com/protocol-buffers/\n","Author: \n","Author-email: \n","License: BSD-3-Clause\n","Location: /usr/local/lib/python3.10/dist-packages\n","Requires: \n","Required-by: apache-beam, google-ai-generativelanguage, google-api-core, google-cloud-aiplatform, google-cloud-bigquery-connection, google-cloud-bigquery-storage, google-cloud-bigtable, google-cloud-datastore, google-cloud-firestore, google-cloud-functions, google-cloud-iam, google-cloud-language, google-cloud-pubsub, google-cloud-resource-manager, google-cloud-translate, google-generativeai, googleapis-common-protos, grpc-google-iam-v1, grpcio-status, orbax-checkpoint, proto-plus, tensorboard, tensorflow, tensorflow-datasets, tensorflow-hub, tensorflow-metadata, wandb\n"]}],"source":["# Protobuf 패키지 정보 확인\n","!pip show protobuf"]},{"cell_type":"markdown","metadata":{"id":"H_S3_tX48Rgj"},"source":["## 1-2. TensorFlow Object Detection API 설치 확인"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2829,"status":"ok","timestamp":1733207779839,"user":{"displayName":"정현우","userId":"03215566591887948765"},"user_tz":-540},"id":"tKB-ZxQY4KKv","outputId":"2716e3c3-d8d4-4fb4-c05a-33374584dd88"},"outputs":[{"output_type":"stream","name":"stdout","text":["Traceback (most recent call last):\n","  File \"/content/models/research/object_detection/builders/model_builder_tf2_test.py\", line 21, in <module>\n","    import tensorflow.compat.v1 as tf\n","  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/__init__.py\", line 37, in <module>\n","    from tensorflow.python.tools import module_util as _module_util\n","  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/__init__.py\", line 42, in <module>\n","    from tensorflow.python import data\n","  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/__init__.py\", line 21, in <module>\n","    from tensorflow.python.data import experimental\n","  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/experimental/__init__.py\", line 95, in <module>\n","    from tensorflow.python.data.experimental import service\n","  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/experimental/service/__init__.py\", line 387, in <module>\n","    from tensorflow.python.data.experimental.ops.data_service_ops import distribute\n","  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/experimental/ops/data_service_ops.py\", line 23, in <module>\n","    from tensorflow.python.data.experimental.ops import compression_ops\n","  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/experimental/ops/compression_ops.py\", line 16, in <module>\n","    from tensorflow.python.data.util import structure\n","  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/util/structure.py\", line 22, in <module>\n","    from tensorflow.python.data.util import nest\n","  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/util/nest.py\", line 36, in <module>\n","    from tensorflow.python.framework import sparse_tensor as _sparse_tensor\n","  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/sparse_tensor.py\", line 24, in <module>\n","    from tensorflow.python.framework import constant_op\n","  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/constant_op.py\", line 25, in <module>\n","    from tensorflow.python.eager import execute\n","  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\", line 22, in <module>\n","    from tensorflow.python.eager import core\n","  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/core.py\", line 18, in <module>\n","    from tensorflow.python.framework import errors\n","  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/errors.py\", line 18, in <module>\n","    from tensorflow.python.framework import errors_impl as _impl\n","  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/errors_impl.py\", line 21, in <module>\n","    from tensorflow.python import _pywrap_py_exception_registry\n","KeyboardInterrupt\n","^C\n"]}],"source":["# 모델 빌더 테스트 파일 실행: 설정이 올바르게 작동하는지 확인하기 위한 테스트\n","\n","!python /content/models/research/object_detection/builders/model_builder_tf2_test.py\n","# Object Detection API의 모델 빌더 구성 요소를 테스트하는 스크립트를 실행\n","# 이 스크립트는 설치 및 구성 파일들이 제대로 작동하는지 확인하는 데 사용됨"]},{"cell_type":"markdown","metadata":{"id":"wspwAJ904dNK"},"source":["# 2.&nbsp;데이터 준비"]},{"cell_type":"markdown","metadata":{"id":"shYePDc68bFI"},"source":["## 2-1. 라벨 맵(labelmap.txt) 파일 생성\n","- 테스트 데이터의 형식을 참고하여 아래에 클래스 이름 작성하기"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qGOk09Bi4ezZ"},"outputs":[],"source":["# 객체 탐지 모델이 탐지할 클래스 목록을 포함하는 \"labelmap.txt\" 파일 생성\n","%%bash\n","\n","# labelmap.txt 파일에 클래스 이름을 추가\n","cat <<EOF >> /content/labelmap.txt\n","motorcycle\n","bicycle\n","kickboard\n","EOF"]},{"cell_type":"markdown","metadata":{"id":"YL8xoDWY8jmU"},"source":["## 2-2. 데이터셋 위치 정의(train/test 데이터)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17945,"status":"ok","timestamp":1733207801535,"user":{"displayName":"정현우","userId":"03215566591887948765"},"user_tz":-540},"id":"VG1WeY0j4ie4","outputId":"b7e20443-15be-4172-ef59-0a2318e2d3c2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","\n","# Google Drive 연결\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"Jl0ncbpaRBwS"},"source":["- 각 파일이 있는 경로 지정\n","  - `base_dir`\n","  - `train_record_fname`\n","  - `val_record_fname`\n","  - `label_map_pbtxt_fname`"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Uze6-74j4lTf"},"outputs":[],"source":["# 작업 디렉토리 설정\n","base_dir = '/content/drive/MyDrive/CrossMate/data/학습데이터/tfrecord'\n","train_record_fname = f'{base_dir}/train/2.tfrecord'\n","val_record_fname = f'{base_dir}/valid/2.tfrecord'\n","label_map_pbtxt_fname = f'{base_dir}/train/2_label_map.pbtxt'"]},{"cell_type":"markdown","metadata":{"id":"ysI2ODW44qDb"},"source":["# 3.&nbsp;훈련 구성 설정"]},{"cell_type":"markdown","metadata":{"id":"Ozid90gD8rS-"},"source":["## 3-1. 사용할 모델 설정(SSD MobileNet V2)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EHWwjhAB4pOL"},"outputs":[],"source":["# TF2 Object Detection Zoo에서 제공하는 다양한 모델 중 하나를 선택하여 배포할 수 있도록 설정\n","\n","# 선택한 모델의 이름을 설정\n","# chosen_model = 'ssd-mobilenet-v2-fpnlite-640'\n","chosen_model = 'efficientdet-d1'\n","\n","# 사용할 모델들의 구성 정보 딕셔너리\n","MODELS_CONFIG = {\n","    # 1. SSD MobileNet V2 (320x320 해상도, COCO 데이터셋 기반)\n","    'ssd-mobilenet-v2': {\n","        'model_name': 'ssd_mobilenet_v2_320x320_coco17_tpu-8',  # 모델 이름\n","        'base_pipeline_file': 'ssd_mobilenet_v2_320x320_coco17_tpu-8.config',  # 기본 파이프라인 구성 파일\n","        'pretrained_checkpoint': 'ssd_mobilenet_v2_320x320_coco17_tpu-8.tar.gz',  # 사전 학습된 체크포인트 파일\n","    },\n","    # 2. EfficientDet-D0 (효율적인 작은 크기의 모델, COCO 데이터셋 기반)\n","    'efficientdet-d0': {\n","        'model_name': 'efficientdet_d0_coco17_tpu-32',\n","        'base_pipeline_file': 'ssd_efficientdet_d0_512x512_coco17_tpu-8.config',\n","        'pretrained_checkpoint': 'efficientdet_d0_coco17_tpu-32.tar.gz',\n","    },\n","    # 3. SSD MobileNet V2 FPNLite (320x320 해상도, COCO 데이터셋 기반, FPN 사용)\n","    'ssd-mobilenet-v2-fpnlite-320': {\n","        'model_name': 'ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8',\n","        'base_pipeline_file': 'ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.config',\n","        'pretrained_checkpoint': 'ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz',\n","    },\n","    # 4. CenterNet (현재 작동하지 않음 - 2022년 9월 10일 기준)\n","    # 'centernet-mobilenet-v2': {\n","    #     'model_name': 'centernet_mobilenetv2fpn_512x512_coco17_od',\n","    #     'base_pipeline_file': 'pipeline.config',\n","    #     'pretrained_checkpoint': 'centernet_mobilenetv2fpn_512x512_coco17_od.tar.gz',\n","    # },\n","    # 1. SSD MobileNet V2 (640x640 해상도, COCO 데이터셋 기반)\n","    'ssd-mobilenet-v2': {\n","        'model_name': 'ssd_mobilenet_v2_640x640_coco17_tpu-8',  # 모델 이름\n","        'base_pipeline_file': 'ssd_mobilenet_v2_640x640_coco17_tpu-8.config',  # 기본 파이프라인 구성 파일\n","        'pretrained_checkpoint': 'ssd_mobilenet_v2_640x640_coco17_tpu-8.tar.gz',  # 사전 학습된 체크포인트 파일\n","    },\n","    # 2. EfficientDet-D0 (효율적인 작은 크기의 모델, COCO 데이터셋 기반)\n","    'efficientdet-d1': {\n","        'model_name': 'efficientdet_d1_coco17_tpu-32',\n","        'base_pipeline_file': 'ssd_efficientdet_d1_640x640_coco17_tpu-8.config',\n","        'pretrained_checkpoint': 'efficientdet_d1_coco17_tpu-32.tar.gz',\n","    },\n","    # 3. SSD MobileNet V2 FPNLite (640x640 해상도, COCO 데이터셋 기반, FPN 사용)\n","    'ssd-mobilenet-v2-fpnlite-640': {\n","        'model_name': 'ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8',\n","        'base_pipeline_file': 'ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8.config',\n","        'pretrained_checkpoint': 'ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8.tar.gz',\n","    },\n","    # 4. CenterNet (현재 작동하지 않음 - 2022년 9월 10일 기준)\n","    # 'centernet-mobilenet-v2': {\n","    #     'model_name': 'centernet_mobilenetv2fpn_512x512_coco17_od',\n","    #     'base_pipeline_file': 'pipeline.config',\n","    #     'pretrained_checkpoint': 'centernet_mobilenetv2fpn_512x512_coco17_od.tar.gz',\n","    # }\n","}\n","\n","# 선택된 모델에 해당하는 구성 정보 가져오기\n","model_name = MODELS_CONFIG[chosen_model]['model_name']  # 모델 이름\n","pretrained_checkpoint = MODELS_CONFIG[chosen_model]['pretrained_checkpoint']  # 사전 학습된 체크포인트 경로\n","base_pipeline_file = MODELS_CONFIG[chosen_model]['base_pipeline_file']  # 기본 파이프라인 구성 파일 경로"]},{"cell_type":"markdown","metadata":{"id":"mQRgaEYP8vq1"},"source":["## 3-2. 모델 구성 파일 및 사전 학습된 가중치 다운로드"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2039,"status":"ok","timestamp":1733207803571,"user":{"displayName":"정현우","userId":"03215566591887948765"},"user_tz":-540},"id":"tv6L8xOV4yOp","outputId":"1156d7ff-6810-49be-ab8a-1d5dc54a4c71"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/models/mymodel\n","--2024-12-03 06:36:41--  http://download.tensorflow.org/models/object_detection/tf2/20200711/efficientdet_d1_coco17_tpu-32.tar.gz\n","Resolving download.tensorflow.org (download.tensorflow.org)... 142.251.2.207, 74.125.137.207, 2607:f8b0:4023:c0d::cf, ...\n","Connecting to download.tensorflow.org (download.tensorflow.org)|142.251.2.207|:80... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 51839363 (49M) [application/x-tar]\n","Saving to: ‘efficientdet_d1_coco17_tpu-32.tar.gz’\n","\n","efficientdet_d1_coc 100%[===================>]  49.44M   116MB/s    in 0.4s    \n","\n","2024-12-03 06:36:41 (116 MB/s) - ‘efficientdet_d1_coco17_tpu-32.tar.gz’ saved [51839363/51839363]\n","\n","--2024-12-03 06:36:42--  https://raw.githubusercontent.com/tensorflow/models/master/research/object_detection/configs/tf2/ssd_efficientdet_d1_640x640_coco17_tpu-8.config\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 4630 (4.5K) [text/plain]\n","Saving to: ‘ssd_efficientdet_d1_640x640_coco17_tpu-8.config’\n","\n","ssd_efficientdet_d1 100%[===================>]   4.52K  --.-KB/s    in 0s      \n","\n","2024-12-03 06:36:42 (53.4 MB/s) - ‘ssd_efficientdet_d1_640x640_coco17_tpu-8.config’ saved [4630/4630]\n","\n"]}],"source":["# \"mymodel\" 폴더 생성: 사전 학습된 가중치와 구성 파일을 저장할 디렉토리 생성\n","%mkdir /content/models/mymodel/\n","%cd /content/models/mymodel/\n","\n","# 사전 학습된 모델 가중치 다운로드\n","import tarfile  # tar 파일 압축 해제를 위한 라이브러리\n","download_tar = 'http://download.tensorflow.org/models/object_detection/tf2/20200711/' + pretrained_checkpoint\n","\n","# 설정된 URL에서 가중치 파일 다운로드\n","!wget {download_tar}\n","\n","tar = tarfile.open(pretrained_checkpoint)  # 다운로드한 tar 파일 열기\n","tar.extractall()  # tar 파일의 모든 내용을 현재 디렉토리에 추출\n","tar.close()  # 파일 닫기\n","\n","# 학습 구성 파일 다운로드\n","# 해당 모델의 훈련을 위한 기본 설정이 포함된 구성 파일(pipeline.config)을 다운로드\n","download_config = 'https://raw.githubusercontent.com/tensorflow/models/master/research/object_detection/configs/tf2/' + base_pipeline_file\n","\n","# 구성 파일을 지정된 URL에서 다운로드\n","!wget {download_config}"]},{"cell_type":"markdown","metadata":{"id":"MRm3ThfJ8y_I"},"source":["## 3-3. 훈련 단계 및 배치 크기 설정\n","$$\n","\\text{Number of epochs} = \\frac{\\text{num steps} \\times \\text{batch size}}{\\text{number of data}}\n","$$\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1733207803571,"user":{"displayName":"정현우","userId":"03215566591887948765"},"user_tz":-540},"id":"HhbyCQib41AV","colab":{"base_uri":"https://localhost:8080/"},"outputId":"00fb20da-bae5-4584-89d5-8946ede16fb1"},"outputs":[{"output_type":"stream","name":"stdout","text":["265500\n"]}],"source":["# 선택한 모델에 따라 배치 크기(batch size) 설정\n","if 'efficientdet' in chosen_model:  # EfficientDet case\n","  batch_size = 4  # 작은 모델이므로 더 작은 배치 크기 사용\n","else:\n","  batch_size = 16\n","\n","num_data = 5310\n","epoch = 200\n","\n","# 모델 훈련을 위한 파라미터 설정\n","num_steps = int(epoch*num_data/batch_size)  # 총 훈련 단계 수 설정 (훈련 반복 횟수)\n","print(num_steps)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6728,"status":"ok","timestamp":1733207810296,"user":{"displayName":"정현우","userId":"03215566591887948765"},"user_tz":-540},"id":"O-4mZ65K44az","outputId":"2661b1df-1ca4-4c05-d357-8e9dceba4ccd"},"outputs":[{"output_type":"stream","name":"stdout","text":["Total classes: 3\n"]}],"source":["# 파일 경로 및 클래스 수 가져오기\n","# 모델 훈련에 필요한 설정 파일 및 체크포인트 파일 경로 설정\n","pipeline_fname = '/content/models/mymodel/' + base_pipeline_file  # 파이프라인 구성 파일 경로\n","fine_tune_checkpoint = '/content/models/mymodel/' + model_name + '/checkpoint/ckpt-0'  # 사전 학습된 체크포인트 파일 경로\n","\n","# 라벨 맵에서 클래스 수를 계산하는 함수 정의\n","def get_num_classes(pbtxt_fname):\n","    from object_detection.utils import label_map_util  # Object Detection API에서 제공하는 유틸리티 모듈\n","    label_map = label_map_util.load_labelmap(pbtxt_fname)  # 라벨 맵 파일 로드\n","    categories = label_map_util.convert_label_map_to_categories(  # 라벨 맵 데이터를 카테고리로 변환\n","        label_map, max_num_classes=90, use_display_name=True)\n","    category_index = label_map_util.create_category_index(categories)  # 카테고리 인덱스를 생성\n","    return len(category_index.keys())  # 카테고리(클래스) 수 반환\n","\n","# 라벨 맵 파일에서 총 클래스 수 계산\n","num_classes = get_num_classes(label_map_pbtxt_fname)  # 라벨 맵 파일 경로를 전달하여 클래스 수 가져오기\n","print('Total classes:', num_classes)  # 클래스 수 출력"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1897,"status":"ok","timestamp":1733207812188,"user":{"displayName":"정현우","userId":"03215566591887948765"},"user_tz":-540},"id":"MV9u2WRR45ti","outputId":"d0c8991d-f323-4f19-a480-88b3a3161999"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["# 구글 드라이브 연결 확인\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"_hntoks69BGh"},"source":["# 4.&nbsp;사용자 정의 구성 파일 작성"]},{"cell_type":"markdown","metadata":{"id":"YOfPW2tcBnh8"},"source":["## 4-1. 데이터셋 경로, 라벨 맵 경로, 가중치 경로 등 업데이트"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1733207812188,"user":{"displayName":"정현우","userId":"03215566591887948765"},"user_tz":-540},"id":"qjJv2DC_48AO","outputId":"90a82141-38c6-4ee7-c44d-115af9c9742a"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/models/mymodel\n","writing custom configuration file\n"]}],"source":["# 기본 파이프라인 파일을 수정하여 사용자 정의 구성 파일 생성\n","# 데이터셋, 모델 체크포인트, 학습 파라미터를 작성\n","\n","import re\n","\n","# 작업 디렉토리 변경\n","%cd /content/models/mymodel\n","print('writing custom configuration file')\n","\n","# 기존 파이프라인 파일 읽기\n","with open(pipeline_fname) as f:\n","    s = f.read()\n","\n","# 수정된 내용을 새로운 구성 파일에 쓰기\n","with open('pipeline_file.config', 'w') as f:\n","\n","    # 사전 학습된 체크포인트 경로 설정\n","    s = re.sub('fine_tune_checkpoint: \".*?\"',\n","               'fine_tune_checkpoint: \"{}\"'.format(fine_tune_checkpoint), s)\n","\n","    # 학습 데이터(train) 및 검증 데이터(val) 경로 설정\n","    s = re.sub(\n","        '(input_path: \".*?)(PATH_TO_BE_CONFIGURED/train)(.*?\")', 'input_path: \"{}\"'.format(train_record_fname), s)\n","    s = re.sub(\n","        '(input_path: \".*?)(PATH_TO_BE_CONFIGURED/val)(.*?\")', 'input_path: \"{}\"'.format(val_record_fname), s)\n","\n","    # 라벨 맵 경로 설정\n","    s = re.sub(\n","        'label_map_path: \".*?\"', 'label_map_path: \"{}\"'.format(label_map_pbtxt_fname), s)\n","\n","    # 배치 크기 설정\n","    s = re.sub('batch_size: [0-9]+',\n","               'batch_size: {}'.format(batch_size), s)\n","\n","    # 학습 단계 수(num_steps) 설정\n","    s = re.sub('num_steps: [0-9]+',\n","               'num_steps: {}'.format(num_steps), s)\n","\n","    # 클래스 수(num_classes) 설정\n","    s = re.sub('num_classes: [0-9]+',\n","               'num_classes: {}'.format(num_classes), s)\n","\n","    # 체크포인트 유형을 \"classification\"에서 \"detection\"으로 변경\n","    s = re.sub(\n","        'fine_tune_checkpoint_type: \"classification\"', 'fine_tune_checkpoint_type: \"{}\"'.format('detection'), s)\n","\n","    # SSD MobileNet V2 모델의 경우 학습률(learning rate) 감소\n","    if chosen_model == 'ssd-mobilenet-v2':\n","      s = re.sub('learning_rate_base: .8',\n","                 'learning_rate_base: .08', s)\n","      s = re.sub('warmup_learning_rate: 0.13333',\n","                 'warmup_learning_rate: .026666', s)\n","\n","    # EfficientDet-D0 모델의 경우, TFLite와 호환되지 않는 구성을 수정\n","    if 'efficientdet' in chosen_model:\n","      s = re.sub('learning_rate_base: .8', 'learning_rate_base: .08', s)\n","      s = re.sub('keep_aspect_ratio_resizer', 'fixed_shape_resizer', s)  # 비율 유지 대신 고정 크기 사용\n","      s = re.sub('pad_to_max_dimension: true', '', s)  # 패딩 제거\n","      s = re.sub('min_dimension', 'height', s)  # 최소 크기를 높이로 변경\n","      s = re.sub('max_dimension', 'width', s)  # 최대 크기를 너비로 변경\n","\n","    # 수정된 내용을 파일에 작성\n","    f.write(s)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1733207812188,"user":{"displayName":"정현우","userId":"03215566591887948765"},"user_tz":-540},"id":"Sr6EwDZ54-yU","outputId":"65991285-e4cb-4364-e983-3e43b5f04574"},"outputs":[{"output_type":"stream","name":"stdout","text":[" # SSD with EfficientNet-b1 + BiFPN feature extractor,\n","# shared box predictor and focal loss (a.k.a EfficientDet-d1).\n","# See EfficientDet, Tan et al, https://arxiv.org/abs/1911.09070\n","# See Lin et al, https://arxiv.org/abs/1708.02002\n","# Trained on COCO, initialized from an EfficientNet-b1 checkpoint.\n","#\n","# Train on TPU-8\n","\n","model {\n","  ssd {\n","    inplace_batchnorm_update: true\n","    freeze_batchnorm: false\n","    num_classes: 3\n","    add_background_class: false\n","    box_coder {\n","      faster_rcnn_box_coder {\n","        y_scale: 10.0\n","        x_scale: 10.0\n","        height_scale: 5.0\n","        width_scale: 5.0\n","      }\n","    }\n","    matcher {\n","      argmax_matcher {\n","        matched_threshold: 0.5\n","        unmatched_threshold: 0.5\n","        ignore_thresholds: false\n","        negatives_lower_than_unmatched: true\n","        force_match_for_each_row: true\n","        use_matmul_gather: true\n","      }\n","    }\n","    similarity_calculator {\n","      iou_similarity {\n","      }\n","    }\n","    encode_background_as_zeros: true\n","    anchor_generator {\n","      multiscale_anchor_generator {\n","        min_level: 3\n","        max_level: 7\n","        anchor_scale: 4.0\n","        aspect_ratios: [1.0, 2.0, 0.5]\n","        scales_per_octave: 3\n","      }\n","    }\n","    image_resizer {\n","      fixed_shape_resizer {\n","        height: 640\n","        width: 640\n","        \n","        }\n","    }\n","    box_predictor {\n","      weight_shared_convolutional_box_predictor {\n","        depth: 88\n","        class_prediction_bias_init: -4.6\n","        conv_hyperparams {\n","          force_use_bias: true\n","          activation: SWISH\n","          regularizer {\n","            l2_regularizer {\n","              weight: 0.00004\n","            }\n","          }\n","          initializer {\n","            random_normal_initializer {\n","              stddev: 0.01\n","              mean: 0.0\n","            }\n","          }\n","          batch_norm {\n","            scale: true\n","            decay: 0.99\n","            epsilon: 0.001\n","          }\n","        }\n","        num_layers_before_predictor: 3\n","        kernel_size: 3\n","        use_depthwise: true\n","      }\n","    }\n","    feature_extractor {\n","      type: 'ssd_efficientnet-b1_bifpn_keras'\n","      bifpn {\n","        min_level: 3\n","        max_level: 7\n","        num_iterations: 4\n","        num_filters: 88\n","      }\n","      conv_hyperparams {\n","        force_use_bias: true\n","        activation: SWISH\n","        regularizer {\n","          l2_regularizer {\n","            weight: 0.00004\n","          }\n","        }\n","        initializer {\n","          truncated_normal_initializer {\n","            stddev: 0.03\n","            mean: 0.0\n","          }\n","        }\n","        batch_norm {\n","          scale: true,\n","          decay: 0.99,\n","          epsilon: 0.001,\n","        }\n","      }\n","    }\n","    loss {\n","      classification_loss {\n","        weighted_sigmoid_focal {\n","          alpha: 0.25\n","          gamma: 1.5\n","        }\n","      }\n","      localization_loss {\n","        weighted_smooth_l1 {\n","        }\n","      }\n","      classification_weight: 1.0\n","      localization_weight: 1.0\n","    }\n","    normalize_loss_by_num_matches: true\n","    normalize_loc_loss_by_codesize: true\n","    post_processing {\n","      batch_non_max_suppression {\n","        score_threshold: 1e-8\n","        iou_threshold: 0.5\n","        max_detections_per_class: 100\n","        max_total_detections: 100\n","      }\n","      score_converter: SIGMOID\n","    }\n","  }\n","}\n","\n","train_config: {\n","  fine_tune_checkpoint: \"/content/models/mymodel/efficientdet_d1_coco17_tpu-32/checkpoint/ckpt-0\"\n","  fine_tune_checkpoint_version: V2\n","  fine_tune_checkpoint_type: \"detection\"\n","  batch_size: 4\n","  sync_replicas: true\n","  startup_delay_steps: 0\n","  replicas_to_aggregate: 8\n","  use_bfloat16: true\n","  num_steps: 265500\n","  data_augmentation_options {\n","    random_horizontal_flip {\n","    }\n","  }\n","  data_augmentation_options {\n","    random_scale_crop_and_pad_to_square {\n","      output_size: 640\n","      scale_min: 0.1\n","      scale_max: 2.0\n","    }\n","  }\n","  optimizer {\n","    momentum_optimizer: {\n","      learning_rate: {\n","        cosine_decay_learning_rate {\n","          learning_rate_base: 8e-2\n","          total_steps: 300000\n","          warmup_learning_rate: .001\n","          warmup_steps: 2500\n","        }\n","      }\n","      momentum_optimizer_value: 0.9\n","    }\n","    use_moving_average: false\n","  }\n","  max_number_of_boxes: 100\n","  unpad_groundtruth_tensors: false\n","}\n","\n","train_input_reader: {\n","  label_map_path: \"/content/drive/MyDrive/CrossMate/data/학습데이터/tfrecord/train/2_label_map.pbtxt\"\n","  tf_record_input_reader {\n","    input_path: \"/content/drive/MyDrive/CrossMate/data/학습데이터/tfrecord/train/2.tfrecord\"\n","  }\n","}\n","\n","eval_config: {\n","  metrics_set: \"coco_detection_metrics\"\n","  use_moving_averages: false\n","  batch_size: 4;\n","}\n","\n","eval_input_reader: {\n","  label_map_path: \"/content/drive/MyDrive/CrossMate/data/학습데이터/tfrecord/train/2_label_map.pbtxt\"\n","  shuffle: false\n","  num_epochs: 1\n","  tf_record_input_reader {\n","    input_path: \"/content/drive/MyDrive/CrossMate/data/학습데이터/tfrecord/valid/2.tfrecord\"\n","  }\n","}\n"]}],"source":["# (Optional) 사용자 정의 구성 파일의 내용을 출력하여 확인\n","\n","!cat /content/models/mymodel/pipeline_file.config\n","# 터미널에서 pipeline_file.config 파일의 내용을 출력\n","# 작성된 구성 파일이 올바른지 확인하는 데 사용"]},{"cell_type":"markdown","metadata":{"id":"oacZ6OPQBsOa"},"source":["## 4-2. 사용자 정의 파일 경로 설정"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mf4bpWsu5CFx"},"outputs":[],"source":["# 사용자 정의 구성 파일 경로 및 훈련 체크포인트 저장 디렉토리 설정\n","\n","pipeline_file = '/content/models/mymodel/pipeline_file.config'  # 사용자 정의 구성 파일 경로\n","model_dir = f'/content/drive/MyDrive/CrossMate/model/fine_tuned_models/{model_name}/training/'  # 훈련 중 생성되는 체크포인트 파일을 저장할 디렉토리 경로"]},{"cell_type":"markdown","metadata":{"id":"U0Dq9W6y5DeR"},"source":["# 5.&nbsp;모델 훈련"]},{"cell_type":"markdown","metadata":{"id":"Gp2EHwvYB0R0"},"source":["## 5-1. TensorBoard를 활용한 훈련 모니터링"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5283,"status":"ok","timestamp":1733207817468,"user":{"displayName":"정현우","userId":"03215566591887948765"},"user_tz":-540},"id":"L2DxZfdX5DNZ","outputId":"090502f7-fb58-4440-e49e-3d9757264b7c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (2.8.0)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.4.0)\n","Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.65.5)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (2.27.0)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (0.4.6)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.7)\n","Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.26.4)\n","Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.20.1)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (2.32.3)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (75.1.0)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (0.6.1)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.8.1)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.1.3)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (0.45.0)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (5.5.0)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (0.4.1)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (1.3.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard) (2024.8.30)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=0.11.15->tensorboard) (3.0.2)\n","Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard) (0.6.1)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (3.2.2)\n"]}],"source":["!pip install tensorboard"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3143,"status":"ok","timestamp":1733207820606,"user":{"displayName":"정현우","userId":"03215566591887948765"},"user_tz":-540},"id":"uvbAqjXz5JGr","outputId":"1ed3b60c-0f58-49fe-dd87-62f63a57763b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Name: tensorboard\n","Version: 2.8.0\n","Summary: TensorBoard lets you watch Tensors Flow\n","Home-page: https://github.com/tensorflow/tensorboard\n","Author: Google Inc.\n","Author-email: packages@tensorflow.org\n","License: Apache 2.0\n","Location: /usr/local/lib/python3.10/dist-packages\n","Requires: absl-py, google-auth, google-auth-oauthlib, grpcio, markdown, numpy, protobuf, requests, setuptools, tensorboard-data-server, tensorboard-plugin-wit, werkzeug, wheel\n","Required-by: tensorflow\n"]}],"source":["!pip show tensorboard"]},{"cell_type":"markdown","metadata":{"id":"V4hdnGLEZ9qM"},"source":["- 아래 코드는 일단 실행  \n","but 처음엔 아무 내용도 나오지 않음  \n","모델 학습을 진행하는 중에 새로고침하면 학습 과정 그래프 볼 수 있음"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Rt2eqOey5Loi"},"outputs":[],"source":["# TensorBoard 확장 로드 및 로그 디렉토리 설정\n","\n","# Jupyter/Colab 환경에서 TensorBoard 확장 로드\n","# %load_ext tensorboard\n","\n","# TensorBoard를 실행하여 '/content/training/train' 디렉토리의 로그 데이터 시각화\n","# %tensorboard --logdir '/content/drive/MyDrive/CrossMate/model/fine_tuned_models/ssd_mobilenet_v2_fpnlite_640x640/training/train'"]},{"cell_type":"markdown","metadata":{"id":"39MsT_ffB3vn"},"source":["## 5-2. Object Detection API를 이용한 훈련 실행"]},{"cell_type":"markdown","metadata":{"id":"dQLP26Hiax2p"},"source":["\n","\n","```\n","!python /content/models/research/object_detection/model_main_tf2.py \\  # Object Detection API의 주요 훈련 스크립트 실행\n","    --pipeline_config_path={pipeline_file} \\  # 사용자 정의 구성 파일의 경로를 전달\n","    --model_dir={model_dir} \\  # 체크포인트 파일과 로그를 저장할 디렉토리 경로 지정\n","    --alsologtostderr \\  # 표준 오류(stdout)로도 로그 메시지를 출력하도록 설정\n","    --num_train_steps={num_steps} \\  # 훈련 단계 수를 설정 (여기서는 {num_steps}로 지정)\n","    --sample_1_of_n_eval_examples=1  # 평가 데이터에서 1/n 샘플을 사용하여 평가를 수행 (여기서는 모든 예제를 평가)\n","```\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4z0-GgCV5PBT","executionInfo":{"status":"ok","timestamp":1733214683559,"user_tz":-540,"elapsed":6862955,"user":{"displayName":"정현우","userId":"03215566591887948765"}},"outputId":"5e7dc2e4-0e2e-4c23-8c6c-f05692833b4b"},"outputs":[{"output_type":"stream","name":"stdout","text":["/usr/local/lib/python3.10/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n","\n","TensorFlow Addons (TFA) has ended development and introduction of new features.\n","TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n","Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n","\n","For more information see: https://github.com/tensorflow/addons/issues/2807 \n","\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/tensorflow_addons/utils/ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.13.0 and strictly below 2.16.0 (nightly versions are not supported). \n"," The versions of TensorFlow you are currently using is 2.8.0 and is not supported. \n","Some things might work, some things might not.\n","If you were to encounter a bug, do not file an issue.\n","If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n","You can find the compatibility matrix in TensorFlow Addon's readme:\n","https://github.com/tensorflow/addons\n","  warnings.warn(\n","2024-12-03 06:37:15.753078: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n","I1203 06:37:15.801788 133410652246656 mirrored_strategy.py:374] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n","INFO:tensorflow:Maybe overwriting train_steps: 265500\n","I1203 06:37:15.805448 133410652246656 config_util.py:552] Maybe overwriting train_steps: 265500\n","INFO:tensorflow:Maybe overwriting use_bfloat16: False\n","I1203 06:37:15.805646 133410652246656 config_util.py:552] Maybe overwriting use_bfloat16: False\n","I1203 06:37:15.820397 133410652246656 ssd_efficientnet_bifpn_feature_extractor.py:161] EfficientDet EfficientNet backbone version: efficientnet-b1\n","I1203 06:37:15.820525 133410652246656 ssd_efficientnet_bifpn_feature_extractor.py:163] EfficientDet BiFPN num filters: 88\n","I1203 06:37:15.820595 133410652246656 ssd_efficientnet_bifpn_feature_extractor.py:164] EfficientDet BiFPN num iterations: 4\n","I1203 06:37:15.825829 133410652246656 efficientnet_model.py:144] round_filter input=32 output=32\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I1203 06:37:15.874227 133410652246656 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I1203 06:37:15.888792 133410652246656 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I1203 06:37:15.891077 133410652246656 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I1203 06:37:15.891977 133410652246656 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I1203 06:37:15.901328 133410652246656 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I1203 06:37:15.904256 133410652246656 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I1203 06:37:15.909397 133410652246656 efficientnet_model.py:144] round_filter input=32 output=32\n","I1203 06:37:15.909510 133410652246656 efficientnet_model.py:144] round_filter input=16 output=16\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I1203 06:37:15.924820 133410652246656 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I1203 06:37:15.925725 133410652246656 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I1203 06:37:15.927313 133410652246656 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I1203 06:37:15.928385 133410652246656 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I1203 06:37:16.091651 133410652246656 efficientnet_model.py:144] round_filter input=16 output=16\n","I1203 06:37:16.091792 133410652246656 efficientnet_model.py:144] round_filter input=24 output=24\n","I1203 06:37:16.596029 133410652246656 efficientnet_model.py:144] round_filter input=24 output=24\n","I1203 06:37:16.596218 133410652246656 efficientnet_model.py:144] round_filter input=40 output=40\n","I1203 06:37:16.946655 133410652246656 efficientnet_model.py:144] round_filter input=40 output=40\n","I1203 06:37:16.946819 133410652246656 efficientnet_model.py:144] round_filter input=80 output=80\n","I1203 06:37:17.416366 133410652246656 efficientnet_model.py:144] round_filter input=80 output=80\n","I1203 06:37:17.416563 133410652246656 efficientnet_model.py:144] round_filter input=112 output=112\n","I1203 06:37:17.882076 133410652246656 efficientnet_model.py:144] round_filter input=112 output=112\n","I1203 06:37:17.882276 133410652246656 efficientnet_model.py:144] round_filter input=192 output=192\n","I1203 06:37:18.476073 133410652246656 efficientnet_model.py:144] round_filter input=192 output=192\n","I1203 06:37:18.476239 133410652246656 efficientnet_model.py:144] round_filter input=320 output=320\n","I1203 06:37:18.748092 133410652246656 efficientnet_model.py:144] round_filter input=1280 output=1280\n","I1203 06:37:18.801449 133410652246656 efficientnet_model.py:454] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.1, resolution=240, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/object_detection/model_lib_v2.py:563: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","rename to distribute_datasets_from_function\n","W1203 06:37:18.853989 133410652246656 deprecation.py:337] From /usr/local/lib/python3.10/dist-packages/object_detection/model_lib_v2.py:563: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","rename to distribute_datasets_from_function\n","INFO:tensorflow:Reading unweighted datasets: ['/content/drive/MyDrive/CrossMate/data/학습데이터/tfrecord/train/2.tfrecord']\n","I1203 06:37:18.879733 133410652246656 dataset_builder.py:162] Reading unweighted datasets: ['/content/drive/MyDrive/CrossMate/data/학습데이터/tfrecord/train/2.tfrecord']\n","INFO:tensorflow:Reading record datasets for input file: ['/content/drive/MyDrive/CrossMate/data/학습데이터/tfrecord/train/2.tfrecord']\n","I1203 06:37:18.880457 133410652246656 dataset_builder.py:79] Reading record datasets for input file: ['/content/drive/MyDrive/CrossMate/data/학습데이터/tfrecord/train/2.tfrecord']\n","INFO:tensorflow:Number of filenames to read: 1\n","I1203 06:37:18.880647 133410652246656 dataset_builder.py:80] Number of filenames to read: 1\n","WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n","W1203 06:37:18.880745 133410652246656 dataset_builder.py:86] num_readers has been reduced to 1 to match input file shards.\n","WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n","W1203 06:37:18.886749 133410652246656 deprecation.py:337] From /usr/local/lib/python3.10/dist-packages/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n","WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/object_detection/builders/dataset_builder.py:235: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.map()\n","W1203 06:37:18.916534 133410652246656 deprecation.py:337] From /usr/local/lib/python3.10/dist-packages/object_detection/builders/dataset_builder.py:235: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.map()\n","WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py:1082: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n","W1203 06:37:27.766497 133410652246656 deprecation.py:337] From /usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py:1082: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n","WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py:1082: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","W1203 06:37:32.510260 133410652246656 deprecation.py:337] From /usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py:1082: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","/usr/local/lib/python3.10/dist-packages/keras/backend.py:450: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n","  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\n","I1203 06:37:50.960084 133404846687808 api.py:441] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\n","I1203 06:38:04.790639 133404846687808 api.py:441] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\n","2024-12-03 06:38:12.534034: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 30690000 exceeds 10% of free system memory.\n","2024-12-03 06:38:13.651365: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 30690000 exceeds 10% of free system memory.\n","2024-12-03 06:38:13.669614: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 30690000 exceeds 10% of free system memory.\n","2024-12-03 06:38:13.715313: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 30690000 exceeds 10% of free system memory.\n","2024-12-03 06:38:13.733955: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 30690000 exceeds 10% of free system memory.\n","2024-12-03 06:38:14.486563: W tensorflow/stream_executor/gpu/asm_compiler.cc:111] *** WARNING *** You are using ptxas 11.0.194, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n","\n","You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n","WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow/python/util/deprecation.py:616: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use fn_output_signature instead\n","W1203 06:38:31.590679 133404863473216 deprecation.py:541] From /usr/local/lib/python3.10/dist-packages/tensorflow/python/util/deprecation.py:616: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use fn_output_signature instead\n","I1203 06:38:34.528611 133404863473216 api.py:441] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\n","WARNING:tensorflow:Gradients do not exist for variables ['stack_6/block_1/expand_bn/gamma:0', 'stack_6/block_1/expand_bn/beta:0', 'stack_6/block_1/depthwise_conv2d/depthwise_kernel:0', 'stack_6/block_1/depthwise_bn/gamma:0', 'stack_6/block_1/depthwise_bn/beta:0', 'stack_6/block_1/project_bn/gamma:0', 'stack_6/block_1/project_bn/beta:0', 'top_bn/gamma:0', 'top_bn/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n","W1203 06:38:42.692634 133404863473216 utils.py:76] Gradients do not exist for variables ['stack_6/block_1/expand_bn/gamma:0', 'stack_6/block_1/expand_bn/beta:0', 'stack_6/block_1/depthwise_conv2d/depthwise_kernel:0', 'stack_6/block_1/depthwise_bn/gamma:0', 'stack_6/block_1/depthwise_bn/beta:0', 'stack_6/block_1/project_bn/gamma:0', 'stack_6/block_1/project_bn/beta:0', 'top_bn/gamma:0', 'top_bn/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n","I1203 06:38:49.602823 133404863473216 api.py:441] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\n","WARNING:tensorflow:Gradients do not exist for variables ['stack_6/block_1/expand_bn/gamma:0', 'stack_6/block_1/expand_bn/beta:0', 'stack_6/block_1/depthwise_conv2d/depthwise_kernel:0', 'stack_6/block_1/depthwise_bn/gamma:0', 'stack_6/block_1/depthwise_bn/beta:0', 'stack_6/block_1/project_bn/gamma:0', 'stack_6/block_1/project_bn/beta:0', 'top_bn/gamma:0', 'top_bn/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n","W1203 06:38:57.186724 133404863473216 utils.py:76] Gradients do not exist for variables ['stack_6/block_1/expand_bn/gamma:0', 'stack_6/block_1/expand_bn/beta:0', 'stack_6/block_1/depthwise_conv2d/depthwise_kernel:0', 'stack_6/block_1/depthwise_bn/gamma:0', 'stack_6/block_1/depthwise_bn/beta:0', 'stack_6/block_1/project_bn/gamma:0', 'stack_6/block_1/project_bn/beta:0', 'top_bn/gamma:0', 'top_bn/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n","I1203 06:39:02.990486 133404863473216 api.py:441] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\n","WARNING:tensorflow:Gradients do not exist for variables ['stack_6/block_1/expand_bn/gamma:0', 'stack_6/block_1/expand_bn/beta:0', 'stack_6/block_1/depthwise_conv2d/depthwise_kernel:0', 'stack_6/block_1/depthwise_bn/gamma:0', 'stack_6/block_1/depthwise_bn/beta:0', 'stack_6/block_1/project_bn/gamma:0', 'stack_6/block_1/project_bn/beta:0', 'top_bn/gamma:0', 'top_bn/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n","W1203 06:39:11.092209 133404863473216 utils.py:76] Gradients do not exist for variables ['stack_6/block_1/expand_bn/gamma:0', 'stack_6/block_1/expand_bn/beta:0', 'stack_6/block_1/depthwise_conv2d/depthwise_kernel:0', 'stack_6/block_1/depthwise_bn/gamma:0', 'stack_6/block_1/depthwise_bn/beta:0', 'stack_6/block_1/project_bn/gamma:0', 'stack_6/block_1/project_bn/beta:0', 'top_bn/gamma:0', 'top_bn/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n","I1203 06:39:16.938877 133404863473216 api.py:441] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\n","WARNING:tensorflow:Gradients do not exist for variables ['stack_6/block_1/expand_bn/gamma:0', 'stack_6/block_1/expand_bn/beta:0', 'stack_6/block_1/depthwise_conv2d/depthwise_kernel:0', 'stack_6/block_1/depthwise_bn/gamma:0', 'stack_6/block_1/depthwise_bn/beta:0', 'stack_6/block_1/project_bn/gamma:0', 'stack_6/block_1/project_bn/beta:0', 'top_bn/gamma:0', 'top_bn/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n","W1203 06:39:25.543880 133404863473216 utils.py:76] Gradients do not exist for variables ['stack_6/block_1/expand_bn/gamma:0', 'stack_6/block_1/expand_bn/beta:0', 'stack_6/block_1/depthwise_conv2d/depthwise_kernel:0', 'stack_6/block_1/depthwise_bn/gamma:0', 'stack_6/block_1/depthwise_bn/beta:0', 'stack_6/block_1/project_bn/gamma:0', 'stack_6/block_1/project_bn/beta:0', 'top_bn/gamma:0', 'top_bn/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n","INFO:tensorflow:Step 100 per-step time 1.491s\n","I1203 06:41:00.154145 133410652246656 model_lib_v2.py:705] Step 100 per-step time 1.491s\n","INFO:tensorflow:{'Loss/classification_loss': 1.0876245,\n"," 'Loss/localization_loss': 0.66016006,\n"," 'Loss/regularization_loss': 0.029540643,\n"," 'Loss/total_loss': 1.7773253,\n"," 'learning_rate': 0.00416}\n","I1203 06:41:00.154599 133410652246656 model_lib_v2.py:708] {'Loss/classification_loss': 1.0876245,\n"," 'Loss/localization_loss': 0.66016006,\n"," 'Loss/regularization_loss': 0.029540643,\n"," 'Loss/total_loss': 1.7773253,\n"," 'learning_rate': 0.00416}\n","INFO:tensorflow:Step 200 per-step time 0.647s\n","I1203 06:42:04.836998 133410652246656 model_lib_v2.py:705] Step 200 per-step time 0.647s\n","INFO:tensorflow:{'Loss/classification_loss': 0.91072965,\n"," 'Loss/localization_loss': 0.5540354,\n"," 'Loss/regularization_loss': 0.029595304,\n"," 'Loss/total_loss': 1.4943603,\n"," 'learning_rate': 0.0073200003}\n","I1203 06:42:04.837422 133410652246656 model_lib_v2.py:708] {'Loss/classification_loss': 0.91072965,\n"," 'Loss/localization_loss': 0.5540354,\n"," 'Loss/regularization_loss': 0.029595304,\n"," 'Loss/total_loss': 1.4943603,\n"," 'learning_rate': 0.0073200003}\n","INFO:tensorflow:Step 300 per-step time 0.642s\n","I1203 06:43:09.016376 133410652246656 model_lib_v2.py:705] Step 300 per-step time 0.642s\n","INFO:tensorflow:{'Loss/classification_loss': 0.77549094,\n"," 'Loss/localization_loss': 0.5094741,\n"," 'Loss/regularization_loss': 0.029703906,\n"," 'Loss/total_loss': 1.3146689,\n"," 'learning_rate': 0.010480001}\n","I1203 06:43:09.016836 133410652246656 model_lib_v2.py:708] {'Loss/classification_loss': 0.77549094,\n"," 'Loss/localization_loss': 0.5094741,\n"," 'Loss/regularization_loss': 0.029703906,\n"," 'Loss/total_loss': 1.3146689,\n"," 'learning_rate': 0.010480001}\n","INFO:tensorflow:Step 400 per-step time 0.644s\n","I1203 06:44:13.458194 133410652246656 model_lib_v2.py:705] Step 400 per-step time 0.644s\n","INFO:tensorflow:{'Loss/classification_loss': 0.662186,\n"," 'Loss/localization_loss': 0.53944933,\n"," 'Loss/regularization_loss': 0.02989046,\n"," 'Loss/total_loss': 1.2315258,\n"," 'learning_rate': 0.0136400005}\n","I1203 06:44:13.458572 133410652246656 model_lib_v2.py:708] {'Loss/classification_loss': 0.662186,\n"," 'Loss/localization_loss': 0.53944933,\n"," 'Loss/regularization_loss': 0.02989046,\n"," 'Loss/total_loss': 1.2315258,\n"," 'learning_rate': 0.0136400005}\n","INFO:tensorflow:Step 500 per-step time 0.644s\n","I1203 06:45:17.884130 133410652246656 model_lib_v2.py:705] Step 500 per-step time 0.644s\n","INFO:tensorflow:{'Loss/classification_loss': 0.67793334,\n"," 'Loss/localization_loss': 0.47479856,\n"," 'Loss/regularization_loss': 0.03010415,\n"," 'Loss/total_loss': 1.182836,\n"," 'learning_rate': 0.016800001}\n","I1203 06:45:17.884619 133410652246656 model_lib_v2.py:708] {'Loss/classification_loss': 0.67793334,\n"," 'Loss/localization_loss': 0.47479856,\n"," 'Loss/regularization_loss': 0.03010415,\n"," 'Loss/total_loss': 1.182836,\n"," 'learning_rate': 0.016800001}\n","INFO:tensorflow:Step 600 per-step time 0.641s\n","I1203 06:46:22.022889 133410652246656 model_lib_v2.py:705] Step 600 per-step time 0.641s\n","INFO:tensorflow:{'Loss/classification_loss': 0.78016526,\n"," 'Loss/localization_loss': 0.52241427,\n"," 'Loss/regularization_loss': 0.030368846,\n"," 'Loss/total_loss': 1.3329483,\n"," 'learning_rate': 0.019960001}\n","I1203 06:46:22.023241 133410652246656 model_lib_v2.py:708] {'Loss/classification_loss': 0.78016526,\n"," 'Loss/localization_loss': 0.52241427,\n"," 'Loss/regularization_loss': 0.030368846,\n"," 'Loss/total_loss': 1.3329483,\n"," 'learning_rate': 0.019960001}\n","INFO:tensorflow:Step 700 per-step time 0.642s\n","I1203 06:47:26.226010 133410652246656 model_lib_v2.py:705] Step 700 per-step time 0.642s\n","INFO:tensorflow:{'Loss/classification_loss': 0.787489,\n"," 'Loss/localization_loss': 0.59006894,\n"," 'Loss/regularization_loss': 0.030662032,\n"," 'Loss/total_loss': 1.40822,\n"," 'learning_rate': 0.023120001}\n","I1203 06:47:26.226380 133410652246656 model_lib_v2.py:708] {'Loss/classification_loss': 0.787489,\n"," 'Loss/localization_loss': 0.59006894,\n"," 'Loss/regularization_loss': 0.030662032,\n"," 'Loss/total_loss': 1.40822,\n"," 'learning_rate': 0.023120001}\n","INFO:tensorflow:Step 800 per-step time 0.646s\n","I1203 06:48:30.808592 133410652246656 model_lib_v2.py:705] Step 800 per-step time 0.646s\n","INFO:tensorflow:{'Loss/classification_loss': 0.63622075,\n"," 'Loss/localization_loss': 0.4049783,\n"," 'Loss/regularization_loss': 0.03096061,\n"," 'Loss/total_loss': 1.0721596,\n"," 'learning_rate': 0.02628}\n","I1203 06:48:30.808995 133410652246656 model_lib_v2.py:708] {'Loss/classification_loss': 0.63622075,\n"," 'Loss/localization_loss': 0.4049783,\n"," 'Loss/regularization_loss': 0.03096061,\n"," 'Loss/total_loss': 1.0721596,\n"," 'learning_rate': 0.02628}\n","INFO:tensorflow:Step 900 per-step time 0.648s\n","I1203 06:49:35.629006 133410652246656 model_lib_v2.py:705] Step 900 per-step time 0.648s\n","INFO:tensorflow:{'Loss/classification_loss': 1.2704375,\n"," 'Loss/localization_loss': 0.47102717,\n"," 'Loss/regularization_loss': 0.03154288,\n"," 'Loss/total_loss': 1.7730075,\n"," 'learning_rate': 0.02944}\n","I1203 06:49:35.629360 133410652246656 model_lib_v2.py:708] {'Loss/classification_loss': 1.2704375,\n"," 'Loss/localization_loss': 0.47102717,\n"," 'Loss/regularization_loss': 0.03154288,\n"," 'Loss/total_loss': 1.7730075,\n"," 'learning_rate': 0.02944}\n","INFO:tensorflow:Step 1000 per-step time 0.646s\n","I1203 06:50:40.258601 133410652246656 model_lib_v2.py:705] Step 1000 per-step time 0.646s\n","INFO:tensorflow:{'Loss/classification_loss': 0.7832764,\n"," 'Loss/localization_loss': 0.37897798,\n"," 'Loss/regularization_loss': 0.031995352,\n"," 'Loss/total_loss': 1.1942496,\n"," 'learning_rate': 0.0326}\n","I1203 06:50:40.258950 133410652246656 model_lib_v2.py:708] {'Loss/classification_loss': 0.7832764,\n"," 'Loss/localization_loss': 0.37897798,\n"," 'Loss/regularization_loss': 0.031995352,\n"," 'Loss/total_loss': 1.1942496,\n"," 'learning_rate': 0.0326}\n","INFO:tensorflow:Step 1100 per-step time 0.653s\n","I1203 06:51:45.564950 133410652246656 model_lib_v2.py:705] Step 1100 per-step time 0.653s\n","INFO:tensorflow:{'Loss/classification_loss': 0.7725334,\n"," 'Loss/localization_loss': 0.4585301,\n"," 'Loss/regularization_loss': 0.03228711,\n"," 'Loss/total_loss': 1.2633506,\n"," 'learning_rate': 0.03576}\n","I1203 06:51:45.565411 133410652246656 model_lib_v2.py:708] {'Loss/classification_loss': 0.7725334,\n"," 'Loss/localization_loss': 0.4585301,\n"," 'Loss/regularization_loss': 0.03228711,\n"," 'Loss/total_loss': 1.2633506,\n"," 'learning_rate': 0.03576}\n","INFO:tensorflow:Step 1200 per-step time 0.641s\n","I1203 06:52:49.690018 133410652246656 model_lib_v2.py:705] Step 1200 per-step time 0.641s\n","INFO:tensorflow:{'Loss/classification_loss': 0.8157065,\n"," 'Loss/localization_loss': 0.45758435,\n"," 'Loss/regularization_loss': 0.032577354,\n"," 'Loss/total_loss': 1.3058683,\n"," 'learning_rate': 0.03892}\n","I1203 06:52:49.690387 133410652246656 model_lib_v2.py:708] {'Loss/classification_loss': 0.8157065,\n"," 'Loss/localization_loss': 0.45758435,\n"," 'Loss/regularization_loss': 0.032577354,\n"," 'Loss/total_loss': 1.3058683,\n"," 'learning_rate': 0.03892}\n","INFO:tensorflow:Step 1300 per-step time 0.643s\n","I1203 06:53:54.034373 133410652246656 model_lib_v2.py:705] Step 1300 per-step time 0.643s\n","INFO:tensorflow:{'Loss/classification_loss': 0.7016282,\n"," 'Loss/localization_loss': 0.47645286,\n"," 'Loss/regularization_loss': 0.03286369,\n"," 'Loss/total_loss': 1.2109448,\n"," 'learning_rate': 0.04208}\n","I1203 06:53:54.034813 133410652246656 model_lib_v2.py:708] {'Loss/classification_loss': 0.7016282,\n"," 'Loss/localization_loss': 0.47645286,\n"," 'Loss/regularization_loss': 0.03286369,\n"," 'Loss/total_loss': 1.2109448,\n"," 'learning_rate': 0.04208}\n","INFO:tensorflow:Step 1400 per-step time 0.648s\n","I1203 06:54:58.831354 133410652246656 model_lib_v2.py:705] Step 1400 per-step time 0.648s\n","INFO:tensorflow:{'Loss/classification_loss': 0.6876752,\n"," 'Loss/localization_loss': 0.40819407,\n"," 'Loss/regularization_loss': 0.03330538,\n"," 'Loss/total_loss': 1.1291747,\n"," 'learning_rate': 0.04524}\n","I1203 06:54:58.831784 133410652246656 model_lib_v2.py:708] {'Loss/classification_loss': 0.6876752,\n"," 'Loss/localization_loss': 0.40819407,\n"," 'Loss/regularization_loss': 0.03330538,\n"," 'Loss/total_loss': 1.1291747,\n"," 'learning_rate': 0.04524}\n","INFO:tensorflow:Step 1500 per-step time 0.647s\n","I1203 06:56:03.497578 133410652246656 model_lib_v2.py:705] Step 1500 per-step time 0.647s\n","INFO:tensorflow:{'Loss/classification_loss': 0.7120596,\n"," 'Loss/localization_loss': 0.41921985,\n"," 'Loss/regularization_loss': 0.03367044,\n"," 'Loss/total_loss': 1.1649499,\n"," 'learning_rate': 0.0484}\n","I1203 06:56:03.497928 133410652246656 model_lib_v2.py:708] {'Loss/classification_loss': 0.7120596,\n"," 'Loss/localization_loss': 0.41921985,\n"," 'Loss/regularization_loss': 0.03367044,\n"," 'Loss/total_loss': 1.1649499,\n"," 'learning_rate': 0.0484}\n","INFO:tensorflow:Step 1600 per-step time 0.646s\n","I1203 06:57:08.063000 133410652246656 model_lib_v2.py:705] Step 1600 per-step time 0.646s\n","INFO:tensorflow:{'Loss/classification_loss': 0.7607359,\n"," 'Loss/localization_loss': 0.60768247,\n"," 'Loss/regularization_loss': 0.03411762,\n"," 'Loss/total_loss': 1.402536,\n"," 'learning_rate': 0.05156}\n","I1203 06:57:08.063357 133410652246656 model_lib_v2.py:708] {'Loss/classification_loss': 0.7607359,\n"," 'Loss/localization_loss': 0.60768247,\n"," 'Loss/regularization_loss': 0.03411762,\n"," 'Loss/total_loss': 1.402536,\n"," 'learning_rate': 0.05156}\n","INFO:tensorflow:Step 1700 per-step time 0.643s\n","I1203 06:58:12.322573 133410652246656 model_lib_v2.py:705] Step 1700 per-step time 0.643s\n","INFO:tensorflow:{'Loss/classification_loss': 0.6192695,\n"," 'Loss/localization_loss': 0.46711197,\n"," 'Loss/regularization_loss': 0.035105795,\n"," 'Loss/total_loss': 1.1214873,\n"," 'learning_rate': 0.05472}\n","I1203 06:58:12.322959 133410652246656 model_lib_v2.py:708] {'Loss/classification_loss': 0.6192695,\n"," 'Loss/localization_loss': 0.46711197,\n"," 'Loss/regularization_loss': 0.035105795,\n"," 'Loss/total_loss': 1.1214873,\n"," 'learning_rate': 0.05472}\n","INFO:tensorflow:Step 1800 per-step time 0.648s\n","I1203 06:59:17.105070 133410652246656 model_lib_v2.py:705] Step 1800 per-step time 0.648s\n","INFO:tensorflow:{'Loss/classification_loss': 0.6519774,\n"," 'Loss/localization_loss': 0.37579343,\n"," 'Loss/regularization_loss': 0.035426512,\n"," 'Loss/total_loss': 1.0631974,\n"," 'learning_rate': 0.05788}\n","I1203 06:59:17.105463 133410652246656 model_lib_v2.py:708] {'Loss/classification_loss': 0.6519774,\n"," 'Loss/localization_loss': 0.37579343,\n"," 'Loss/regularization_loss': 0.035426512,\n"," 'Loss/total_loss': 1.0631974,\n"," 'learning_rate': 0.05788}\n","INFO:tensorflow:Step 1900 per-step time 0.644s\n","I1203 07:00:21.505526 133410652246656 model_lib_v2.py:705] Step 1900 per-step time 0.644s\n","INFO:tensorflow:{'Loss/classification_loss': 1.0730282,\n"," 'Loss/localization_loss': 0.6047321,\n"," 'Loss/regularization_loss': 0.042638637,\n"," 'Loss/total_loss': 1.720399,\n"," 'learning_rate': 0.06104}\n","I1203 07:00:21.505930 133410652246656 model_lib_v2.py:708] {'Loss/classification_loss': 1.0730282,\n"," 'Loss/localization_loss': 0.6047321,\n"," 'Loss/regularization_loss': 0.042638637,\n"," 'Loss/total_loss': 1.720399,\n"," 'learning_rate': 0.06104}\n","INFO:tensorflow:Step 2000 per-step time 0.650s\n","I1203 07:01:26.530932 133410652246656 model_lib_v2.py:705] Step 2000 per-step time 0.650s\n","INFO:tensorflow:{'Loss/classification_loss': 0.93132687,\n"," 'Loss/localization_loss': 0.45463508,\n"," 'Loss/regularization_loss': 0.04432639,\n"," 'Loss/total_loss': 1.4302884,\n"," 'learning_rate': 0.06420001}\n","I1203 07:01:26.531347 133410652246656 model_lib_v2.py:708] {'Loss/classification_loss': 0.93132687,\n"," 'Loss/localization_loss': 0.45463508,\n"," 'Loss/regularization_loss': 0.04432639,\n"," 'Loss/total_loss': 1.4302884,\n"," 'learning_rate': 0.06420001}\n","INFO:tensorflow:Step 2100 per-step time 0.666s\n","I1203 07:02:33.123495 133410652246656 model_lib_v2.py:705] Step 2100 per-step time 0.666s\n","INFO:tensorflow:{'Loss/classification_loss': 0.8202369,\n"," 'Loss/localization_loss': 0.4548359,\n"," 'Loss/regularization_loss': 0.044598516,\n"," 'Loss/total_loss': 1.3196713,\n"," 'learning_rate': 0.067360006}\n","I1203 07:02:33.123921 133410652246656 model_lib_v2.py:708] {'Loss/classification_loss': 0.8202369,\n"," 'Loss/localization_loss': 0.4548359,\n"," 'Loss/regularization_loss': 0.044598516,\n"," 'Loss/total_loss': 1.3196713,\n"," 'learning_rate': 0.067360006}\n","INFO:tensorflow:Step 2200 per-step time 0.644s\n","I1203 07:03:37.506521 133410652246656 model_lib_v2.py:705] Step 2200 per-step time 0.644s\n","INFO:tensorflow:{'Loss/classification_loss': 1.1512989,\n"," 'Loss/localization_loss': 0.56887496,\n"," 'Loss/regularization_loss': 0.046799034,\n"," 'Loss/total_loss': 1.7669729,\n"," 'learning_rate': 0.070520006}\n","I1203 07:03:37.506877 133410652246656 model_lib_v2.py:708] {'Loss/classification_loss': 1.1512989,\n"," 'Loss/localization_loss': 0.56887496,\n"," 'Loss/regularization_loss': 0.046799034,\n"," 'Loss/total_loss': 1.7669729,\n"," 'learning_rate': 0.070520006}\n","INFO:tensorflow:Step 2300 per-step time 0.648s\n","I1203 07:04:42.324745 133410652246656 model_lib_v2.py:705] Step 2300 per-step time 0.648s\n","INFO:tensorflow:{'Loss/classification_loss': 0.9905844,\n"," 'Loss/localization_loss': 0.59076446,\n"," 'Loss/regularization_loss': 0.046866,\n"," 'Loss/total_loss': 1.6282148,\n"," 'learning_rate': 0.073680006}\n","I1203 07:04:42.325086 133410652246656 model_lib_v2.py:708] {'Loss/classification_loss': 0.9905844,\n"," 'Loss/localization_loss': 0.59076446,\n"," 'Loss/regularization_loss': 0.046866,\n"," 'Loss/total_loss': 1.6282148,\n"," 'learning_rate': 0.073680006}\n","INFO:tensorflow:Step 2400 per-step time 0.650s\n","I1203 07:05:47.375255 133410652246656 model_lib_v2.py:705] Step 2400 per-step time 0.650s\n","INFO:tensorflow:{'Loss/classification_loss': 1.035102,\n"," 'Loss/localization_loss': 0.6401468,\n"," 'Loss/regularization_loss': 0.046833932,\n"," 'Loss/total_loss': 1.7220829,\n"," 'learning_rate': 0.076840006}\n","I1203 07:05:47.375681 133410652246656 model_lib_v2.py:708] {'Loss/classification_loss': 1.035102,\n"," 'Loss/localization_loss': 0.6401468,\n"," 'Loss/regularization_loss': 0.046833932,\n"," 'Loss/total_loss': 1.7220829,\n"," 'learning_rate': 0.076840006}\n","INFO:tensorflow:Step 2500 per-step time 0.645s\n","I1203 07:06:51.890849 133410652246656 model_lib_v2.py:705] Step 2500 per-step time 0.645s\n","INFO:tensorflow:{'Loss/classification_loss': 0.83442307,\n"," 'Loss/localization_loss': 0.38178337,\n"," 'Loss/regularization_loss': 0.046825267,\n"," 'Loss/total_loss': 1.2630317,\n"," 'learning_rate': 0.08}\n","I1203 07:06:51.891207 133410652246656 model_lib_v2.py:708] {'Loss/classification_loss': 0.83442307,\n"," 'Loss/localization_loss': 0.38178337,\n"," 'Loss/regularization_loss': 0.046825267,\n"," 'Loss/total_loss': 1.2630317,\n"," 'learning_rate': 0.08}\n","INFO:tensorflow:Step 2600 per-step time 0.646s\n","I1203 07:07:56.488324 133410652246656 model_lib_v2.py:705] Step 2600 per-step time 0.646s\n","INFO:tensorflow:{'Loss/classification_loss': 1.0435778,\n"," 'Loss/localization_loss': 0.47517505,\n"," 'Loss/regularization_loss': 0.046843216,\n"," 'Loss/total_loss': 1.565596,\n"," 'learning_rate': 0.079999976}\n","I1203 07:07:56.488706 133410652246656 model_lib_v2.py:708] {'Loss/classification_loss': 1.0435778,\n"," 'Loss/localization_loss': 0.47517505,\n"," 'Loss/regularization_loss': 0.046843216,\n"," 'Loss/total_loss': 1.565596,\n"," 'learning_rate': 0.079999976}\n","INFO:tensorflow:Step 2700 per-step time 0.647s\n","I1203 07:09:01.235049 133410652246656 model_lib_v2.py:705] Step 2700 per-step time 0.647s\n","INFO:tensorflow:{'Loss/classification_loss': 0.7001844,\n"," 'Loss/localization_loss': 0.54665023,\n"," 'Loss/regularization_loss': 0.046876468,\n"," 'Loss/total_loss': 1.2937111,\n"," 'learning_rate': 0.07999991}\n","I1203 07:09:01.235517 133410652246656 model_lib_v2.py:708] {'Loss/classification_loss': 0.7001844,\n"," 'Loss/localization_loss': 0.54665023,\n"," 'Loss/regularization_loss': 0.046876468,\n"," 'Loss/total_loss': 1.2937111,\n"," 'learning_rate': 0.07999991}\n","INFO:tensorflow:Step 2800 per-step time 0.649s\n","I1203 07:10:06.148341 133410652246656 model_lib_v2.py:705] Step 2800 per-step time 0.649s\n","INFO:tensorflow:{'Loss/classification_loss': 0.97513103,\n"," 'Loss/localization_loss': 0.43156615,\n"," 'Loss/regularization_loss': 0.046938106,\n"," 'Loss/total_loss': 1.4536352,\n"," 'learning_rate': 0.0799998}\n","I1203 07:10:06.148705 133410652246656 model_lib_v2.py:708] {'Loss/classification_loss': 0.97513103,\n"," 'Loss/localization_loss': 0.43156615,\n"," 'Loss/regularization_loss': 0.046938106,\n"," 'Loss/total_loss': 1.4536352,\n"," 'learning_rate': 0.0799998}\n","INFO:tensorflow:Step 2900 per-step time 0.647s\n","I1203 07:11:10.886676 133410652246656 model_lib_v2.py:705] Step 2900 per-step time 0.647s\n","INFO:tensorflow:{'Loss/classification_loss': 1.0317111,\n"," 'Loss/localization_loss': 0.58297896,\n"," 'Loss/regularization_loss': 0.046953008,\n"," 'Loss/total_loss': 1.661643,\n"," 'learning_rate': 0.07999964}\n","I1203 07:11:10.887027 133410652246656 model_lib_v2.py:708] {'Loss/classification_loss': 1.0317111,\n"," 'Loss/localization_loss': 0.58297896,\n"," 'Loss/regularization_loss': 0.046953008,\n"," 'Loss/total_loss': 1.661643,\n"," 'learning_rate': 0.07999964}\n","INFO:tensorflow:Step 3000 per-step time 0.644s\n","I1203 07:12:15.282785 133410652246656 model_lib_v2.py:705] Step 3000 per-step time 0.644s\n","INFO:tensorflow:{'Loss/classification_loss': 0.67539734,\n"," 'Loss/localization_loss': 0.40901706,\n"," 'Loss/regularization_loss': 0.047078595,\n"," 'Loss/total_loss': 1.131493,\n"," 'learning_rate': 0.07999944}\n","I1203 07:12:15.283155 133410652246656 model_lib_v2.py:708] {'Loss/classification_loss': 0.67539734,\n"," 'Loss/localization_loss': 0.40901706,\n"," 'Loss/regularization_loss': 0.047078595,\n"," 'Loss/total_loss': 1.131493,\n"," 'learning_rate': 0.07999944}\n","INFO:tensorflow:Step 3100 per-step time 0.657s\n","I1203 07:13:21.007497 133410652246656 model_lib_v2.py:705] Step 3100 per-step time 0.657s\n","INFO:tensorflow:{'Loss/classification_loss': 0.9238914,\n"," 'Loss/localization_loss': 0.49464887,\n"," 'Loss/regularization_loss': 0.047104225,\n"," 'Loss/total_loss': 1.4656445,\n"," 'learning_rate': 0.07999919}\n","I1203 07:13:21.007945 133410652246656 model_lib_v2.py:708] {'Loss/classification_loss': 0.9238914,\n"," 'Loss/localization_loss': 0.49464887,\n"," 'Loss/regularization_loss': 0.047104225,\n"," 'Loss/total_loss': 1.4656445,\n"," 'learning_rate': 0.07999919}\n","INFO:tensorflow:Step 3200 per-step time 0.646s\n","I1203 07:14:25.632807 133410652246656 model_lib_v2.py:705] Step 3200 per-step time 0.646s\n","INFO:tensorflow:{'Loss/classification_loss': 0.76101947,\n"," 'Loss/localization_loss': 0.5308018,\n"," 'Loss/regularization_loss': 0.04712023,\n"," 'Loss/total_loss': 1.3389415,\n"," 'learning_rate': 0.0799989}\n","I1203 07:14:25.633168 133410652246656 model_lib_v2.py:708] {'Loss/classification_loss': 0.76101947,\n"," 'Loss/localization_loss': 0.5308018,\n"," 'Loss/regularization_loss': 0.04712023,\n"," 'Loss/total_loss': 1.3389415,\n"," 'learning_rate': 0.0799989}\n","INFO:tensorflow:Step 3300 per-step time 0.642s\n","I1203 07:15:29.848738 133410652246656 model_lib_v2.py:705] Step 3300 per-step time 0.642s\n","INFO:tensorflow:{'Loss/classification_loss': 0.78459334,\n"," 'Loss/localization_loss': 0.57626235,\n"," 'Loss/regularization_loss': 0.04715245,\n"," 'Loss/total_loss': 1.4080081,\n"," 'learning_rate': 0.07999857}\n","I1203 07:15:29.849098 133410652246656 model_lib_v2.py:708] {'Loss/classification_loss': 0.78459334,\n"," 'Loss/localization_loss': 0.57626235,\n"," 'Loss/regularization_loss': 0.04715245,\n"," 'Loss/total_loss': 1.4080081,\n"," 'learning_rate': 0.07999857}\n","INFO:tensorflow:Step 3400 per-step time 0.646s\n","I1203 07:16:34.431857 133410652246656 model_lib_v2.py:705] Step 3400 per-step time 0.646s\n","INFO:tensorflow:{'Loss/classification_loss': 0.7107325,\n"," 'Loss/localization_loss': 0.53643364,\n"," 'Loss/regularization_loss': 0.047230564,\n"," 'Loss/total_loss': 1.2943968,\n"," 'learning_rate': 0.07999819}\n","I1203 07:16:34.432206 133410652246656 model_lib_v2.py:708] {'Loss/classification_loss': 0.7107325,\n"," 'Loss/localization_loss': 0.53643364,\n"," 'Loss/regularization_loss': 0.047230564,\n"," 'Loss/total_loss': 1.2943968,\n"," 'learning_rate': 0.07999819}\n","INFO:tensorflow:Step 3500 per-step time 0.641s\n","I1203 07:17:38.530883 133410652246656 model_lib_v2.py:705] Step 3500 per-step time 0.641s\n","INFO:tensorflow:{'Loss/classification_loss': 0.6774014,\n"," 'Loss/localization_loss': 0.5458976,\n"," 'Loss/regularization_loss': 0.047268577,\n"," 'Loss/total_loss': 1.2705677,\n"," 'learning_rate': 0.07999776}\n","I1203 07:17:38.531313 133410652246656 model_lib_v2.py:708] {'Loss/classification_loss': 0.6774014,\n"," 'Loss/localization_loss': 0.5458976,\n"," 'Loss/regularization_loss': 0.047268577,\n"," 'Loss/total_loss': 1.2705677,\n"," 'learning_rate': 0.07999776}\n","INFO:tensorflow:Step 3600 per-step time 0.644s\n","I1203 07:18:42.968457 133410652246656 model_lib_v2.py:705] Step 3600 per-step time 0.644s\n","INFO:tensorflow:{'Loss/classification_loss': 0.9068023,\n"," 'Loss/localization_loss': 0.46390513,\n"," 'Loss/regularization_loss': 0.047307976,\n"," 'Loss/total_loss': 1.4180154,\n"," 'learning_rate': 0.0799973}\n","I1203 07:18:42.968848 133410652246656 model_lib_v2.py:708] {'Loss/classification_loss': 0.9068023,\n"," 'Loss/localization_loss': 0.46390513,\n"," 'Loss/regularization_loss': 0.047307976,\n"," 'Loss/total_loss': 1.4180154,\n"," 'learning_rate': 0.0799973}\n","INFO:tensorflow:Step 3700 per-step time 0.644s\n","I1203 07:19:47.382323 133410652246656 model_lib_v2.py:705] Step 3700 per-step time 0.644s\n","INFO:tensorflow:{'Loss/classification_loss': 0.7162354,\n"," 'Loss/localization_loss': 0.42856035,\n"," 'Loss/regularization_loss': 0.047327843,\n"," 'Loss/total_loss': 1.1921237,\n"," 'learning_rate': 0.07999679}\n","I1203 07:19:47.382695 133410652246656 model_lib_v2.py:708] {'Loss/classification_loss': 0.7162354,\n"," 'Loss/localization_loss': 0.42856035,\n"," 'Loss/regularization_loss': 0.047327843,\n"," 'Loss/total_loss': 1.1921237,\n"," 'learning_rate': 0.07999679}\n","INFO:tensorflow:Step 3800 per-step time 0.639s\n","I1203 07:20:51.327734 133410652246656 model_lib_v2.py:705] Step 3800 per-step time 0.639s\n","INFO:tensorflow:{'Loss/classification_loss': nan,\n"," 'Loss/localization_loss': nan,\n"," 'Loss/regularization_loss': nan,\n"," 'Loss/total_loss': nan,\n"," 'learning_rate': 0.07999623}\n","I1203 07:20:51.328189 133410652246656 model_lib_v2.py:708] {'Loss/classification_loss': nan,\n"," 'Loss/localization_loss': nan,\n"," 'Loss/regularization_loss': nan,\n"," 'Loss/total_loss': nan,\n"," 'learning_rate': 0.07999623}\n","INFO:tensorflow:Step 3900 per-step time 0.620s\n","I1203 07:21:53.285255 133410652246656 model_lib_v2.py:705] Step 3900 per-step time 0.620s\n","INFO:tensorflow:{'Loss/classification_loss': nan,\n"," 'Loss/localization_loss': nan,\n"," 'Loss/regularization_loss': nan,\n"," 'Loss/total_loss': nan,\n"," 'learning_rate': 0.07999563}\n","I1203 07:21:53.285602 133410652246656 model_lib_v2.py:708] {'Loss/classification_loss': nan,\n"," 'Loss/localization_loss': nan,\n"," 'Loss/regularization_loss': nan,\n"," 'Loss/total_loss': nan,\n"," 'learning_rate': 0.07999563}\n","INFO:tensorflow:Step 4000 per-step time 0.619s\n","I1203 07:22:55.203755 133410652246656 model_lib_v2.py:705] Step 4000 per-step time 0.619s\n","INFO:tensorflow:{'Loss/classification_loss': nan,\n"," 'Loss/localization_loss': nan,\n"," 'Loss/regularization_loss': nan,\n"," 'Loss/total_loss': nan,\n"," 'learning_rate': 0.079994984}\n","I1203 07:22:55.204103 133410652246656 model_lib_v2.py:708] {'Loss/classification_loss': nan,\n"," 'Loss/localization_loss': nan,\n"," 'Loss/regularization_loss': nan,\n"," 'Loss/total_loss': nan,\n"," 'learning_rate': 0.079994984}\n","INFO:tensorflow:Step 4100 per-step time 0.636s\n","I1203 07:23:58.845821 133410652246656 model_lib_v2.py:705] Step 4100 per-step time 0.636s\n","INFO:tensorflow:{'Loss/classification_loss': nan,\n"," 'Loss/localization_loss': nan,\n"," 'Loss/regularization_loss': nan,\n"," 'Loss/total_loss': nan,\n"," 'learning_rate': 0.07999428}\n","I1203 07:23:58.846164 133410652246656 model_lib_v2.py:708] {'Loss/classification_loss': nan,\n"," 'Loss/localization_loss': nan,\n"," 'Loss/regularization_loss': nan,\n"," 'Loss/total_loss': nan,\n"," 'learning_rate': 0.07999428}\n","INFO:tensorflow:Step 4200 per-step time 0.619s\n","I1203 07:25:00.767901 133410652246656 model_lib_v2.py:705] Step 4200 per-step time 0.619s\n","INFO:tensorflow:{'Loss/classification_loss': nan,\n"," 'Loss/localization_loss': nan,\n"," 'Loss/regularization_loss': nan,\n"," 'Loss/total_loss': nan,\n"," 'learning_rate': 0.07999355}\n","I1203 07:25:00.768303 133410652246656 model_lib_v2.py:708] {'Loss/classification_loss': nan,\n"," 'Loss/localization_loss': nan,\n"," 'Loss/regularization_loss': nan,\n"," 'Loss/total_loss': nan,\n"," 'learning_rate': 0.07999355}\n","INFO:tensorflow:Step 4300 per-step time 0.623s\n","I1203 07:26:03.025492 133410652246656 model_lib_v2.py:705] Step 4300 per-step time 0.623s\n","INFO:tensorflow:{'Loss/classification_loss': nan,\n"," 'Loss/localization_loss': nan,\n"," 'Loss/regularization_loss': nan,\n"," 'Loss/total_loss': nan,\n"," 'learning_rate': 0.07999277}\n","I1203 07:26:03.025823 133410652246656 model_lib_v2.py:708] {'Loss/classification_loss': nan,\n"," 'Loss/localization_loss': nan,\n"," 'Loss/regularization_loss': nan,\n"," 'Loss/total_loss': nan,\n"," 'learning_rate': 0.07999277}\n","INFO:tensorflow:Step 4400 per-step time 0.619s\n","I1203 07:27:04.979580 133410652246656 model_lib_v2.py:705] Step 4400 per-step time 0.619s\n","INFO:tensorflow:{'Loss/classification_loss': nan,\n"," 'Loss/localization_loss': nan,\n"," 'Loss/regularization_loss': nan,\n"," 'Loss/total_loss': nan,\n"," 'learning_rate': 0.07999195}\n","I1203 07:27:04.979921 133410652246656 model_lib_v2.py:708] {'Loss/classification_loss': nan,\n"," 'Loss/localization_loss': nan,\n"," 'Loss/regularization_loss': nan,\n"," 'Loss/total_loss': nan,\n"," 'learning_rate': 0.07999195}\n","INFO:tensorflow:Step 4500 per-step time 0.619s\n","I1203 07:28:06.919679 133410652246656 model_lib_v2.py:705] Step 4500 per-step time 0.619s\n","INFO:tensorflow:{'Loss/classification_loss': nan,\n"," 'Loss/localization_loss': nan,\n"," 'Loss/regularization_loss': nan,\n"," 'Loss/total_loss': nan,\n"," 'learning_rate': 0.07999108}\n","I1203 07:28:06.920065 133410652246656 model_lib_v2.py:708] {'Loss/classification_loss': nan,\n"," 'Loss/localization_loss': nan,\n"," 'Loss/regularization_loss': nan,\n"," 'Loss/total_loss': nan,\n"," 'learning_rate': 0.07999108}\n","INFO:tensorflow:Step 4600 per-step time 0.621s\n","I1203 07:29:09.033508 133410652246656 model_lib_v2.py:705] Step 4600 per-step time 0.621s\n","INFO:tensorflow:{'Loss/classification_loss': nan,\n"," 'Loss/localization_loss': nan,\n"," 'Loss/regularization_loss': nan,\n"," 'Loss/total_loss': nan,\n"," 'learning_rate': 0.07999016}\n","I1203 07:29:09.033866 133410652246656 model_lib_v2.py:708] {'Loss/classification_loss': nan,\n"," 'Loss/localization_loss': nan,\n"," 'Loss/regularization_loss': nan,\n"," 'Loss/total_loss': nan,\n"," 'learning_rate': 0.07999016}\n","INFO:tensorflow:Step 4700 per-step time 0.621s\n","I1203 07:30:11.118364 133410652246656 model_lib_v2.py:705] Step 4700 per-step time 0.621s\n","INFO:tensorflow:{'Loss/classification_loss': nan,\n"," 'Loss/localization_loss': nan,\n"," 'Loss/regularization_loss': nan,\n"," 'Loss/total_loss': nan,\n"," 'learning_rate': 0.0799892}\n","I1203 07:30:11.118790 133410652246656 model_lib_v2.py:708] {'Loss/classification_loss': nan,\n"," 'Loss/localization_loss': nan,\n"," 'Loss/regularization_loss': nan,\n"," 'Loss/total_loss': nan,\n"," 'learning_rate': 0.0799892}\n","INFO:tensorflow:Step 4800 per-step time 0.622s\n","I1203 07:31:13.349636 133410652246656 model_lib_v2.py:705] Step 4800 per-step time 0.622s\n","INFO:tensorflow:{'Loss/classification_loss': nan,\n"," 'Loss/localization_loss': nan,\n"," 'Loss/regularization_loss': nan,\n"," 'Loss/total_loss': nan,\n"," 'learning_rate': 0.079988204}\n","I1203 07:31:13.350065 133410652246656 model_lib_v2.py:708] {'Loss/classification_loss': nan,\n"," 'Loss/localization_loss': nan,\n"," 'Loss/regularization_loss': nan,\n"," 'Loss/total_loss': nan,\n"," 'learning_rate': 0.079988204}\n","INFO:tensorflow:Step 4900 per-step time 0.626s\n","I1203 07:32:15.987624 133410652246656 model_lib_v2.py:705] Step 4900 per-step time 0.626s\n","INFO:tensorflow:{'Loss/classification_loss': nan,\n"," 'Loss/localization_loss': nan,\n"," 'Loss/regularization_loss': nan,\n"," 'Loss/total_loss': nan,\n"," 'learning_rate': 0.07998715}\n","I1203 07:32:15.988050 133410652246656 model_lib_v2.py:708] {'Loss/classification_loss': nan,\n"," 'Loss/localization_loss': nan,\n"," 'Loss/regularization_loss': nan,\n"," 'Loss/total_loss': nan,\n"," 'learning_rate': 0.07998715}\n","INFO:tensorflow:Step 5000 per-step time 0.627s\n","I1203 07:33:18.712680 133410652246656 model_lib_v2.py:705] Step 5000 per-step time 0.627s\n","INFO:tensorflow:{'Loss/classification_loss': nan,\n"," 'Loss/localization_loss': nan,\n"," 'Loss/regularization_loss': nan,\n"," 'Loss/total_loss': nan,\n"," 'learning_rate': 0.07998606}\n","I1203 07:33:18.713042 133410652246656 model_lib_v2.py:708] {'Loss/classification_loss': nan,\n"," 'Loss/localization_loss': nan,\n"," 'Loss/regularization_loss': nan,\n"," 'Loss/total_loss': nan,\n"," 'learning_rate': 0.07998606}\n","INFO:tensorflow:Step 5100 per-step time 0.642s\n","I1203 07:34:22.902181 133410652246656 model_lib_v2.py:705] Step 5100 per-step time 0.642s\n","INFO:tensorflow:{'Loss/classification_loss': nan,\n"," 'Loss/localization_loss': nan,\n"," 'Loss/regularization_loss': nan,\n"," 'Loss/total_loss': nan,\n"," 'learning_rate': 0.07998492}\n","I1203 07:34:22.902527 133410652246656 model_lib_v2.py:708] {'Loss/classification_loss': nan,\n"," 'Loss/localization_loss': nan,\n"," 'Loss/regularization_loss': nan,\n"," 'Loss/total_loss': nan,\n"," 'learning_rate': 0.07998492}\n","INFO:tensorflow:Step 5200 per-step time 0.616s\n","I1203 07:35:24.510931 133410652246656 model_lib_v2.py:705] Step 5200 per-step time 0.616s\n","INFO:tensorflow:{'Loss/classification_loss': nan,\n"," 'Loss/localization_loss': nan,\n"," 'Loss/regularization_loss': nan,\n"," 'Loss/total_loss': nan,\n"," 'learning_rate': 0.07998374}\n","I1203 07:35:24.511274 133410652246656 model_lib_v2.py:708] {'Loss/classification_loss': nan,\n"," 'Loss/localization_loss': nan,\n"," 'Loss/regularization_loss': nan,\n"," 'Loss/total_loss': nan,\n"," 'learning_rate': 0.07998374}\n","INFO:tensorflow:Step 5300 per-step time 0.616s\n","I1203 07:36:26.080217 133410652246656 model_lib_v2.py:705] Step 5300 per-step time 0.616s\n","INFO:tensorflow:{'Loss/classification_loss': nan,\n"," 'Loss/localization_loss': nan,\n"," 'Loss/regularization_loss': nan,\n"," 'Loss/total_loss': nan,\n"," 'learning_rate': 0.07998252}\n","I1203 07:36:26.080633 133410652246656 model_lib_v2.py:708] {'Loss/classification_loss': nan,\n"," 'Loss/localization_loss': nan,\n"," 'Loss/regularization_loss': nan,\n"," 'Loss/total_loss': nan,\n"," 'learning_rate': 0.07998252}\n","INFO:tensorflow:Step 5400 per-step time 0.620s\n","I1203 07:37:28.104490 133410652246656 model_lib_v2.py:705] Step 5400 per-step time 0.620s\n","INFO:tensorflow:{'Loss/classification_loss': nan,\n"," 'Loss/localization_loss': nan,\n"," 'Loss/regularization_loss': nan,\n"," 'Loss/total_loss': nan,\n"," 'learning_rate': 0.079981245}\n","I1203 07:37:28.104901 133410652246656 model_lib_v2.py:708] {'Loss/classification_loss': nan,\n"," 'Loss/localization_loss': nan,\n"," 'Loss/regularization_loss': nan,\n"," 'Loss/total_loss': nan,\n"," 'learning_rate': 0.079981245}\n","INFO:tensorflow:Step 5500 per-step time 0.627s\n","I1203 07:38:30.828088 133410652246656 model_lib_v2.py:705] Step 5500 per-step time 0.627s\n","INFO:tensorflow:{'Loss/classification_loss': nan,\n"," 'Loss/localization_loss': nan,\n"," 'Loss/regularization_loss': nan,\n"," 'Loss/total_loss': nan,\n"," 'learning_rate': 0.07997993}\n","I1203 07:38:30.828421 133410652246656 model_lib_v2.py:708] {'Loss/classification_loss': nan,\n"," 'Loss/localization_loss': nan,\n"," 'Loss/regularization_loss': nan,\n"," 'Loss/total_loss': nan,\n"," 'learning_rate': 0.07997993}\n","INFO:tensorflow:Step 5600 per-step time 0.620s\n","I1203 07:39:32.821263 133410652246656 model_lib_v2.py:705] Step 5600 per-step time 0.620s\n","INFO:tensorflow:{'Loss/classification_loss': nan,\n"," 'Loss/localization_loss': nan,\n"," 'Loss/regularization_loss': nan,\n"," 'Loss/total_loss': nan,\n"," 'learning_rate': 0.07997857}\n","I1203 07:39:32.821652 133410652246656 model_lib_v2.py:708] {'Loss/classification_loss': nan,\n"," 'Loss/localization_loss': nan,\n"," 'Loss/regularization_loss': nan,\n"," 'Loss/total_loss': nan,\n"," 'learning_rate': 0.07997857}\n","INFO:tensorflow:Step 5700 per-step time 0.620s\n","I1203 07:40:34.772448 133410652246656 model_lib_v2.py:705] Step 5700 per-step time 0.620s\n","INFO:tensorflow:{'Loss/classification_loss': nan,\n"," 'Loss/localization_loss': nan,\n"," 'Loss/regularization_loss': nan,\n"," 'Loss/total_loss': nan,\n"," 'learning_rate': 0.07997716}\n","I1203 07:40:34.772812 133410652246656 model_lib_v2.py:708] {'Loss/classification_loss': nan,\n"," 'Loss/localization_loss': nan,\n"," 'Loss/regularization_loss': nan,\n"," 'Loss/total_loss': nan,\n"," 'learning_rate': 0.07997716}\n","INFO:tensorflow:Step 5800 per-step time 0.618s\n","I1203 07:41:36.579674 133410652246656 model_lib_v2.py:705] Step 5800 per-step time 0.618s\n","INFO:tensorflow:{'Loss/classification_loss': nan,\n"," 'Loss/localization_loss': nan,\n"," 'Loss/regularization_loss': nan,\n"," 'Loss/total_loss': nan,\n"," 'learning_rate': 0.07997571}\n","I1203 07:41:36.580022 133410652246656 model_lib_v2.py:708] {'Loss/classification_loss': nan,\n"," 'Loss/localization_loss': nan,\n"," 'Loss/regularization_loss': nan,\n"," 'Loss/total_loss': nan,\n"," 'learning_rate': 0.07997571}\n","INFO:tensorflow:Step 5900 per-step time 0.622s\n","I1203 07:42:38.756202 133410652246656 model_lib_v2.py:705] Step 5900 per-step time 0.622s\n","INFO:tensorflow:{'Loss/classification_loss': nan,\n"," 'Loss/localization_loss': nan,\n"," 'Loss/regularization_loss': nan,\n"," 'Loss/total_loss': nan,\n"," 'learning_rate': 0.07997422}\n","I1203 07:42:38.756572 133410652246656 model_lib_v2.py:708] {'Loss/classification_loss': nan,\n"," 'Loss/localization_loss': nan,\n"," 'Loss/regularization_loss': nan,\n"," 'Loss/total_loss': nan,\n"," 'learning_rate': 0.07997422}\n","INFO:tensorflow:Step 6000 per-step time 0.622s\n","I1203 07:43:40.916498 133410652246656 model_lib_v2.py:705] Step 6000 per-step time 0.622s\n","INFO:tensorflow:{'Loss/classification_loss': nan,\n"," 'Loss/localization_loss': nan,\n"," 'Loss/regularization_loss': nan,\n"," 'Loss/total_loss': nan,\n"," 'learning_rate': 0.07997268}\n","I1203 07:43:40.916916 133410652246656 model_lib_v2.py:708] {'Loss/classification_loss': nan,\n"," 'Loss/localization_loss': nan,\n"," 'Loss/regularization_loss': nan,\n"," 'Loss/total_loss': nan,\n"," 'learning_rate': 0.07997268}\n","INFO:tensorflow:Step 6100 per-step time 0.641s\n","I1203 07:44:44.998553 133410652246656 model_lib_v2.py:705] Step 6100 per-step time 0.641s\n","INFO:tensorflow:{'Loss/classification_loss': nan,\n"," 'Loss/localization_loss': nan,\n"," 'Loss/regularization_loss': nan,\n"," 'Loss/total_loss': nan,\n"," 'learning_rate': 0.0799711}\n","I1203 07:44:44.998969 133410652246656 model_lib_v2.py:708] {'Loss/classification_loss': nan,\n"," 'Loss/localization_loss': nan,\n"," 'Loss/regularization_loss': nan,\n"," 'Loss/total_loss': nan,\n"," 'learning_rate': 0.0799711}\n","INFO:tensorflow:Step 6200 per-step time 0.618s\n","I1203 07:45:46.792651 133410652246656 model_lib_v2.py:705] Step 6200 per-step time 0.618s\n","INFO:tensorflow:{'Loss/classification_loss': nan,\n"," 'Loss/localization_loss': nan,\n"," 'Loss/regularization_loss': nan,\n"," 'Loss/total_loss': nan,\n"," 'learning_rate': 0.07996947}\n","I1203 07:45:46.792977 133410652246656 model_lib_v2.py:708] {'Loss/classification_loss': nan,\n"," 'Loss/localization_loss': nan,\n"," 'Loss/regularization_loss': nan,\n"," 'Loss/total_loss': nan,\n"," 'learning_rate': 0.07996947}\n","INFO:tensorflow:Step 6300 per-step time 0.617s\n","I1203 07:46:48.472905 133410652246656 model_lib_v2.py:705] Step 6300 per-step time 0.617s\n","INFO:tensorflow:{'Loss/classification_loss': nan,\n"," 'Loss/localization_loss': nan,\n"," 'Loss/regularization_loss': nan,\n"," 'Loss/total_loss': nan,\n"," 'learning_rate': 0.0799678}\n","I1203 07:46:48.473243 133410652246656 model_lib_v2.py:708] {'Loss/classification_loss': nan,\n"," 'Loss/localization_loss': nan,\n"," 'Loss/regularization_loss': nan,\n"," 'Loss/total_loss': nan,\n"," 'learning_rate': 0.0799678}\n","INFO:tensorflow:Step 6400 per-step time 0.622s\n","I1203 07:47:50.655027 133410652246656 model_lib_v2.py:705] Step 6400 per-step time 0.622s\n","INFO:tensorflow:{'Loss/classification_loss': nan,\n"," 'Loss/localization_loss': nan,\n"," 'Loss/regularization_loss': nan,\n"," 'Loss/total_loss': nan,\n"," 'learning_rate': 0.07996608}\n","I1203 07:47:50.655344 133410652246656 model_lib_v2.py:708] {'Loss/classification_loss': nan,\n"," 'Loss/localization_loss': nan,\n"," 'Loss/regularization_loss': nan,\n"," 'Loss/total_loss': nan,\n"," 'learning_rate': 0.07996608}\n","INFO:tensorflow:Step 6500 per-step time 0.618s\n","I1203 07:48:52.510279 133410652246656 model_lib_v2.py:705] Step 6500 per-step time 0.618s\n","INFO:tensorflow:{'Loss/classification_loss': nan,\n"," 'Loss/localization_loss': nan,\n"," 'Loss/regularization_loss': nan,\n"," 'Loss/total_loss': nan,\n"," 'learning_rate': 0.079964325}\n","I1203 07:48:52.510637 133410652246656 model_lib_v2.py:708] {'Loss/classification_loss': nan,\n"," 'Loss/localization_loss': nan,\n"," 'Loss/regularization_loss': nan,\n"," 'Loss/total_loss': nan,\n"," 'learning_rate': 0.079964325}\n","INFO:tensorflow:Step 6600 per-step time 0.625s\n","I1203 07:49:54.958375 133410652246656 model_lib_v2.py:705] Step 6600 per-step time 0.625s\n","INFO:tensorflow:{'Loss/classification_loss': nan,\n"," 'Loss/localization_loss': nan,\n"," 'Loss/regularization_loss': nan,\n"," 'Loss/total_loss': nan,\n"," 'learning_rate': 0.079962514}\n","I1203 07:49:54.958751 133410652246656 model_lib_v2.py:708] {'Loss/classification_loss': nan,\n"," 'Loss/localization_loss': nan,\n"," 'Loss/regularization_loss': nan,\n"," 'Loss/total_loss': nan,\n"," 'learning_rate': 0.079962514}\n","INFO:tensorflow:Step 6700 per-step time 0.623s\n","I1203 07:50:57.236711 133410652246656 model_lib_v2.py:705] Step 6700 per-step time 0.623s\n","INFO:tensorflow:{'Loss/classification_loss': nan,\n"," 'Loss/localization_loss': nan,\n"," 'Loss/regularization_loss': nan,\n"," 'Loss/total_loss': nan,\n"," 'learning_rate': 0.07996067}\n","I1203 07:50:57.237057 133410652246656 model_lib_v2.py:708] {'Loss/classification_loss': nan,\n"," 'Loss/localization_loss': nan,\n"," 'Loss/regularization_loss': nan,\n"," 'Loss/total_loss': nan,\n"," 'learning_rate': 0.07996067}\n","INFO:tensorflow:Step 6800 per-step time 0.622s\n","I1203 07:51:59.400317 133410652246656 model_lib_v2.py:705] Step 6800 per-step time 0.622s\n","INFO:tensorflow:{'Loss/classification_loss': nan,\n"," 'Loss/localization_loss': nan,\n"," 'Loss/regularization_loss': nan,\n"," 'Loss/total_loss': nan,\n"," 'learning_rate': 0.079958774}\n","I1203 07:51:59.400654 133410652246656 model_lib_v2.py:708] {'Loss/classification_loss': nan,\n"," 'Loss/localization_loss': nan,\n"," 'Loss/regularization_loss': nan,\n"," 'Loss/total_loss': nan,\n"," 'learning_rate': 0.079958774}\n","INFO:tensorflow:Step 6900 per-step time 0.620s\n","I1203 07:53:01.377469 133410652246656 model_lib_v2.py:705] Step 6900 per-step time 0.620s\n","INFO:tensorflow:{'Loss/classification_loss': nan,\n"," 'Loss/localization_loss': nan,\n"," 'Loss/regularization_loss': nan,\n"," 'Loss/total_loss': nan,\n"," 'learning_rate': 0.07995682}\n","I1203 07:53:01.377812 133410652246656 model_lib_v2.py:708] {'Loss/classification_loss': nan,\n"," 'Loss/localization_loss': nan,\n"," 'Loss/regularization_loss': nan,\n"," 'Loss/total_loss': nan,\n"," 'learning_rate': 0.07995682}\n","INFO:tensorflow:Step 7000 per-step time 0.620s\n","I1203 07:54:03.373837 133410652246656 model_lib_v2.py:705] Step 7000 per-step time 0.620s\n","INFO:tensorflow:{'Loss/classification_loss': nan,\n"," 'Loss/localization_loss': nan,\n"," 'Loss/regularization_loss': nan,\n"," 'Loss/total_loss': nan,\n"," 'learning_rate': 0.07995484}\n","I1203 07:54:03.374155 133410652246656 model_lib_v2.py:708] {'Loss/classification_loss': nan,\n"," 'Loss/localization_loss': nan,\n"," 'Loss/regularization_loss': nan,\n"," 'Loss/total_loss': nan,\n"," 'learning_rate': 0.07995484}\n","INFO:tensorflow:Step 7100 per-step time 0.632s\n","I1203 07:55:06.632326 133410652246656 model_lib_v2.py:705] Step 7100 per-step time 0.632s\n","INFO:tensorflow:{'Loss/classification_loss': nan,\n"," 'Loss/localization_loss': nan,\n"," 'Loss/regularization_loss': nan,\n"," 'Loss/total_loss': nan,\n"," 'learning_rate': 0.07995281}\n","I1203 07:55:06.632780 133410652246656 model_lib_v2.py:708] {'Loss/classification_loss': nan,\n"," 'Loss/localization_loss': nan,\n"," 'Loss/regularization_loss': nan,\n"," 'Loss/total_loss': nan,\n"," 'learning_rate': 0.07995281}\n","INFO:tensorflow:Step 7200 per-step time 0.623s\n","I1203 07:56:08.919972 133410652246656 model_lib_v2.py:705] Step 7200 per-step time 0.623s\n","INFO:tensorflow:{'Loss/classification_loss': nan,\n"," 'Loss/localization_loss': nan,\n"," 'Loss/regularization_loss': nan,\n"," 'Loss/total_loss': nan,\n"," 'learning_rate': 0.07995074}\n","I1203 07:56:08.920379 133410652246656 model_lib_v2.py:708] {'Loss/classification_loss': nan,\n"," 'Loss/localization_loss': nan,\n"," 'Loss/regularization_loss': nan,\n"," 'Loss/total_loss': nan,\n"," 'learning_rate': 0.07995074}\n","INFO:tensorflow:Step 7300 per-step time 0.622s\n","I1203 07:57:11.103128 133410652246656 model_lib_v2.py:705] Step 7300 per-step time 0.622s\n","INFO:tensorflow:{'Loss/classification_loss': nan,\n"," 'Loss/localization_loss': nan,\n"," 'Loss/regularization_loss': nan,\n"," 'Loss/total_loss': nan,\n"," 'learning_rate': 0.07994863}\n","I1203 07:57:11.103455 133410652246656 model_lib_v2.py:708] {'Loss/classification_loss': nan,\n"," 'Loss/localization_loss': nan,\n"," 'Loss/regularization_loss': nan,\n"," 'Loss/total_loss': nan,\n"," 'learning_rate': 0.07994863}\n","INFO:tensorflow:Step 7400 per-step time 0.619s\n","I1203 07:58:12.992042 133410652246656 model_lib_v2.py:705] Step 7400 per-step time 0.619s\n","INFO:tensorflow:{'Loss/classification_loss': nan,\n"," 'Loss/localization_loss': nan,\n"," 'Loss/regularization_loss': nan,\n"," 'Loss/total_loss': nan,\n"," 'learning_rate': 0.07994646}\n","I1203 07:58:12.992386 133410652246656 model_lib_v2.py:708] {'Loss/classification_loss': nan,\n"," 'Loss/localization_loss': nan,\n"," 'Loss/regularization_loss': nan,\n"," 'Loss/total_loss': nan,\n"," 'learning_rate': 0.07994646}\n","INFO:tensorflow:Step 7500 per-step time 0.616s\n","I1203 07:59:14.539425 133410652246656 model_lib_v2.py:705] Step 7500 per-step time 0.616s\n","INFO:tensorflow:{'Loss/classification_loss': nan,\n"," 'Loss/localization_loss': nan,\n"," 'Loss/regularization_loss': nan,\n"," 'Loss/total_loss': nan,\n"," 'learning_rate': 0.07994425}\n","I1203 07:59:14.539788 133410652246656 model_lib_v2.py:708] {'Loss/classification_loss': nan,\n"," 'Loss/localization_loss': nan,\n"," 'Loss/regularization_loss': nan,\n"," 'Loss/total_loss': nan,\n"," 'learning_rate': 0.07994425}\n","INFO:tensorflow:Step 7600 per-step time 0.620s\n","I1203 08:00:16.544692 133410652246656 model_lib_v2.py:705] Step 7600 per-step time 0.620s\n","INFO:tensorflow:{'Loss/classification_loss': nan,\n"," 'Loss/localization_loss': nan,\n"," 'Loss/regularization_loss': nan,\n"," 'Loss/total_loss': nan,\n"," 'learning_rate': 0.079942}\n","I1203 08:00:16.545024 133410652246656 model_lib_v2.py:708] {'Loss/classification_loss': nan,\n"," 'Loss/localization_loss': nan,\n"," 'Loss/regularization_loss': nan,\n"," 'Loss/total_loss': nan,\n"," 'learning_rate': 0.079942}\n","INFO:tensorflow:Step 7700 per-step time 0.619s\n","I1203 08:01:18.497058 133410652246656 model_lib_v2.py:705] Step 7700 per-step time 0.619s\n","INFO:tensorflow:{'Loss/classification_loss': nan,\n"," 'Loss/localization_loss': nan,\n"," 'Loss/regularization_loss': nan,\n"," 'Loss/total_loss': nan,\n"," 'learning_rate': 0.07993971}\n","I1203 08:01:18.497442 133410652246656 model_lib_v2.py:708] {'Loss/classification_loss': nan,\n"," 'Loss/localization_loss': nan,\n"," 'Loss/regularization_loss': nan,\n"," 'Loss/total_loss': nan,\n"," 'learning_rate': 0.07993971}\n","INFO:tensorflow:Step 7800 per-step time 0.623s\n","I1203 08:02:20.801187 133410652246656 model_lib_v2.py:705] Step 7800 per-step time 0.623s\n","INFO:tensorflow:{'Loss/classification_loss': nan,\n"," 'Loss/localization_loss': nan,\n"," 'Loss/regularization_loss': nan,\n"," 'Loss/total_loss': nan,\n"," 'learning_rate': 0.07993737}\n","I1203 08:02:20.801574 133410652246656 model_lib_v2.py:708] {'Loss/classification_loss': nan,\n"," 'Loss/localization_loss': nan,\n"," 'Loss/regularization_loss': nan,\n"," 'Loss/total_loss': nan,\n"," 'learning_rate': 0.07993737}\n","INFO:tensorflow:Step 7900 per-step time 0.624s\n","I1203 08:03:23.166490 133410652246656 model_lib_v2.py:705] Step 7900 per-step time 0.624s\n","INFO:tensorflow:{'Loss/classification_loss': nan,\n"," 'Loss/localization_loss': nan,\n"," 'Loss/regularization_loss': nan,\n"," 'Loss/total_loss': nan,\n"," 'learning_rate': 0.079934984}\n","I1203 08:03:23.166832 133410652246656 model_lib_v2.py:708] {'Loss/classification_loss': nan,\n"," 'Loss/localization_loss': nan,\n"," 'Loss/regularization_loss': nan,\n"," 'Loss/total_loss': nan,\n"," 'learning_rate': 0.079934984}\n","INFO:tensorflow:Step 8000 per-step time 0.622s\n","I1203 08:04:25.366227 133410652246656 model_lib_v2.py:705] Step 8000 per-step time 0.622s\n","INFO:tensorflow:{'Loss/classification_loss': nan,\n"," 'Loss/localization_loss': nan,\n"," 'Loss/regularization_loss': nan,\n"," 'Loss/total_loss': nan,\n"," 'learning_rate': 0.079932556}\n","I1203 08:04:25.366590 133410652246656 model_lib_v2.py:708] {'Loss/classification_loss': nan,\n"," 'Loss/localization_loss': nan,\n"," 'Loss/regularization_loss': nan,\n"," 'Loss/total_loss': nan,\n"," 'learning_rate': 0.079932556}\n","INFO:tensorflow:Step 8100 per-step time 0.635s\n","I1203 08:05:28.823763 133410652246656 model_lib_v2.py:705] Step 8100 per-step time 0.635s\n","INFO:tensorflow:{'Loss/classification_loss': nan,\n"," 'Loss/localization_loss': nan,\n"," 'Loss/regularization_loss': nan,\n"," 'Loss/total_loss': nan,\n"," 'learning_rate': 0.079930075}\n","I1203 08:05:28.824113 133410652246656 model_lib_v2.py:708] {'Loss/classification_loss': nan,\n"," 'Loss/localization_loss': nan,\n"," 'Loss/regularization_loss': nan,\n"," 'Loss/total_loss': nan,\n"," 'learning_rate': 0.079930075}\n","INFO:tensorflow:Step 8200 per-step time 0.625s\n","I1203 08:06:31.369826 133410652246656 model_lib_v2.py:705] Step 8200 per-step time 0.625s\n","INFO:tensorflow:{'Loss/classification_loss': nan,\n"," 'Loss/localization_loss': nan,\n"," 'Loss/regularization_loss': nan,\n"," 'Loss/total_loss': nan,\n"," 'learning_rate': 0.079927556}\n","I1203 08:06:31.370208 133410652246656 model_lib_v2.py:708] {'Loss/classification_loss': nan,\n"," 'Loss/localization_loss': nan,\n"," 'Loss/regularization_loss': nan,\n"," 'Loss/total_loss': nan,\n"," 'learning_rate': 0.079927556}\n","INFO:tensorflow:Step 8300 per-step time 0.626s\n","I1203 08:07:33.982640 133410652246656 model_lib_v2.py:705] Step 8300 per-step time 0.626s\n","INFO:tensorflow:{'Loss/classification_loss': nan,\n"," 'Loss/localization_loss': nan,\n"," 'Loss/regularization_loss': nan,\n"," 'Loss/total_loss': nan,\n"," 'learning_rate': 0.07992499}\n","I1203 08:07:33.983024 133410652246656 model_lib_v2.py:708] {'Loss/classification_loss': nan,\n"," 'Loss/localization_loss': nan,\n"," 'Loss/regularization_loss': nan,\n"," 'Loss/total_loss': nan,\n"," 'learning_rate': 0.07992499}\n","INFO:tensorflow:Step 8400 per-step time 0.622s\n","I1203 08:08:36.140585 133410652246656 model_lib_v2.py:705] Step 8400 per-step time 0.622s\n","INFO:tensorflow:{'Loss/classification_loss': nan,\n"," 'Loss/localization_loss': nan,\n"," 'Loss/regularization_loss': nan,\n"," 'Loss/total_loss': nan,\n"," 'learning_rate': 0.079922386}\n","I1203 08:08:36.140920 133410652246656 model_lib_v2.py:708] {'Loss/classification_loss': nan,\n"," 'Loss/localization_loss': nan,\n"," 'Loss/regularization_loss': nan,\n"," 'Loss/total_loss': nan,\n"," 'learning_rate': 0.079922386}\n","INFO:tensorflow:Step 8500 per-step time 0.620s\n","I1203 08:09:38.170249 133410652246656 model_lib_v2.py:705] Step 8500 per-step time 0.620s\n","INFO:tensorflow:{'Loss/classification_loss': nan,\n"," 'Loss/localization_loss': nan,\n"," 'Loss/regularization_loss': nan,\n"," 'Loss/total_loss': nan,\n"," 'learning_rate': 0.07991974}\n","I1203 08:09:38.170665 133410652246656 model_lib_v2.py:708] {'Loss/classification_loss': nan,\n"," 'Loss/localization_loss': nan,\n"," 'Loss/regularization_loss': nan,\n"," 'Loss/total_loss': nan,\n"," 'learning_rate': 0.07991974}\n","INFO:tensorflow:Step 8600 per-step time 0.620s\n","I1203 08:10:40.163623 133410652246656 model_lib_v2.py:705] Step 8600 per-step time 0.620s\n","INFO:tensorflow:{'Loss/classification_loss': nan,\n"," 'Loss/localization_loss': nan,\n"," 'Loss/regularization_loss': nan,\n"," 'Loss/total_loss': nan,\n"," 'learning_rate': 0.079917036}\n","I1203 08:10:40.163954 133410652246656 model_lib_v2.py:708] {'Loss/classification_loss': nan,\n"," 'Loss/localization_loss': nan,\n"," 'Loss/regularization_loss': nan,\n"," 'Loss/total_loss': nan,\n"," 'learning_rate': 0.079917036}\n","INFO:tensorflow:Step 8700 per-step time 0.619s\n","I1203 08:11:42.090358 133410652246656 model_lib_v2.py:705] Step 8700 per-step time 0.619s\n","INFO:tensorflow:{'Loss/classification_loss': nan,\n"," 'Loss/localization_loss': nan,\n"," 'Loss/regularization_loss': nan,\n"," 'Loss/total_loss': nan,\n"," 'learning_rate': 0.0799143}\n","I1203 08:11:42.090746 133410652246656 model_lib_v2.py:708] {'Loss/classification_loss': nan,\n"," 'Loss/localization_loss': nan,\n"," 'Loss/regularization_loss': nan,\n"," 'Loss/total_loss': nan,\n"," 'learning_rate': 0.0799143}\n","INFO:tensorflow:Step 8800 per-step time 0.620s\n","I1203 08:12:44.094051 133410652246656 model_lib_v2.py:705] Step 8800 per-step time 0.620s\n","INFO:tensorflow:{'Loss/classification_loss': nan,\n"," 'Loss/localization_loss': nan,\n"," 'Loss/regularization_loss': nan,\n"," 'Loss/total_loss': nan,\n"," 'learning_rate': 0.079911515}\n","I1203 08:12:44.094457 133410652246656 model_lib_v2.py:708] {'Loss/classification_loss': nan,\n"," 'Loss/localization_loss': nan,\n"," 'Loss/regularization_loss': nan,\n"," 'Loss/total_loss': nan,\n"," 'learning_rate': 0.079911515}\n","INFO:tensorflow:Step 8900 per-step time 0.626s\n","I1203 08:13:46.724400 133410652246656 model_lib_v2.py:705] Step 8900 per-step time 0.626s\n","INFO:tensorflow:{'Loss/classification_loss': nan,\n"," 'Loss/localization_loss': nan,\n"," 'Loss/regularization_loss': nan,\n"," 'Loss/total_loss': nan,\n"," 'learning_rate': 0.079908684}\n","I1203 08:13:46.724766 133410652246656 model_lib_v2.py:708] {'Loss/classification_loss': nan,\n"," 'Loss/localization_loss': nan,\n"," 'Loss/regularization_loss': nan,\n"," 'Loss/total_loss': nan,\n"," 'learning_rate': 0.079908684}\n","INFO:tensorflow:Step 9000 per-step time 0.619s\n","I1203 08:14:48.590250 133410652246656 model_lib_v2.py:705] Step 9000 per-step time 0.619s\n","INFO:tensorflow:{'Loss/classification_loss': nan,\n"," 'Loss/localization_loss': nan,\n"," 'Loss/regularization_loss': nan,\n"," 'Loss/total_loss': nan,\n"," 'learning_rate': 0.0799058}\n","I1203 08:14:48.590635 133410652246656 model_lib_v2.py:708] {'Loss/classification_loss': nan,\n"," 'Loss/localization_loss': nan,\n"," 'Loss/regularization_loss': nan,\n"," 'Loss/total_loss': nan,\n"," 'learning_rate': 0.0799058}\n","INFO:tensorflow:Step 9100 per-step time 0.632s\n","I1203 08:15:51.771433 133410652246656 model_lib_v2.py:705] Step 9100 per-step time 0.632s\n","INFO:tensorflow:{'Loss/classification_loss': nan,\n"," 'Loss/localization_loss': nan,\n"," 'Loss/regularization_loss': nan,\n"," 'Loss/total_loss': nan,\n"," 'learning_rate': 0.07990289}\n","I1203 08:15:51.771808 133410652246656 model_lib_v2.py:708] {'Loss/classification_loss': nan,\n"," 'Loss/localization_loss': nan,\n"," 'Loss/regularization_loss': nan,\n"," 'Loss/total_loss': nan,\n"," 'learning_rate': 0.07990289}\n","INFO:tensorflow:Step 9200 per-step time 0.626s\n","I1203 08:16:54.343846 133410652246656 model_lib_v2.py:705] Step 9200 per-step time 0.626s\n","INFO:tensorflow:{'Loss/classification_loss': nan,\n"," 'Loss/localization_loss': nan,\n"," 'Loss/regularization_loss': nan,\n"," 'Loss/total_loss': nan,\n"," 'learning_rate': 0.07989992}\n","I1203 08:16:54.344233 133410652246656 model_lib_v2.py:708] {'Loss/classification_loss': nan,\n"," 'Loss/localization_loss': nan,\n"," 'Loss/regularization_loss': nan,\n"," 'Loss/total_loss': nan,\n"," 'learning_rate': 0.07989992}\n","INFO:tensorflow:Step 9300 per-step time 0.623s\n","I1203 08:17:56.671074 133410652246656 model_lib_v2.py:705] Step 9300 per-step time 0.623s\n","INFO:tensorflow:{'Loss/classification_loss': nan,\n"," 'Loss/localization_loss': nan,\n"," 'Loss/regularization_loss': nan,\n"," 'Loss/total_loss': nan,\n"," 'learning_rate': 0.07989691}\n","I1203 08:17:56.671401 133410652246656 model_lib_v2.py:708] {'Loss/classification_loss': nan,\n"," 'Loss/localization_loss': nan,\n"," 'Loss/regularization_loss': nan,\n"," 'Loss/total_loss': nan,\n"," 'learning_rate': 0.07989691}\n","INFO:tensorflow:Step 9400 per-step time 0.622s\n","I1203 08:18:58.838101 133410652246656 model_lib_v2.py:705] Step 9400 per-step time 0.622s\n","INFO:tensorflow:{'Loss/classification_loss': nan,\n"," 'Loss/localization_loss': nan,\n"," 'Loss/regularization_loss': nan,\n"," 'Loss/total_loss': nan,\n"," 'learning_rate': 0.079893865}\n","I1203 08:18:58.838467 133410652246656 model_lib_v2.py:708] {'Loss/classification_loss': nan,\n"," 'Loss/localization_loss': nan,\n"," 'Loss/regularization_loss': nan,\n"," 'Loss/total_loss': nan,\n"," 'learning_rate': 0.079893865}\n","INFO:tensorflow:Step 9500 per-step time 0.621s\n","I1203 08:20:00.916637 133410652246656 model_lib_v2.py:705] Step 9500 per-step time 0.621s\n","INFO:tensorflow:{'Loss/classification_loss': nan,\n"," 'Loss/localization_loss': nan,\n"," 'Loss/regularization_loss': nan,\n"," 'Loss/total_loss': nan,\n"," 'learning_rate': 0.079890765}\n","I1203 08:20:00.916974 133410652246656 model_lib_v2.py:708] {'Loss/classification_loss': nan,\n"," 'Loss/localization_loss': nan,\n"," 'Loss/regularization_loss': nan,\n"," 'Loss/total_loss': nan,\n"," 'learning_rate': 0.079890765}\n","INFO:tensorflow:Step 9600 per-step time 0.620s\n","I1203 08:21:02.955163 133410652246656 model_lib_v2.py:705] Step 9600 per-step time 0.620s\n","INFO:tensorflow:{'Loss/classification_loss': nan,\n"," 'Loss/localization_loss': nan,\n"," 'Loss/regularization_loss': nan,\n"," 'Loss/total_loss': nan,\n"," 'learning_rate': 0.07988763}\n","I1203 08:21:02.955521 133410652246656 model_lib_v2.py:708] {'Loss/classification_loss': nan,\n"," 'Loss/localization_loss': nan,\n"," 'Loss/regularization_loss': nan,\n"," 'Loss/total_loss': nan,\n"," 'learning_rate': 0.07988763}\n","INFO:tensorflow:Step 9700 per-step time 0.620s\n","I1203 08:22:04.947984 133410652246656 model_lib_v2.py:705] Step 9700 per-step time 0.620s\n","INFO:tensorflow:{'Loss/classification_loss': nan,\n"," 'Loss/localization_loss': nan,\n"," 'Loss/regularization_loss': nan,\n"," 'Loss/total_loss': nan,\n"," 'learning_rate': 0.07988444}\n","I1203 08:22:04.948342 133410652246656 model_lib_v2.py:708] {'Loss/classification_loss': nan,\n"," 'Loss/localization_loss': nan,\n"," 'Loss/regularization_loss': nan,\n"," 'Loss/total_loss': nan,\n"," 'learning_rate': 0.07988444}\n","INFO:tensorflow:Step 9800 per-step time 0.620s\n","I1203 08:23:06.929039 133410652246656 model_lib_v2.py:705] Step 9800 per-step time 0.620s\n","INFO:tensorflow:{'Loss/classification_loss': nan,\n"," 'Loss/localization_loss': nan,\n"," 'Loss/regularization_loss': nan,\n"," 'Loss/total_loss': nan,\n"," 'learning_rate': 0.079881206}\n","I1203 08:23:06.929470 133410652246656 model_lib_v2.py:708] {'Loss/classification_loss': nan,\n"," 'Loss/localization_loss': nan,\n"," 'Loss/regularization_loss': nan,\n"," 'Loss/total_loss': nan,\n"," 'learning_rate': 0.079881206}\n","INFO:tensorflow:Step 9900 per-step time 0.617s\n","I1203 08:24:08.661809 133410652246656 model_lib_v2.py:705] Step 9900 per-step time 0.617s\n","INFO:tensorflow:{'Loss/classification_loss': nan,\n"," 'Loss/localization_loss': nan,\n"," 'Loss/regularization_loss': nan,\n"," 'Loss/total_loss': nan,\n"," 'learning_rate': 0.07987793}\n","I1203 08:24:08.662156 133410652246656 model_lib_v2.py:708] {'Loss/classification_loss': nan,\n"," 'Loss/localization_loss': nan,\n"," 'Loss/regularization_loss': nan,\n"," 'Loss/total_loss': nan,\n"," 'learning_rate': 0.07987793}\n","INFO:tensorflow:Step 10000 per-step time 0.616s\n","I1203 08:25:10.208867 133410652246656 model_lib_v2.py:705] Step 10000 per-step time 0.616s\n","INFO:tensorflow:{'Loss/classification_loss': nan,\n"," 'Loss/localization_loss': nan,\n"," 'Loss/regularization_loss': nan,\n"," 'Loss/total_loss': nan,\n"," 'learning_rate': 0.07987461}\n","I1203 08:25:10.209214 133410652246656 model_lib_v2.py:708] {'Loss/classification_loss': nan,\n"," 'Loss/localization_loss': nan,\n"," 'Loss/regularization_loss': nan,\n"," 'Loss/total_loss': nan,\n"," 'learning_rate': 0.07987461}\n","INFO:tensorflow:Step 10100 per-step time 0.635s\n","I1203 08:26:13.693217 133410652246656 model_lib_v2.py:705] Step 10100 per-step time 0.635s\n","INFO:tensorflow:{'Loss/classification_loss': nan,\n"," 'Loss/localization_loss': nan,\n"," 'Loss/regularization_loss': nan,\n"," 'Loss/total_loss': nan,\n"," 'learning_rate': 0.079871245}\n","I1203 08:26:13.693625 133410652246656 model_lib_v2.py:708] {'Loss/classification_loss': nan,\n"," 'Loss/localization_loss': nan,\n"," 'Loss/regularization_loss': nan,\n"," 'Loss/total_loss': nan,\n"," 'learning_rate': 0.079871245}\n","INFO:tensorflow:Step 10200 per-step time 0.621s\n","I1203 08:27:15.826344 133410652246656 model_lib_v2.py:705] Step 10200 per-step time 0.621s\n","INFO:tensorflow:{'Loss/classification_loss': nan,\n"," 'Loss/localization_loss': nan,\n"," 'Loss/regularization_loss': nan,\n"," 'Loss/total_loss': nan,\n"," 'learning_rate': 0.07986784}\n","I1203 08:27:15.826770 133410652246656 model_lib_v2.py:708] {'Loss/classification_loss': nan,\n"," 'Loss/localization_loss': nan,\n"," 'Loss/regularization_loss': nan,\n"," 'Loss/total_loss': nan,\n"," 'learning_rate': 0.07986784}\n","INFO:tensorflow:Step 10300 per-step time 0.620s\n","I1203 08:28:17.852819 133410652246656 model_lib_v2.py:705] Step 10300 per-step time 0.620s\n","INFO:tensorflow:{'Loss/classification_loss': nan,\n"," 'Loss/localization_loss': nan,\n"," 'Loss/regularization_loss': nan,\n"," 'Loss/total_loss': nan,\n"," 'learning_rate': 0.07986438}\n","I1203 08:28:17.853132 133410652246656 model_lib_v2.py:708] {'Loss/classification_loss': nan,\n"," 'Loss/localization_loss': nan,\n"," 'Loss/regularization_loss': nan,\n"," 'Loss/total_loss': nan,\n"," 'learning_rate': 0.07986438}\n","INFO:tensorflow:Step 10400 per-step time 0.622s\n","I1203 08:29:20.103076 133410652246656 model_lib_v2.py:705] Step 10400 per-step time 0.622s\n","INFO:tensorflow:{'Loss/classification_loss': nan,\n"," 'Loss/localization_loss': nan,\n"," 'Loss/regularization_loss': nan,\n"," 'Loss/total_loss': nan,\n"," 'learning_rate': 0.07986089}\n","I1203 08:29:20.103420 133410652246656 model_lib_v2.py:708] {'Loss/classification_loss': nan,\n"," 'Loss/localization_loss': nan,\n"," 'Loss/regularization_loss': nan,\n"," 'Loss/total_loss': nan,\n"," 'learning_rate': 0.07986089}\n","INFO:tensorflow:Step 10500 per-step time 0.618s\n","I1203 08:30:21.908103 133410652246656 model_lib_v2.py:705] Step 10500 per-step time 0.618s\n","INFO:tensorflow:{'Loss/classification_loss': nan,\n"," 'Loss/localization_loss': nan,\n"," 'Loss/regularization_loss': nan,\n"," 'Loss/total_loss': nan,\n"," 'learning_rate': 0.07985735}\n","I1203 08:30:21.908412 133410652246656 model_lib_v2.py:708] {'Loss/classification_loss': nan,\n"," 'Loss/localization_loss': nan,\n"," 'Loss/regularization_loss': nan,\n"," 'Loss/total_loss': nan,\n"," 'learning_rate': 0.07985735}\n","^C\n"]}],"source":["# 모델 학습 실행\n","!python /content/models/research/object_detection/model_main_tf2.py \\\n","    --pipeline_config_path={pipeline_file} \\\n","    --model_dir={model_dir} \\\n","    --alsologtostderr \\\n","    --num_train_steps={num_steps} \\\n","    --sample_1_of_n_eval_examples=1"]},{"cell_type":"code","source":["pipeline_file"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"2ZzQF5b9f6ZU","executionInfo":{"status":"ok","timestamp":1733214683559,"user_tz":-540,"elapsed":29,"user":{"displayName":"정현우","userId":"03215566591887948765"}},"outputId":"7bb8e3c7-3092-4d5d-bf55-7805412b98b4"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content/models/mymodel/pipeline_file.config'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":18}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":151136,"status":"ok","timestamp":1733214834669,"user":{"displayName":"정현우","userId":"03215566591887948765"},"user_tz":-540},"id":"kkS0EZz5EwtH","outputId":"ef1cb955-614f-4e20-ef97-65156b10e245"},"outputs":[{"output_type":"stream","name":"stdout","text":["Latest checkpoint: /content/drive/MyDrive/CrossMate/model/fine_tuned_models/efficientdet_d1_coco17_tpu-32/training/ckpt-12\n","2024-12-03 08:31:30.932400: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","I1203 08:31:31.019763 139854818497152 ssd_efficientnet_bifpn_feature_extractor.py:161] EfficientDet EfficientNet backbone version: efficientnet-b1\n","I1203 08:31:31.020011 139854818497152 ssd_efficientnet_bifpn_feature_extractor.py:163] EfficientDet BiFPN num filters: 88\n","I1203 08:31:31.020232 139854818497152 ssd_efficientnet_bifpn_feature_extractor.py:164] EfficientDet BiFPN num iterations: 4\n","I1203 08:31:31.030666 139854818497152 efficientnet_model.py:144] round_filter input=32 output=32\n","I1203 08:31:31.108372 139854818497152 efficientnet_model.py:144] round_filter input=32 output=32\n","I1203 08:31:31.116577 139854818497152 efficientnet_model.py:144] round_filter input=16 output=16\n","I1203 08:31:31.621127 139854818497152 efficientnet_model.py:144] round_filter input=16 output=16\n","I1203 08:31:31.621320 139854818497152 efficientnet_model.py:144] round_filter input=24 output=24\n","I1203 08:31:32.339219 139854818497152 efficientnet_model.py:144] round_filter input=24 output=24\n","I1203 08:31:32.339416 139854818497152 efficientnet_model.py:144] round_filter input=40 output=40\n","I1203 08:31:33.098932 139854818497152 efficientnet_model.py:144] round_filter input=40 output=40\n","I1203 08:31:33.100043 139854818497152 efficientnet_model.py:144] round_filter input=80 output=80\n","I1203 08:31:34.037789 139854818497152 efficientnet_model.py:144] round_filter input=80 output=80\n","I1203 08:31:34.037967 139854818497152 efficientnet_model.py:144] round_filter input=112 output=112\n","I1203 08:31:35.403224 139854818497152 efficientnet_model.py:144] round_filter input=112 output=112\n","I1203 08:31:35.403420 139854818497152 efficientnet_model.py:144] round_filter input=192 output=192\n","I1203 08:31:36.204979 139854818497152 efficientnet_model.py:144] round_filter input=192 output=192\n","I1203 08:31:36.205168 139854818497152 efficientnet_model.py:144] round_filter input=320 output=320\n","I1203 08:31:36.538812 139854818497152 efficientnet_model.py:144] round_filter input=1280 output=1280\n","I1203 08:31:36.582311 139854818497152 efficientnet_model.py:454] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.1, resolution=240, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/impl/api.py:458: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with back_prop=False is deprecated and will be removed in a future version.\n","Instructions for updating:\n","back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n","Instead of:\n","results = tf.map_fn(fn, elems, back_prop=False)\n","Use:\n","results = tf.nest.map_structure(tf.stop_gradient, tf.map_fn(fn, elems))\n","W1203 08:31:43.439951 139854818497152 deprecation.py:610] From /usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/impl/api.py:458: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with back_prop=False is deprecated and will be removed in a future version.\n","Instructions for updating:\n","back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n","Instead of:\n","results = tf.map_fn(fn, elems, back_prop=False)\n","Use:\n","results = tf.nest.map_structure(tf.stop_gradient, tf.map_fn(fn, elems))\n","I1203 08:31:51.289701 139854818497152 api.py:441] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\n","I1203 08:32:04.307574 139854818497152 api.py:441] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\n","2024-12-03 08:32:08.198079: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n","I1203 08:32:10.451845 139854818497152 api.py:441] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\n","WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.meta_architectures.ssd_meta_arch.SSDMetaArch object at 0x7f31ec235870>, because it is not built.\n","W1203 08:32:12.992304 139854818497152 save_impl.py:71] Skipping full serialization of Keras layer <object_detection.meta_architectures.ssd_meta_arch.SSDMetaArch object at 0x7f31ec235870>, because it is not built.\n","W1203 08:33:13.663962 139854818497152 save.py:260] Found untraced functions such as WeightSharedConvolutionalBoxPredictor_layer_call_fn, WeightSharedConvolutionalBoxPredictor_layer_call_and_return_conditional_losses, WeightSharedConvolutionalBoxHead_layer_call_fn, WeightSharedConvolutionalBoxHead_layer_call_and_return_conditional_losses, WeightSharedConvolutionalClassHead_layer_call_fn while saving (showing 5 of 374). These functions will not be directly callable after loading.\n","INFO:tensorflow:Assets written to: /content/fine_tuned_model/saved_model/assets\n","I1203 08:33:45.539097 139854818497152 builder_impl.py:779] Assets written to: /content/fine_tuned_model/saved_model/assets\n","INFO:tensorflow:Writing pipeline config file to /content/fine_tuned_model/pipeline.config\n","I1203 08:33:48.294761 139854818497152 config_util.py:253] Writing pipeline config file to /content/fine_tuned_model/pipeline.config\n"]}],"source":["import os\n","import re\n","import numpy as np\n","\n","\n","output_directory = \"/content/fine_tuned_model\"  # 추론 모델 저장 경로\n","\n","# 최신 체크포인트 찾기\n","lst = os.listdir(model_dir)\n","lst = [l for l in lst if 'ckpt-' in l and '.index' in l]  # .index 파일만 필터링\n","steps = np.array([int(re.findall(r'\\d+', l)[0]) for l in lst])  # 체크포인트 번호 추출\n","latest_checkpoint = f\"ckpt-{steps.max()}\"  # 가장 큰 번호의 체크포인트 선택\n","latest_checkpoint_path = os.path.join(model_dir, latest_checkpoint)\n","\n","print(f\"Latest checkpoint: {latest_checkpoint_path}\")\n","\n","# 추론용 모델 저장\n","!python /content/models/research/object_detection/exporter_main_v2.py \\\n","    --input_type=image_tensor \\\n","    --pipeline_config_path={pipeline_file} \\\n","    --trained_checkpoint_dir={model_dir} \\\n","    --output_directory={output_directory}\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tP7VY0VaFnqx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1733214835631,"user_tz":-540,"elapsed":970,"user":{"displayName":"정현우","userId":"03215566591887948765"}},"outputId":"b86326d4-48fa-45e6-f5f5-535d75190198"},"outputs":[{"output_type":"stream","name":"stdout","text":["  adding: content/fine_tuned_model/saved_model/ (stored 0%)\n","  adding: content/fine_tuned_model/saved_model/saved_model.pb (deflated 93%)\n","  adding: content/fine_tuned_model/saved_model/variables/ (stored 0%)\n","  adding: content/fine_tuned_model/saved_model/variables/variables.data-00000-of-00001 (deflated 82%)\n","  adding: content/fine_tuned_model/saved_model/variables/variables.index (deflated 86%)\n","  adding: content/fine_tuned_model/saved_model/assets/ (stored 0%)\n","Folder '/content/fine_tuned_model/saved_model' has been compressed to '/content/saved_model.zip'.\n"]}],"source":["import os\n","\n","# 압축 대상 폴더 경로와 압축 파일 이름 설정\n","folder_to_zip = '/content/fine_tuned_model/saved_model'  # 압축할 폴더 경로\n","output_zip = '/content/saved_model.zip'  # 생성될 ZIP 파일 경로\n","\n","# 폴더를 ZIP으로 압축\n","!zip -r {output_zip} {folder_to_zip}\n","\n","# 압축 완료 메시지 출력\n","print(f\"Folder '{folder_to_zip}' has been compressed to '{output_zip}'.\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"A19aJfz0HHuB","colab":{"base_uri":"https://localhost:8080/","height":17},"executionInfo":{"status":"ok","timestamp":1733214835632,"user_tz":-540,"elapsed":12,"user":{"displayName":"정현우","userId":"03215566591887948765"}},"outputId":"6cd23794-58e4-4502-daeb-ab14ac405201"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_37bd71e5-7a3c-4f5b-b1ee-0757744b8285\", \"saved_model.zip\", 7677299)"]},"metadata":{}}],"source":["\n","from google.colab import files\n","\n","# 생성된 ZIP 파일 다운로드\n","files.download(output_zip)"]},{"cell_type":"markdown","metadata":{"id":"n4-uR1225Q6T"},"source":["# 6.&nbsp;TFLite 모델로 변환"]},{"cell_type":"markdown","metadata":{"id":"9upsDtWLB_Rt"},"source":["## 6-1. 훈련된 모델을 TFLite 모델로 내보내기"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8558,"status":"ok","timestamp":1732985843830,"user":{"displayName":"정현우","userId":"03215566591887948765"},"user_tz":-540},"id":"f9r9s7PS5TOT","outputId":"41887bfb-54bf-4896-e50e-896af800f7ec"},"outputs":[{"name":"stdout","output_type":"stream","text":["2024-11-30 16:57:21.152706: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","I1130 16:57:21.163748 132983481426560 ssd_efficientnet_bifpn_feature_extractor.py:161] EfficientDet EfficientNet backbone version: efficientnet-b0\n","I1130 16:57:21.163929 132983481426560 ssd_efficientnet_bifpn_feature_extractor.py:163] EfficientDet BiFPN num filters: 64\n","I1130 16:57:21.163997 132983481426560 ssd_efficientnet_bifpn_feature_extractor.py:164] EfficientDet BiFPN num iterations: 3\n","I1130 16:57:21.169609 132983481426560 efficientnet_model.py:144] round_filter input=32 output=32\n","I1130 16:57:21.192843 132983481426560 efficientnet_model.py:144] round_filter input=32 output=32\n","I1130 16:57:21.192956 132983481426560 efficientnet_model.py:144] round_filter input=16 output=16\n","I1130 16:57:21.250809 132983481426560 efficientnet_model.py:144] round_filter input=16 output=16\n","I1130 16:57:21.250928 132983481426560 efficientnet_model.py:144] round_filter input=24 output=24\n","I1130 16:57:21.397631 132983481426560 efficientnet_model.py:144] round_filter input=24 output=24\n","I1130 16:57:21.397768 132983481426560 efficientnet_model.py:144] round_filter input=40 output=40\n","I1130 16:57:21.551393 132983481426560 efficientnet_model.py:144] round_filter input=40 output=40\n","I1130 16:57:21.551554 132983481426560 efficientnet_model.py:144] round_filter input=80 output=80\n","I1130 16:57:21.769493 132983481426560 efficientnet_model.py:144] round_filter input=80 output=80\n","I1130 16:57:21.769637 132983481426560 efficientnet_model.py:144] round_filter input=112 output=112\n","I1130 16:57:21.986117 132983481426560 efficientnet_model.py:144] round_filter input=112 output=112\n","I1130 16:57:21.986270 132983481426560 efficientnet_model.py:144] round_filter input=192 output=192\n","I1130 16:57:22.469780 132983481426560 efficientnet_model.py:144] round_filter input=192 output=192\n","I1130 16:57:22.469956 132983481426560 efficientnet_model.py:144] round_filter input=320 output=320\n","I1130 16:57:22.546294 132983481426560 efficientnet_model.py:144] round_filter input=1280 output=1280\n","I1130 16:57:22.578901 132983481426560 efficientnet_model.py:454] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.0, resolution=224, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","Traceback (most recent call last):\n","  File \"/content/models/research/object_detection/export_tflite_graph_tf2.py\", line 160, in <module>\n","    app.run(main)\n","  File \"/usr/local/lib/python3.10/dist-packages/absl/app.py\", line 308, in run\n","    _run_main(main, args)\n","  File \"/usr/local/lib/python3.10/dist-packages/absl/app.py\", line 254, in _run_main\n","    sys.exit(main(argv))\n","  File \"/content/models/research/object_detection/export_tflite_graph_tf2.py\", line 153, in main\n","    export_tflite_graph_lib_tf2.export_tflite_model(\n","  File \"/usr/local/lib/python3.10/dist-packages/object_detection/export_tflite_graph_lib_tf2.py\", line 364, in export_tflite_model\n","    status.assert_existing_objects_matched()\n","  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/training/tracking/util.py\", line 944, in assert_existing_objects_matched\n","    raise AssertionError(\n","AssertionError: No checkpoint specified (save_path=None); nothing is being restored.\n"]}],"source":["# 훈련된 TFLite 모델을 저장할 디렉토리 생성\n","!mkdir /content/custom_model_lite\n","output_directory = '/content/custom_model_lite'\n","\n","# 훈련 디렉토리 경로 설정 (변환 스크립트가 가장 최신 체크포인트 파일을 자동으로 선택)\n","last_model_path = '/content/training'\n","\n","# TFLite 변환 그래프를 생성\n","!python /content/models/research/object_detection/export_tflite_graph_tf2.py \\\n","    --trained_checkpoint_dir {last_model_path} \\\n","    --output_directory {output_directory} \\\n","    --pipeline_config_path {pipeline_file}\n"]},{"cell_type":"markdown","metadata":{"id":"kbBlzaUaCI-z"},"source":["## 6-2. TensorFlow Lite 모델 저장 및 테스트"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":523},"executionInfo":{"elapsed":4,"status":"error","timestamp":1732985843830,"user":{"displayName":"정현우","userId":"03215566591887948765"},"user_tz":-540},"id":"vEA397hI5XGV","outputId":"b4ddb2de-9c73-48ab-9ce7-5d0d34ca6186"},"outputs":[{"ename":"OSError","evalue":"SavedModel file does not exist at: /content/custom_model_lite/saved_model/{saved_model.pbtxt|saved_model.pb}","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)","\u001b[0;32m<ipython-input-34-9b63dd02fdf7>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# 저장된 모델(saved_model) 경로를 지정하여 TFLiteConverter 생성\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mconverter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTFLiteConverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_saved_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/custom_model_lite/saved_model'\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 저장된 모델 로드\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# TFLite 형식으로 모델 변환\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/lite/python/lite.py\u001b[0m in \u001b[0;36mfrom_saved_model\u001b[0;34m(cls, saved_model_dir, signature_keys, tags)\u001b[0m\n\u001b[1;32m   1646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1647\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meager_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1648\u001b[0;31m       \u001b[0msaved_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaved_model_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1649\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignature_keys\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1650\u001b[0m       \u001b[0msignature_keys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msaved_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignatures\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/saved_model/load.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(export_dir, tags, options)\u001b[0m\n\u001b[1;32m    934\u001b[0m     \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIf\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mdon\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0mt\u001b[0m \u001b[0mmatch\u001b[0m \u001b[0ma\u001b[0m \u001b[0mMetaGraph\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mSavedModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m   \"\"\"\n\u001b[0;32m--> 936\u001b[0;31m   \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexport_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"root\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    937\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    938\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/saved_model/load.py\u001b[0m in \u001b[0;36mload_internal\u001b[0;34m(export_dir, tags, options, loader_cls, filters)\u001b[0m\n\u001b[1;32m    947\u001b[0m     \u001b[0mtags\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    948\u001b[0m   saved_model_proto, debug_info = (\n\u001b[0;32m--> 949\u001b[0;31m       loader_impl.parse_saved_model_with_debug_info(export_dir))\n\u001b[0m\u001b[1;32m    950\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m   if (len(saved_model_proto.meta_graphs) == 1 and\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/saved_model/loader_impl.py\u001b[0m in \u001b[0;36mparse_saved_model_with_debug_info\u001b[0;34m(export_dir)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0mparsed\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mMissing\u001b[0m \u001b[0mgraph\u001b[0m \u001b[0mdebug\u001b[0m \u001b[0minfo\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mfine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m   \"\"\"\n\u001b[0;32m---> 57\u001b[0;31m   \u001b[0msaved_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse_saved_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexport_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m   debug_info_path = file_io.join(\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/saved_model/loader_impl.py\u001b[0m in \u001b[0;36mparse_saved_model\u001b[0;34m(export_dir)\u001b[0m\n\u001b[1;32m    113\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Cannot parse file {path_to_pbtxt}: {str(e)}.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m     raise IOError(\n\u001b[0m\u001b[1;32m    116\u001b[0m         \u001b[0;34mf\"SavedModel file does not exist at: {export_dir}{os.path.sep}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;34mf\"{{{constants.SAVED_MODEL_FILENAME_PBTXT}|\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mOSError\u001b[0m: SavedModel file does not exist at: /content/custom_model_lite/saved_model/{saved_model.pbtxt|saved_model.pb}"]}],"source":["# 내보낸 그래프 파일을 TFLite 모델 파일로 변환\n","\n","import tensorflow as tf\n","\n","# 저장된 모델(saved_model) 경로를 지정하여 TFLiteConverter 생성\n","converter = tf.lite.TFLiteConverter.from_saved_model('/content/drive/MyDrive/models/saved_model')  # 저장된 모델 로드\n","\n","# TFLite 형식으로 모델 변환\n","tflite_model = converter.convert()  # TFLite 모델로 변환\n","\n","# 변환된 TFLite 모델을 파일로 저장\n","with open('/content/custom_model_lite/detect.tflite', 'wb') as f:  # TFLite 파일 경로 지정\n","  f.write(tflite_model)  # 변환된 TFLite 모델 데이터를 파일에 작성"]},{"cell_type":"markdown","metadata":{"id":"-rv3dwlh5Y1W"},"source":["# 7.&nbsp;TFLite 모델 테스트 및 평가"]},{"cell_type":"markdown","metadata":{"id":"B4Doj5xOCkwc"},"source":["## 7-1. TFLite 모델을 이용한 객체 탐지 수행"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"r9i1Xdls5YpL"},"outputs":[],"source":["# 사용자 정의 TFLite 모델을 테스트 이미지에서 실행하여 객체를 탐지하는 스크립트\n","# 출처: https://github.com/EdjeElectronics/TensorFlow-Lite-Object-Detection-on-Android-and-Raspberry-Pi/blob/master/TFLite_detection_image.py\n","\n","# 필요한 패키지 임포트\n","import os\n","import cv2  # 이미지 처리 라이브러리\n","import numpy as np\n","import sys\n","import glob  # 파일 경로를 다룰 때 사용\n","import random  # 테스트 이미지를 무작위로 선택\n","import importlib.util\n","from tensorflow.lite.python.interpreter import Interpreter  # TFLite 모델 해석기\n","\n","import matplotlib\n","import matplotlib.pyplot as plt\n","\n","# Jupyter/Colab에서 이미지를 인라인으로 표시\n","%matplotlib inline\n","\n","# TFLite 모델을 사용하여 이미지에서 객체를 탐지하고 결과를 표시하는 함수 정의\n","def tflite_detect_images(modelpath, imgpath, lblpath, min_conf=0.5, num_test_images=10, savepath='/content/results', txt_only=False):\n","    # 테스트 폴더에서 이미지 파일 경로를 모두 가져옴\n","    images = glob.glob(imgpath + '/*.jpg') + glob.glob(imgpath + '/*.JPG') + glob.glob(imgpath + '/*.png') + glob.glob(imgpath + '/*.bmp')\n","\n","    # 라벨 맵 파일 로드\n","    with open(lblpath, 'r') as f:\n","        labels = [line.strip() for line in f.readlines()]  # 각 라인을 클래스 이름으로 저장\n","\n","    # TensorFlow Lite 모델 로드\n","    interpreter = Interpreter(model_path=modelpath)\n","    interpreter.allocate_tensors()  # 모델에서 필요한 텐서를 메모리에 할당\n","\n","    # 모델 입력 및 출력 세부정보 가져오기\n","    input_details = interpreter.get_input_details()\n","    output_details = interpreter.get_output_details()\n","    height = input_details[0]['shape'][1]  # 입력 이미지 높이\n","    width = input_details[0]['shape'][2]   # 입력 이미지 너비\n","\n","    float_input = (input_details[0]['dtype'] == np.float32)  # 입력 데이터 유형이 float인지 확인\n","\n","    input_mean = 127.5  # 이미지 정규화를 위한 평균 값\n","    input_std = 127.5   # 이미지 정규화를 위한 표준 편차 값\n","\n","    # 테스트 이미지 무작위 선택\n","    images_to_test = random.sample(images, num_test_images)\n","\n","    # 각 이미지에 대해 탐지 수행\n","    for image_path in images_to_test:\n","        # 이미지 로드 및 모델 입력 크기로 리사이즈\n","        image = cv2.imread(image_path)  # 이미지를 읽어옴\n","        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # RGB로 변환\n","        imH, imW, _ = image.shape  # 원본 이미지 크기 저장\n","        image_resized = cv2.resize(image_rgb, (width, height))  # 모델 입력 크기로 리사이즈\n","        input_data = np.expand_dims(image_resized, axis=0)  # 배치를 추가하여 [1xHxWx3] 형태로 만듦\n","\n","        # 모델이 float 입력을 기대하면 정규화 수행\n","        if float_input:\n","            input_data = (np.float32(input_data) - input_mean) / input_std\n","\n","        # 모델에 데이터를 입력하고 탐지 수행\n","        interpreter.set_tensor(input_details[0]['index'], input_data)\n","        interpreter.invoke()  # 모델 실행\n","\n","        # 탐지 결과 가져오기\n","        boxes = interpreter.get_tensor(output_details[1]['index'])[0]  # 탐지된 객체의 바운딩 박스 좌표\n","        classes = interpreter.get_tensor(output_details[3]['index'])[0]  # 탐지된 객체의 클래스 인덱스\n","        scores = interpreter.get_tensor(output_details[0]['index'])[0]  # 탐지된 객체의 신뢰도\n","\n","        detections = []  # 탐지 결과 저장\n","\n","        # 탐지 결과를 바탕으로 바운딩 박스를 그리거나 결과를 저장\n","        for i in range(len(scores)):\n","            if ((scores[i] > min_conf) and (scores[i] <= 1.0)):  # 최소 신뢰도 임계값 이상인 경우만 처리\n","                # 바운딩 박스 좌표 계산 (이미지 크기를 고려하여 조정)\n","                ymin = int(max(1, (boxes[i][0] * imH)))\n","                xmin = int(max(1, (boxes[i][1] * imW)))\n","                ymax = int(min(imH, (boxes[i][2] * imH)))\n","                xmax = int(min(imW, (boxes[i][3] * imW)))\n","\n","                cv2.rectangle(image, (xmin, ymin), (xmax, ymax), (10, 255, 0), 2)  # 바운딩 박스 그리기\n","\n","                # 객체 이름과 신뢰도 표시\n","                object_name = labels[int(classes[i])]  # 클래스 이름 가져오기\n","                label = '%s: %d%%' % (object_name, int(scores[i] * 100))  # 예: 'person: 72%'\n","                labelSize, baseLine = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.7, 2)\n","                label_ymin = max(ymin, labelSize[1] + 10)\n","                cv2.rectangle(image, (xmin, label_ymin - labelSize[1] - 10), (xmin + labelSize[0], label_ymin + baseLine - 10), (255, 255, 255), cv2.FILLED)\n","                cv2.putText(image, label, (xmin, label_ymin - 7), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 0), 2)\n","\n","                detections.append([object_name, scores[i], xmin, ymin, xmax, ymax])\n","\n","        # 탐지된 결과를 이미지로 표시하거나 저장\n","        if txt_only == False:  # 이미지 결과를 표시\n","            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","            plt.figure(figsize=(12, 16))\n","            plt.imshow(image)\n","            plt.show()\n","\n","        elif txt_only == True:  # 텍스트 파일로 저장\n","            image_fn = os.path.basename(image_path)\n","            base_fn, ext = os.path.splitext(image_fn)\n","            txt_result_fn = base_fn + '.txt'\n","            txt_savepath = os.path.join(savepath, txt_result_fn)\n","\n","            # 탐지 결과를 텍스트 파일에 작성\n","            with open(txt_savepath, 'w') as f:\n","                for detection in detections:\n","                    f.write('%s %.4f %d %d %d %d\\n' % (detection[0], detection[1], detection[2], detection[3], detection[4], detection[5]))\n","\n","    return"]},{"cell_type":"markdown","metadata":{"id":"9-pehif0O5ai"},"source":["- `PATH_TO_IMAGES` 경로 지정\n","- `images_to_test` 탐지 실행할 이미지 개수 지정"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"HLtqRUPO5iYe"},"outputs":[],"source":["# 사용자 모델 실행을 위한 변수 설정\n","\n","# 테스트 이미지 폴더 경로\n","PATH_TO_IMAGES = '/content/drive/MyDrive/nipa_google/data/images_52'  # 테스트 이미지가 저장된 폴더 경로\n","\n","# TFLite 모델 파일 경로\n","PATH_TO_MODEL = '/content/custom_model_lite/detect.tflite'  # 변환된 TFLite 모델 파일 경로\n","\n","# 라벨 맵 파일 경로\n","PATH_TO_LABELS = '/content/labelmap.txt'  # 클래스 이름이 정의된 labelmap.txt 파일 경로\n","\n","# 최소 신뢰도 임계값 설정\n","min_conf_threshold = 0.3  # 탐지된 객체의 신뢰도가 30% 이상인 경우만 표시\n","# 신뢰도가 낮은 탐지 결과도 확인하려면 값을 낮춰 예: 0.01로 변경 가능\n","\n","# 테스트에 사용할 이미지 수 설정\n","images_to_test = 52  # 탐지를 실행할 이미지 개수\n","\n","# 객체 탐지 함수 실행\n","tflite_detect_images(PATH_TO_MODEL, PATH_TO_IMAGES, PATH_TO_LABELS, min_conf_threshold, images_to_test)\n","# TFLite 모델, 이미지 폴더, 라벨 파일, 신뢰도 임계값, 테스트 이미지 개수를 입력으로 전달"]},{"cell_type":"markdown","metadata":{"id":"BMOUGBZbCos0"},"source":["## 7-2. mAP(mean Average Precision) 계산을 통한 모델 성능 평가"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2276,"status":"ok","timestamp":1732672791915,"user":{"displayName":"코딩 부계정","userId":"17521845357504763889"},"user_tz":-540},"id":"X8BnoBlE5l6B","outputId":"6ec88202-77c3-4bab-feb2-77bede80f653"},"outputs":[{"name":"stderr","output_type":"stream","text":["Cloning into '/content/mAP'...\n","--2024-11-27 01:59:50--  https://raw.githubusercontent.com/EdjeElectronics/TensorFlow-Lite-Object-Detection-on-Android-and-Raspberry-Pi/master/util_scripts/calculate_map_cartucho.py\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 5397 (5.3K) [text/plain]\n","Saving to: ‘calculate_map_cartucho.py’\n","\n","     0K .....                                                 100% 51.6M=0s\n","\n","2024-11-27 01:59:50 (51.6 MB/s) - ‘calculate_map_cartucho.py’ saved [5397/5397]\n","\n"]}],"source":["%%bash\n","# mAP(mAP - mean Average Precision) 계산을 위한 GitHub 저장소 클론\n","git clone https://github.com/Cartucho/mAP /content/mAP\n","# Cartucho의 mAP 프로젝트를 로컬로 복사하여 /content/mAP 디렉토리에 저장\n","\n","# mAP 디렉토리로 이동\n","cd /content/mAP\n","\n","# 기존 탐지 결과(detection-results) 폴더 초기화\n","rm input/detection-results/*\n","\n","# 기존 Ground Truth(정답 데이터) 폴더 초기화\n","rm input/ground-truth/*\n","\n","# 선택적 이미지 폴더 초기화\n","rm input/images-optional/*\n","\n","# mAP 계산에 필요한 유틸리티 스크립트 다운로드\n","wget https://raw.githubusercontent.com/EdjeElectronics/TensorFlow-Lite-Object-Detection-on-Android-and-Raspberry-Pi/master/util_scripts/calculate_map_cartucho.py\n","# EdjeElectronics의 GitHub에서 mAP 계산을 도와주는 Python 스크립트를 다운로드"]},{"cell_type":"markdown","metadata":{"id":"jJfRgkM7UpwC"},"source":["- 아래 코드의 '이미지와 XML 파일 복사' 코드에 `PATH_TO_IMAGES` 경로 지정\n","  - !cp `PATH_TO_IMAGES`* /content/mAP/input/images-optional"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yXxPhQkF5pT5"},"outputs":[],"source":["# 테스트 이미지 및 관련 XML 파일을 mAP 평가 환경으로 복사 및 이동\n","\n","# 이미지와 XML 파일 복사\n","!cp /content/drive/MyDrive/nipa_google/data/images_52/* /content/mAP/input/images-optional\n","# 테스트 이미지와 관련 XML 파일을 mAP의 선택적 이미지 폴더(`images-optional`)로 복사\n","\n","# XML 파일 이동\n","!mv /content/mAP/input/images-optional/*.xml /content/mAP/input/ground-truth/\n","# 복사된 XML 파일을 Ground Truth 데이터 폴더(`ground-truth`)로 이동\n","# Ground Truth 폴더는 실제 라벨 데이터를 저장하는 폴더로, mAP 계산에 사용됨"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":346,"status":"ok","timestamp":1732672799236,"user":{"displayName":"코딩 부계정","userId":"17521845357504763889"},"user_tz":-540},"id":"TEtgYgfs5q7Q","outputId":"36ae3b17-69b0-4abb-9ef8-75016c804433"},"outputs":[{"name":"stdout","output_type":"stream","text":["Conversion completed!\n"]}],"source":["# Ground Truth XML 파일을 텍스트 파일로 변환\n","\n","!python /content/mAP/scripts/extra/convert_gt_xml.py\n","# Pascal VOC 형식의 Ground Truth XML 파일을\n","# mAP 계산 도구에서 사용하는 텍스트 파일 형식으로 변환하는 스크립트를 실행"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3299,"status":"ok","timestamp":1732672804976,"user":{"displayName":"코딩 부계정","userId":"17521845357504763889"},"user_tz":-540},"id":"m9H2Z8LG5s7f","outputId":"f561ef71-ca13-42f5-9f98-ee146ef11ff8"},"outputs":[{"name":"stdout","output_type":"stream","text":["Starting inference on 52 images...\n","Finished inferencing!\n"]}],"source":["# 탐지를 실행하여 결과를 텍스트 파일로 저장하기 위한 변수 설정\n","\n","# 테스트 이미지 폴더 경로\n","PATH_TO_IMAGES = '/content/drive/MyDrive/nipa_google/data/images_52'  # 테스트 이미지가 저장된 폴더 경로\n","\n","# TFLite 모델 파일 경로\n","PATH_TO_MODEL = '/content/custom_model_lite/detect.tflite'  # 변환된 TFLite 모델 파일 경로\n","\n","# 라벨 맵 파일 경로\n","PATH_TO_LABELS = '/content/labelmap.txt'  # 클래스 이름이 정의된 labelmap.txt 파일 경로\n","\n","# 탐지 결과를 저장할 폴더 경로\n","PATH_TO_RESULTS = '/content/mAP/input/detection-results'  # 탐지 결과 텍스트 파일을 저장할 디렉토리\n","\n","# 최소 신뢰도 임계값 설정\n","min_conf_threshold = 0.1  # 탐지된 객체의 신뢰도가 10% 이상인 경우만 저장\n","\n","# 테스트 폴더에 있는 모든 이미지 파일 경로를 가져오기\n","image_list = glob.glob(PATH_TO_IMAGES + '/*.jpg') + glob.glob(PATH_TO_IMAGES + '/*.JPG') + glob.glob(PATH_TO_IMAGES + '/*.png') + glob.glob(PATH_TO_IMAGES + '/*.bmp')\n","images_to_test = min(500, len(image_list))  # 이미지가 500개 이상이면 상한선을 500개로 설정\n","\n","# 탐지 결과만 텍스트 파일로 저장하도록 설정 (이미지 표시하지 않음)\n","txt_only = True\n","\n","# 탐지 함수 실행\n","print('Starting inference on %d images...' % images_to_test)  # 탐지 시작 메시지 출력\n","tflite_detect_images(PATH_TO_MODEL, PATH_TO_IMAGES, PATH_TO_LABELS, min_conf_threshold, images_to_test, PATH_TO_RESULTS, txt_only)\n","# TFLite 모델, 이미지 폴더, 라벨 파일, 신뢰도 임계값, 테스트 이미지 수, 탐지 결과 저장 경로를 입력으로 전달\n","print('Finished inferencing!')  # 탐지 완료 메시지 출력"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3192,"status":"ok","timestamp":1732672810404,"user":{"displayName":"코딩 부계정","userId":"17521845357504763889"},"user_tz":-540},"id":"95DYb3095vI9","outputId":"c1f380c1-8f50-46d8-af79-c552ed4b2fb0"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/mAP\n","Calculating mAP at 0.50 IoU threshold...\n","13.95% = bicycle AP \n","20.29% = kickboard AP \n","24.45% = motorcycle AP \n","mAP = 19.56%\n","Calculating mAP at 0.55 IoU threshold...\n","7.10% = bicycle AP \n","20.29% = kickboard AP \n","22.62% = motorcycle AP \n","mAP = 16.67%\n","Calculating mAP at 0.60 IoU threshold...\n","6.19% = bicycle AP \n","20.29% = kickboard AP \n","20.25% = motorcycle AP \n","mAP = 15.58%\n","Calculating mAP at 0.65 IoU threshold...\n","5.75% = bicycle AP \n","20.29% = kickboard AP \n","16.72% = motorcycle AP \n","mAP = 14.26%\n","Calculating mAP at 0.70 IoU threshold...\n","5.05% = bicycle AP \n","14.93% = kickboard AP \n","14.19% = motorcycle AP \n","mAP = 11.39%\n","Calculating mAP at 0.75 IoU threshold...\n","4.47% = bicycle AP \n","14.11% = kickboard AP \n","8.51% = motorcycle AP \n","mAP = 9.03%\n","Calculating mAP at 0.80 IoU threshold...\n","1.48% = bicycle AP \n","5.58% = kickboard AP \n","3.02% = motorcycle AP \n","mAP = 3.36%\n","Calculating mAP at 0.85 IoU threshold...\n","0.25% = bicycle AP \n","0.95% = kickboard AP \n","1.07% = motorcycle AP \n","mAP = 0.76%\n","Calculating mAP at 0.90 IoU threshold...\n","0.00% = bicycle AP \n","0.95% = kickboard AP \n","0.00% = motorcycle AP \n","mAP = 0.32%\n","Calculating mAP at 0.95 IoU threshold...\n","0.00% = bicycle AP \n","0.00% = kickboard AP \n","0.00% = motorcycle AP \n","mAP = 0.00%\n","\n","***mAP Results***\n","\n","Class\t\tAverage mAP @ 0.5:0.95\n","---------------------------------------\n","bicycle\t\t4.42%\n","kickboard\t\t11.77%\n","motorcycle\t\t11.08%\n","\n","Overall\t\t9.09%\n"]}],"source":["# mAP 계산을 위한 디렉토리 이동\n","%cd /content/mAP\n","\n","# mAP(mean Average Precision) 계산 스크립트 실행\n","!python calculate_map_cartucho.py --labels=/content/labelmap.txt\n","# calculate_map_cartucho.py 스크립트를 실행하여 mAP 계산\n","# --labels 옵션은 라벨 맵 파일(labelmap.txt)의 경로를 지정"]},{"cell_type":"markdown","metadata":{"id":"whhoNjj7525I"},"source":["# 8.&nbsp;TFLite 모델 배포"]},{"cell_type":"markdown","metadata":{"id":"3YWcHALc550E"},"source":["## 8-1. TFLite 모델 및 관련 파일 압축 및 다운로드"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":619,"status":"ok","timestamp":1732985860482,"user":{"displayName":"정현우","userId":"03215566591887948765"},"user_tz":-540},"id":"QBoxpB1E509-","outputId":"00b976eb-fd24-4dd4-97a8-ac0b7acfb507"},"outputs":[{"name":"stdout","output_type":"stream","text":["cp: cannot stat '/content/labelmap.pbtxt': No such file or directory\n","/content\n","  adding: custom_model_lite/ (stored 0%)\n","  adding: custom_model_lite/labelmap.txt (deflated 10%)\n","  adding: custom_model_lite/pipeline_file.config (deflated 66%)\n"]}],"source":["# 라벨 맵 파일과 파이프라인 구성 파일을 TFLite 모델 폴더로 이동한 후 압축하기\n","\n","# 라벨 맵 파일(labelmap.txt)을 TFLite 모델 폴더로 복사\n","!cp /content/labelmap.txt /content/custom_model_lite\n","\n","# 라벨 맵 파일(labelmap.pbtxt)을 TFLite 모델 폴더로 복사\n","!cp /content/labelmap.pbtxt /content/custom_model_lite\n","\n","# 파이프라인 구성 파일(pipeline_file.config)을 TFLite 모델 폴더로 복사\n","!cp /content/models/mymodel/pipeline_file.config /content/custom_model_lite\n","\n","# 현재 디렉토리를 /content로 변경\n","%cd /content\n","\n","# TFLite 모델 폴더(custom_model_lite)를 압축하여 ZIP 파일 생성\n","!zip -r custom_model_lite.zip custom_model_lite\n","# -r 옵션: 폴더 및 하위 파일을 모두 포함하여 압축\n","# 결과 ZIP 파일(custom_model_lite.zip)은 /content 디렉토리에 저장"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"executionInfo":{"elapsed":407,"status":"ok","timestamp":1732985861264,"user":{"displayName":"정현우","userId":"03215566591887948765"},"user_tz":-540},"id":"ly9-GC-w6AFg","outputId":"ebd547d9-5ba2-4154-994c-ca713829e6b7"},"outputs":[{"data":{"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/javascript":["download(\"download_b81cf7a5-6716-4875-adde-6ec341e1681f\", \"custom_model_lite.zip\", 2242)"],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{},"output_type":"display_data"}],"source":["from google.colab import files\n","\n","# 압축된 TFLite 모델 ZIP 파일을 다운로드\n","files.download('/content/custom_model_lite.zip')"]},{"cell_type":"markdown","metadata":{"id":"DhnVKWsqvB3N"},"source":["## 8-2. 모델 정보 확인"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":273,"status":"ok","timestamp":1732679507326,"user":{"displayName":"코딩 부계정","userId":"17521845357504763889"},"user_tz":-540},"id":"x3wftZCuXQg8","outputId":"4d112304-1725-40fd-9eb2-e3f4a8674f28"},"outputs":[{"name":"stdout","output_type":"stream","text":["Input details: [{'name': 'serving_default_input:0', 'index': 0, 'shape': array([  1, 320, 320,   3], dtype=int32), 'shape_signature': array([  1, 320, 320,   3], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n","Output details: [{'name': 'StatefulPartitionedCall:1', 'index': 338, 'shape': array([ 1, 10], dtype=int32), 'shape_signature': array([ 1, 10], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'StatefulPartitionedCall:3', 'index': 336, 'shape': array([ 1, 10,  4], dtype=int32), 'shape_signature': array([ 1, 10,  4], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'StatefulPartitionedCall:0', 'index': 339, 'shape': array([1], dtype=int32), 'shape_signature': array([1], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'StatefulPartitionedCall:2', 'index': 337, 'shape': array([ 1, 10], dtype=int32), 'shape_signature': array([ 1, 10], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n"]}],"source":["import tensorflow as tf\n","\n","# TFLite 모델 로드\n","interpreter = tf.lite.Interpreter(model_path=\"/content/detect.tflite\")\n","interpreter.allocate_tensors()\n","\n","# 입력 정보\n","input_details = interpreter.get_input_details()\n","output_details = interpreter.get_output_details()\n","\n","print(\"Input details:\", input_details)\n","print(\"Output details:\", output_details)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OOUT4SVevikM"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["hSJCDeRPn89q"],"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}