{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1Za5wuNP7mYhuNeELSsrWhqRYShUKulSj","authorship_tag":"ABX9TyP6I0Y58RxBz5eHvELBZiiC"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["# from google.colab import drive\n","# drive.mount('/content/drive')"],"metadata":{"id":"kJvxnK3iAM0J","executionInfo":{"status":"ok","timestamp":1732867216177,"user_tz":-540,"elapsed":422,"user":{"displayName":"ÏµúÏõêÌòÅ","userId":"11700471914794757608"}},"collapsed":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["!pip install ultralytics\n","!pip install \"coremltools>=6.0,<=6.2\" \"protobuf==3.20.3\"\n","!pip install scikit-learn==1.1.2"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"collapsed":true,"id":"liPqPVy9AsXt","executionInfo":{"status":"ok","timestamp":1733275404827,"user_tz":-540,"elapsed":23528,"user":{"displayName":"ÏµúÏõêÌòÅ","userId":"11700471914794757608"}},"outputId":"7ffe0eba-6706-4b5f-a9c6-aae2fd4919c5"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting ultralytics\n","  Downloading ultralytics-8.3.40-py3-none-any.whl.metadata (35 kB)\n","Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.26.4)\n","Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.8.0)\n","Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.10.0.84)\n","Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (11.0.0)\n","Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.2)\n","Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.32.3)\n","Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.13.1)\n","Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.5.1+cu121)\n","Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.20.1+cu121)\n","Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.66.6)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n","Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n","Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.2.2)\n","Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.13.2)\n","Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n","  Downloading ultralytics_thop-2.0.12-py3-none-any.whl.metadata (9.4 kB)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.55.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.7)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.0)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2024.8.30)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.16.1)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2024.10.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n","Downloading ultralytics-8.3.40-py3-none-any.whl (898 kB)\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m898.5/898.5 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading ultralytics_thop-2.0.12-py3-none-any.whl (26 kB)\n","Installing collected packages: ultralytics-thop, ultralytics\n","Successfully installed ultralytics-8.3.40 ultralytics-thop-2.0.12\n","Collecting coremltools<=6.2,>=6.0\n","  Downloading coremltools-6.2-cp310-none-manylinux1_x86_64.whl.metadata (2.4 kB)\n","Collecting protobuf==3.20.3\n","  Downloading protobuf-3.20.3-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (679 bytes)\n","Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.10/dist-packages (from coremltools<=6.2,>=6.0) (1.26.4)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from coremltools<=6.2,>=6.0) (1.13.1)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from coremltools<=6.2,>=6.0) (4.66.6)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from coremltools<=6.2,>=6.0) (24.2)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->coremltools<=6.2,>=6.0) (1.3.0)\n","Downloading protobuf-3.20.3-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading coremltools-6.2-cp310-none-manylinux1_x86_64.whl (1.5 MB)\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m38.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: protobuf, coremltools\n","  Attempting uninstall: protobuf\n","    Found existing installation: protobuf 4.25.5\n","    Uninstalling protobuf-4.25.5:\n","      Successfully uninstalled protobuf-4.25.5\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","grpcio-status 1.62.3 requires protobuf>=4.21.6, but you have protobuf 3.20.3 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed coremltools-6.2 protobuf-3.20.3\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["google"]},"id":"3129286d050441429e714e157bc115ec"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Collecting scikit-learn==1.1.2\n","  Downloading scikit_learn-1.1.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n","Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.1.2) (1.26.4)\n","Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.1.2) (1.13.1)\n","Requirement already satisfied: joblib>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.1.2) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.1.2) (3.5.0)\n","Downloading scikit_learn-1.1.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30.5 MB)\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m30.5/30.5 MB\u001b[0m \u001b[31m48.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: scikit-learn\n","  Attempting uninstall: scikit-learn\n","    Found existing installation: scikit-learn 1.5.2\n","    Uninstalling scikit-learn-1.5.2:\n","      Successfully uninstalled scikit-learn-1.5.2\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","bigframes 1.27.0 requires scikit-learn>=1.2.2, but you have scikit-learn 1.1.2 which is incompatible.\n","mlxtend 0.23.3 requires scikit-learn>=1.3.1, but you have scikit-learn 1.1.2 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed scikit-learn-1.1.2\n"]}]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"L9Zn15ZpAIBd","outputId":"62764bc8-2c69-4be6-ce4e-6f86531c91c5","executionInfo":{"status":"ok","timestamp":1733276619422,"user_tz":-540,"elapsed":1202553,"user":{"displayName":"ÏµúÏõêÌòÅ","userId":"11700471914794757608"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Creating new Ultralytics Settings v0.0.6 file ‚úÖ \n","View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n","Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n","Ultralytics 8.3.40 üöÄ Python-3.10.12 torch-2.5.1+cu121 CPU (Intel Xeon 2.20GHz)\n","WARNING ‚ö†Ô∏è INT8 export requires a missing 'data' arg for calibration. Using default 'data=coco8.yaml'.\n","Model summary (fused): 218 layers, 25,841,497 parameters, 0 gradients, 78.7 GFLOPs\n","\n","\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '/content/yolov8m_final.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 7, 8400) (49.7 MB)\n","\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirements ['sng4onnx>=1.0.1', 'onnx_graphsurgeon>=0.3.26', 'onnx>=1.12.0', 'onnx2tf>1.17.5,<=1.22.3', 'onnxslim>=0.1.31', 'tflite_support', 'onnxruntime'] not found, attempting AutoUpdate...\n","Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n","Collecting sng4onnx>=1.0.1\n","  Downloading sng4onnx-1.0.4-py3-none-any.whl.metadata (4.6 kB)\n","Collecting onnx_graphsurgeon>=0.3.26\n","  Downloading onnx_graphsurgeon-0.5.2-py2.py3-none-any.whl.metadata (8.1 kB)\n","Collecting onnx>=1.12.0\n","  Downloading onnx-1.17.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n","Collecting onnx2tf<=1.22.3,>1.17.5\n","  Downloading onnx2tf-1.22.3-py3-none-any.whl.metadata (136 kB)\n","     ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 136.6/136.6 kB 3.6 MB/s eta 0:00:00\n","Collecting onnxslim>=0.1.31\n","  Downloading onnxslim-0.1.42-py3-none-any.whl.metadata (4.2 kB)\n","Collecting tflite_support\n","  Downloading tflite_support-0.4.4-cp310-cp310-manylinux2014_x86_64.whl.metadata (2.4 kB)\n","Collecting onnxruntime\n","  Downloading onnxruntime-1.20.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from onnx_graphsurgeon>=0.3.26) (1.26.4)\n","Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from onnx>=1.12.0) (3.20.3)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxslim>=0.1.31) (1.13.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from onnxslim>=0.1.31) (24.2)\n","Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tflite_support) (1.4.0)\n","Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tflite_support) (24.3.25)\n","Collecting sounddevice>=0.4.4 (from tflite_support)\n","  Downloading sounddevice-0.5.1-py3-none-any.whl.metadata (1.4 kB)\n","Collecting pybind11>=2.6.0 (from tflite_support)\n","  Downloading pybind11-2.13.6-py3-none-any.whl.metadata (9.5 kB)\n","Collecting coloredlogs (from onnxruntime)\n","  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n","Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.10/dist-packages (from sounddevice>=0.4.4->tflite_support) (1.17.1)\n","Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime)\n","  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxslim>=0.1.31) (1.3.0)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from CFFI>=1.0->sounddevice>=0.4.4->tflite_support) (2.22)\n","Downloading sng4onnx-1.0.4-py3-none-any.whl (5.9 kB)\n","Downloading onnx_graphsurgeon-0.5.2-py2.py3-none-any.whl (56 kB)\n","   ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 56.4/56.4 kB 106.2 MB/s eta 0:00:00\n","Downloading onnx-1.17.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.0 MB)\n","   ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16.0/16.0 MB 119.0 MB/s eta 0:00:00\n","Downloading onnx2tf-1.22.3-py3-none-any.whl (435 kB)\n","   ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 435.0/435.0 kB 272.4 MB/s eta 0:00:00\n","Downloading onnxslim-0.1.42-py3-none-any.whl (142 kB)\n","   ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 142.7/142.7 kB 224.2 MB/s eta 0:00:00\n","Downloading tflite_support-0.4.4-cp310-cp310-manylinux2014_x86_64.whl (60.8 MB)\n","   ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 60.8/60.8 MB 123.8 MB/s eta 0:00:00\n","Downloading onnxruntime-1.20.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (13.3 MB)\n","   ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 13.3/13.3 MB 176.2 MB/s eta 0:00:00\n","Downloading pybind11-2.13.6-py3-none-any.whl (243 kB)\n","   ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 243.3/243.3 kB 123.7 MB/s eta 0:00:00\n","Downloading sounddevice-0.5.1-py3-none-any.whl (32 kB)\n","Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n","   ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 46.0/46.0 kB 119.9 MB/s eta 0:00:00\n","Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n","   ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 86.8/86.8 kB 111.9 MB/s eta 0:00:00\n","Installing collected packages: sng4onnx, pybind11, onnx2tf, onnx, humanfriendly, sounddevice, onnxslim, onnx_graphsurgeon, coloredlogs, tflite_support, onnxruntime\n","Successfully installed coloredlogs-15.0.1 humanfriendly-10.0 onnx-1.17.0 onnx2tf-1.22.3 onnx_graphsurgeon-0.5.2 onnxruntime-1.20.1 onnxslim-0.1.42 pybind11-2.13.6 sng4onnx-1.0.4 sounddevice-0.5.1 tflite_support-0.4.4\n","\n","\u001b[31m\u001b[1mrequirements:\u001b[0m AutoUpdate success ‚úÖ 18.2s, installed 7 packages: ['sng4onnx>=1.0.1', 'onnx_graphsurgeon>=0.3.26', 'onnx>=1.12.0', 'onnx2tf>1.17.5,<=1.22.3', 'onnxslim>=0.1.31', 'tflite_support', 'onnxruntime']\n","\u001b[31m\u001b[1mrequirements:\u001b[0m ‚ö†Ô∏è \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n","\n","\n","\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m starting export with tensorflow 2.17.1...\n","Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/calibration_image_sample_data_20x128x128x3_float32.npy.zip to 'calibration_image_sample_data_20x128x128x3_float32.npy.zip'...\n"]},{"output_type":"stream","name":"stderr","text":["100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1.11M/1.11M [00:00<00:00, 19.8MB/s]\n","Unzipping calibration_image_sample_data_20x128x128x3_float32.npy.zip to /content/calibration_image_sample_data_20x128x128x3_float32.npy...: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 36.57file/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.17.0 opset 19...\n","\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.42...\n","\u001b[34m\u001b[1mONNX:\u001b[0m export success ‚úÖ 6.8s, saved as '/content/yolov8m_final.onnx' (98.9 MB)\n","\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m collecting INT8 calibration images from 'data=coco8.yaml'\n","\n","Dataset 'coco8.yaml' images not found ‚ö†Ô∏è, missing path '/content/datasets/coco8/images/val'\n","Downloading https://ultralytics.com/assets/coco8.zip to '/content/datasets/coco8.zip'...\n"]},{"output_type":"stream","name":"stderr","text":["100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 433k/433k [00:00<00:00, 9.60MB/s]\n","Unzipping /content/datasets/coco8.zip to /content/datasets/coco8...: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:00<00:00, 1543.59file/s]"]},{"output_type":"stream","name":"stdout","text":["Dataset download success ‚úÖ (0.4s), saved to \u001b[1m/content/datasets\u001b[0m\n","\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n"]},{"output_type":"stream","name":"stderr","text":["100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 755k/755k [00:00<00:00, 14.3MB/s]\n","Scanning /content/datasets/coco8/labels/val... 4 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:00<00:00, 76.47it/s]"]},{"output_type":"stream","name":"stdout","text":["New cache created: /content/datasets/coco8/labels/val.cache\n","\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m WARNING ‚ö†Ô∏è >300 images recommended for INT8 calibration, found 4 images.\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m starting TFLite export with onnx2tf 1.22.3...\n","\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m export success ‚úÖ 482.6s, saved as '/content/yolov8m_final_saved_model' (322.6 MB)\n","\n","\u001b[34m\u001b[1mTensorFlow Lite:\u001b[0m starting export with tensorflow 2.17.1...\n","\u001b[34m\u001b[1mTensorFlow Lite:\u001b[0m export success ‚úÖ 0.0s, saved as '/content/yolov8m_final_saved_model/yolov8m_final_int8.tflite' (25.0 MB)\n","\n","Export complete (490.2s)\n","Results saved to \u001b[1m/content\u001b[0m\n","Predict:         yolo predict task=detect model=/content/yolov8m_final_saved_model/yolov8m_final_int8.tflite imgsz=640 int8 \n","Validate:        yolo val task=detect model=/content/yolov8m_final_saved_model/yolov8m_final_int8.tflite imgsz=640 data=fine_tuning.yaml int8 \n","Visualize:       https://netron.app\n","Ultralytics 8.3.40 üöÄ Python-3.10.12 torch-2.5.1+cu121 CPU (Intel Xeon 2.20GHz)\n","WARNING ‚ö†Ô∏è INT8 export requires a missing 'data' arg for calibration. Using default 'data=coco8.yaml'.\n","Model summary (fused): 218 layers, 25,841,497 parameters, 0 gradients, 78.7 GFLOPs\n","\n","\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '/content/yolov8m_final.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 7, 8400) (49.7 MB)\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:coremltools:XGBoost version 2.1.2 has not been tested with coremltools. You may run into unexpected errors. XGBoost 1.4.2 is the most recent version that has been tested.\n","WARNING:coremltools:TensorFlow version 2.17.1 has not been tested with coremltools. You may run into unexpected errors. TensorFlow 2.10.0 is the most recent version that has been tested.\n","WARNING:coremltools:Torch version 2.5.1+cu121 has not been tested with coremltools. You may run into unexpected errors. Torch 1.13.1 is the most recent version that has been tested.\n"]},{"output_type":"stream","name":"stdout","text":["\n","\u001b[34m\u001b[1mCoreML:\u001b[0m starting export with coremltools 6.2...\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:coremltools:Tuple detected at graph output. This will be flattened in the converted model.\n","Converting PyTorch Frontend ==> MIL Ops: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 651/653 [00:00<00:00, 1071.13 ops/s]\n","Running MIL Common passes: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [00:00<00:00, 90.35 passes/s]\n","Running MIL Clean up passes: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 11/11 [00:00<00:00, 41.43 passes/s]\n","Translating MIL ==> NeuralNetwork Ops:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 773/805 [00:03<00:00, 171.55 ops/s]WARNING:coremltools:Const anchor_points was already added.\n","Translating MIL ==> NeuralNetwork Ops: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 805/805 [00:03<00:00, 204.27 ops/s]\n"]},{"output_type":"stream","name":"stdout","text":["Quantizing using kmeans quantization\n","Optimizing Neural Network before Quantization:\n","Finished optimizing network. Quantizing neural network..\n","Quantizing layer input.1 of type convolution\n","Quantizing layer input.5 of type convolution\n","Quantizing layer input.9 of type convolution\n","Quantizing layer input.13 of type convolution\n","Quantizing layer input.17 of type convolution\n","Quantizing layer input.21 of type convolution\n","Quantizing layer input.25 of type convolution\n","Quantizing layer input.29 of type convolution\n","Quantizing layer input.33 of type convolution\n","Quantizing layer input.37 of type convolution\n","Quantizing layer input.41 of type convolution\n","Quantizing layer input.45 of type convolution\n","Quantizing layer input.49 of type convolution\n","Quantizing layer input.53 of type convolution\n","Quantizing layer input.57 of type convolution\n","Quantizing layer input.61 of type convolution\n","Quantizing layer input.65 of type convolution\n","Quantizing layer input.69 of type convolution\n","Quantizing layer input.73 of type convolution\n","Quantizing layer input.77 of type convolution\n","Quantizing layer input.81 of type convolution\n","Quantizing layer input.85 of type convolution\n","Quantizing layer input.89 of type convolution\n","Quantizing layer input.93 of type convolution\n","Quantizing layer input.97 of type convolution\n","Quantizing layer input.101 of type convolution\n","Quantizing layer input.105 of type convolution\n","Quantizing layer input.109 of type convolution\n","Quantizing layer input.113 of type convolution\n","Quantizing layer input.117 of type convolution\n","Quantizing layer input.121 of type convolution\n","Quantizing layer input.125 of type convolution\n","Quantizing layer input.129 of type convolution\n","Quantizing layer input.133 of type convolution\n","Quantizing layer input.137 of type convolution\n","Quantizing layer input.141 of type convolution\n","Quantizing layer input.145 of type convolution\n","Quantizing layer input.149 of type convolution\n","Quantizing layer input.159 of type convolution\n","Quantizing layer input.165 of type convolution\n","Quantizing layer input.169 of type convolution\n","Quantizing layer input.173 of type convolution\n","Quantizing layer input.177 of type convolution\n","Quantizing layer input.181 of type convolution\n","Quantizing layer input.185 of type convolution\n","Quantizing layer input.191 of type convolution\n","Quantizing layer input.195 of type convolution\n","Quantizing layer input.199 of type convolution\n","Quantizing layer input.203 of type convolution\n","Quantizing layer input.207 of type convolution\n","Quantizing layer input.211 of type convolution\n","Quantizing layer input.215 of type convolution\n","Quantizing layer input.219 of type convolution\n","Quantizing layer input.223 of type convolution\n","Quantizing layer input.227 of type convolution\n","Quantizing layer input.231 of type convolution\n","Quantizing layer input.235 of type convolution\n","Quantizing layer input.239 of type convolution\n","Quantizing layer input.243 of type convolution\n","Quantizing layer input.247 of type convolution\n","Quantizing layer input.251 of type convolution\n","Quantizing layer input.255 of type convolution\n","Quantizing layer input.259 of type convolution\n","Quantizing layer input.263 of type convolution\n","Quantizing layer input.267 of type convolution\n","Quantizing layer input.269 of type convolution\n","Quantizing layer input.273 of type convolution\n","Quantizing layer 869 of type convolution\n","Quantizing layer input.277 of type convolution\n","Quantizing layer input.281 of type convolution\n","Quantizing layer 897 of type convolution\n","Quantizing layer input.285 of type convolution\n","Quantizing layer input.289 of type convolution\n","Quantizing layer 927 of type convolution\n","Quantizing layer input.293 of type convolution\n","Quantizing layer input.297 of type convolution\n","Quantizing layer 955 of type convolution\n","Quantizing layer input.303 of type convolution\n","Quantizing layer input.307 of type convolution\n","Quantizing layer 985 of type convolution\n","Quantizing layer input.311 of type convolution\n","Quantizing layer input.315 of type convolution\n","Quantizing layer 1013 of type convolution\n","Quantizing layer 1041 of type convolution\n","\u001b[34m\u001b[1mCoreML Pipeline:\u001b[0m starting pipeline with coremltools 6.2...\n","\u001b[34m\u001b[1mCoreML Pipeline:\u001b[0m pipeline success\n","\u001b[34m\u001b[1mCoreML:\u001b[0m export success ‚úÖ 695.9s, saved as '/content/yolov8m_final.mlmodel' (24.9 MB)\n","\n","Export complete (701.7s)\n","Results saved to \u001b[1m/content\u001b[0m\n","Predict:         yolo predict task=detect model=/content/yolov8m_final.mlmodel imgsz=640 int8 \n","Validate:        yolo val task=detect model=/content/yolov8m_final.mlmodel imgsz=640 data=fine_tuning.yaml int8 \n","Visualize:       https://netron.app\n"]},{"output_type":"execute_result","data":{"text/plain":["'/content/yolov8m_final.mlmodel'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":2}],"source":["from ultralytics import YOLO\n","from ultralytics import RTDETR\n","\n","\n","# Load the model\n","# model = YOLO(\"/content/drive/MyDrive/·ÑÄ·Ö©·Üº·Ñã·Ö≤·Ñá·Ö°·ÜÆ·Ñã·Ö≥·Ü´ ·ÑÜ·ÖÆ·Ü´·Ñâ·Ö•/CrossMate/model/fine_tuned_models/YOLOv8s (Prototype)/yolov8s.pt\")\n","# model = RTDETR(\"/content/drive/MyDrive/·ÑÄ·Ö©·Üº·Ñã·Ö≤·Ñá·Ö°·ÜÆ·Ñã·Ö≥·Ü´ ·ÑÜ·ÖÆ·Ü´·Ñâ·Ö•/CrossMate/model/fine_tuned_models/RT-DETR (Prototype)/rt-detr.pt\")\n","# model = YOLO(\"/content/drive/MyDrive/·ÑÄ·Ö©·Üº·Ñã·Ö≤·Ñá·Ö°·ÜÆ·Ñã·Ö≥·Ü´ ·ÑÜ·ÖÆ·Ü´·Ñâ·Ö•/CrossMate/model/fine_tuned_models/YOLOv8x (Prototype)/300_epoch_imgsz640/yolov8x.pt\")\n","# model = YOLO(\"/content/drive/MyDrive/·ÑÄ·Ö©·Üº·Ñã·Ö≤·Ñá·Ö°·ÜÆ·Ñã·Ö≥·Ü´ ·ÑÜ·ÖÆ·Ü´·Ñâ·Ö•/CrossMate/model/fine_tuned_models/YOLOv11x (Prototype)/300_epoch/yolov11x.pt\")\n","model = YOLO(\"/content/yolov8m_final.pt\")\n","\n","# Export the model to TFLite format\n","model.export(format=\"tflite\", imgsz=640, int8=True)\n","model.export(format=\"mlmodel\", imgsz=[640,640], int8=True, nms=True)"]},{"cell_type":"code","source":["model = YOLO(\"/content/yolov8n_final.pt\")\n","\n","# Export the model to TFLite format\n","model.export(format=\"tflite\", imgsz=640, int8=True)\n","model.export(format=\"mlmodel\", imgsz=[640,640], int8=True, nms=True)"],"metadata":{"id":"onWx6_jYTOV2","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1733276798303,"user_tz":-540,"elapsed":178893,"user":{"displayName":"ÏµúÏõêÌòÅ","userId":"11700471914794757608"}},"outputId":"4fdfddc3-3795-4ae2-ec64-b153e0ec494d"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Ultralytics 8.3.40 üöÄ Python-3.10.12 torch-2.5.1+cu121 CPU (Intel Xeon 2.20GHz)\n","WARNING ‚ö†Ô∏è INT8 export requires a missing 'data' arg for calibration. Using default 'data=coco8.yaml'.\n","Model summary (fused): 168 layers, 3,006,233 parameters, 0 gradients, 8.1 GFLOPs\n","\n","\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '/content/yolov8n_final.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 7, 8400) (6.0 MB)\n","\n","\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m starting export with tensorflow 2.17.1...\n","\n","\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.17.0 opset 19...\n","\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.42...\n","\u001b[34m\u001b[1mONNX:\u001b[0m export success ‚úÖ 7.0s, saved as '/content/yolov8n_final.onnx' (11.8 MB)\n","\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m collecting INT8 calibration images from 'data=coco8.yaml'\n"]},{"output_type":"stream","name":"stderr","text":["Scanning /content/datasets/coco8/labels/val.cache... 4 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m WARNING ‚ö†Ô∏è >300 images recommended for INT8 calibration, found 4 images.\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m starting TFLite export with onnx2tf 1.22.3...\n","\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m export success ‚úÖ 98.2s, saved as '/content/yolov8n_final_saved_model' (39.2 MB)\n","\n","\u001b[34m\u001b[1mTensorFlow Lite:\u001b[0m starting export with tensorflow 2.17.1...\n","\u001b[34m\u001b[1mTensorFlow Lite:\u001b[0m export success ‚úÖ 0.0s, saved as '/content/yolov8n_final_saved_model/yolov8n_final_int8.tflite' (3.1 MB)\n","\n","Export complete (99.4s)\n","Results saved to \u001b[1m/content\u001b[0m\n","Predict:         yolo predict task=detect model=/content/yolov8n_final_saved_model/yolov8n_final_int8.tflite imgsz=640 int8 \n","Validate:        yolo val task=detect model=/content/yolov8n_final_saved_model/yolov8n_final_int8.tflite imgsz=640 data=fine_tuning.yaml int8 \n","Visualize:       https://netron.app\n","Ultralytics 8.3.40 üöÄ Python-3.10.12 torch-2.5.1+cu121 CPU (Intel Xeon 2.20GHz)\n","WARNING ‚ö†Ô∏è INT8 export requires a missing 'data' arg for calibration. Using default 'data=coco8.yaml'.\n","Model summary (fused): 168 layers, 3,006,233 parameters, 0 gradients, 8.1 GFLOPs\n","\n","\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '/content/yolov8n_final.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 7, 8400) (6.0 MB)\n","\n","\u001b[34m\u001b[1mCoreML:\u001b[0m starting export with coremltools 6.2...\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:coremltools:Tuple detected at graph output. This will be flattened in the converted model.\n","Converting PyTorch Frontend ==> MIL Ops: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 523/525 [00:00<00:00, 2740.38 ops/s]\n","Running MIL Common passes: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [00:00<00:00, 140.84 passes/s]\n","Running MIL Clean up passes: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 11/11 [00:00<00:00, 67.21 passes/s]\n","Translating MIL ==> NeuralNetwork Ops:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 502/639 [00:00<00:00, 1194.44 ops/s]WARNING:coremltools:Const anchor_points was already added.\n","Translating MIL ==> NeuralNetwork Ops: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 639/639 [00:00<00:00, 1287.73 ops/s]\n"]},{"output_type":"stream","name":"stdout","text":["Quantizing using kmeans quantization\n","Optimizing Neural Network before Quantization:\n","Finished optimizing network. Quantizing neural network..\n","Quantizing layer input.1 of type convolution\n","Quantizing layer input.5 of type convolution\n","Quantizing layer input.9 of type convolution\n","Quantizing layer input.13 of type convolution\n","Quantizing layer input.17 of type convolution\n","Quantizing layer input.21 of type convolution\n","Quantizing layer input.25 of type convolution\n","Quantizing layer input.29 of type convolution\n","Quantizing layer input.33 of type convolution\n","Quantizing layer input.37 of type convolution\n","Quantizing layer input.41 of type convolution\n","Quantizing layer input.45 of type convolution\n","Quantizing layer input.49 of type convolution\n","Quantizing layer input.53 of type convolution\n","Quantizing layer input.57 of type convolution\n","Quantizing layer input.61 of type convolution\n","Quantizing layer input.65 of type convolution\n","Quantizing layer input.69 of type convolution\n","Quantizing layer input.73 of type convolution\n","Quantizing layer input.77 of type convolution\n","Quantizing layer input.81 of type convolution\n","Quantizing layer input.85 of type convolution\n","Quantizing layer input.89 of type convolution\n","Quantizing layer input.93 of type convolution\n","Quantizing layer input.97 of type convolution\n","Quantizing layer input.101 of type convolution\n","Quantizing layer input.111 of type convolution\n","Quantizing layer input.117 of type convolution\n","Quantizing layer input.121 of type convolution\n","Quantizing layer input.125 of type convolution\n","Quantizing layer input.129 of type convolution\n","Quantizing layer input.135 of type convolution\n","Quantizing layer input.139 of type convolution\n","Quantizing layer input.143 of type convolution\n","Quantizing layer input.147 of type convolution\n","Quantizing layer input.151 of type convolution\n","Quantizing layer input.155 of type convolution\n","Quantizing layer input.159 of type convolution\n","Quantizing layer input.163 of type convolution\n","Quantizing layer input.167 of type convolution\n","Quantizing layer input.171 of type convolution\n","Quantizing layer input.175 of type convolution\n","Quantizing layer input.179 of type convolution\n","Quantizing layer input.183 of type convolution\n","Quantizing layer input.187 of type convolution\n","Quantizing layer input.189 of type convolution\n","Quantizing layer input.193 of type convolution\n","Quantizing layer 641 of type convolution\n","Quantizing layer input.197 of type convolution\n","Quantizing layer input.201 of type convolution\n","Quantizing layer 669 of type convolution\n","Quantizing layer input.205 of type convolution\n","Quantizing layer input.209 of type convolution\n","Quantizing layer 699 of type convolution\n","Quantizing layer input.213 of type convolution\n","Quantizing layer input.217 of type convolution\n","Quantizing layer 727 of type convolution\n","Quantizing layer input.223 of type convolution\n","Quantizing layer input.227 of type convolution\n","Quantizing layer 757 of type convolution\n","Quantizing layer input.231 of type convolution\n","Quantizing layer input.235 of type convolution\n","Quantizing layer 785 of type convolution\n","Quantizing layer 813 of type convolution\n","\u001b[34m\u001b[1mCoreML Pipeline:\u001b[0m starting pipeline with coremltools 6.2...\n","\u001b[34m\u001b[1mCoreML Pipeline:\u001b[0m pipeline success\n","\u001b[34m\u001b[1mCoreML:\u001b[0m export success ‚úÖ 78.5s, saved as '/content/yolov8n_final.mlmodel' (3.1 MB)\n","\n","Export complete (79.3s)\n","Results saved to \u001b[1m/content\u001b[0m\n","Predict:         yolo predict task=detect model=/content/yolov8n_final.mlmodel imgsz=640 int8 \n","Validate:        yolo val task=detect model=/content/yolov8n_final.mlmodel imgsz=640 data=fine_tuning.yaml int8 \n","Visualize:       https://netron.app\n"]},{"output_type":"execute_result","data":{"text/plain":["'/content/yolov8n_final.mlmodel'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":["model = YOLO(\"/content/yolov8s_final.pt\")\n","\n","# Export the model to TFLite format\n","model.export(format=\"tflite\", imgsz=640, int8=True)\n","model.export(format=\"mlmodel\", imgsz=[640,640], int8=True, nms=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"7nAnv7FnQ89t","executionInfo":{"status":"ok","timestamp":1733277320579,"user_tz":-540,"elapsed":522301,"user":{"displayName":"ÏµúÏõêÌòÅ","userId":"11700471914794757608"}},"outputId":"d23de4b0-56d6-42a1-cd3f-cc41fd3133a4"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Ultralytics 8.3.40 üöÄ Python-3.10.12 torch-2.5.1+cu121 CPU (Intel Xeon 2.20GHz)\n","WARNING ‚ö†Ô∏è INT8 export requires a missing 'data' arg for calibration. Using default 'data=coco8.yaml'.\n","Model summary (fused): 168 layers, 11,126,745 parameters, 0 gradients, 28.4 GFLOPs\n","\n","\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '/content/yolov8s_final.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 7, 8400) (21.5 MB)\n","\n","\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m starting export with tensorflow 2.17.1...\n","\n","\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.17.0 opset 19...\n","\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.42...\n","\u001b[34m\u001b[1mONNX:\u001b[0m export success ‚úÖ 4.3s, saved as '/content/yolov8s_final.onnx' (42.8 MB)\n","\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m collecting INT8 calibration images from 'data=coco8.yaml'\n"]},{"output_type":"stream","name":"stderr","text":["Scanning /content/datasets/coco8/labels/val.cache... 4 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m WARNING ‚ö†Ô∏è >300 images recommended for INT8 calibration, found 4 images.\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m starting TFLite export with onnx2tf 1.22.3...\n","\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m export success ‚úÖ 225.6s, saved as '/content/yolov8s_final_saved_model' (139.9 MB)\n","\n","\u001b[34m\u001b[1mTensorFlow Lite:\u001b[0m starting export with tensorflow 2.17.1...\n","\u001b[34m\u001b[1mTensorFlow Lite:\u001b[0m export success ‚úÖ 0.0s, saved as '/content/yolov8s_final_saved_model/yolov8s_final_int8.tflite' (10.9 MB)\n","\n","Export complete (228.6s)\n","Results saved to \u001b[1m/content\u001b[0m\n","Predict:         yolo predict task=detect model=/content/yolov8s_final_saved_model/yolov8s_final_int8.tflite imgsz=640 int8 \n","Validate:        yolo val task=detect model=/content/yolov8s_final_saved_model/yolov8s_final_int8.tflite imgsz=640 data=fine_tuning.yaml int8 \n","Visualize:       https://netron.app\n","Ultralytics 8.3.40 üöÄ Python-3.10.12 torch-2.5.1+cu121 CPU (Intel Xeon 2.20GHz)\n","WARNING ‚ö†Ô∏è INT8 export requires a missing 'data' arg for calibration. Using default 'data=coco8.yaml'.\n","Model summary (fused): 168 layers, 11,126,745 parameters, 0 gradients, 28.4 GFLOPs\n","\n","\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '/content/yolov8s_final.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 7, 8400) (21.5 MB)\n","\n","\u001b[34m\u001b[1mCoreML:\u001b[0m starting export with coremltools 6.2...\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:coremltools:Tuple detected at graph output. This will be flattened in the converted model.\n","Converting PyTorch Frontend ==> MIL Ops: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 524/526 [00:00<00:00, 2426.32 ops/s]\n","Running MIL Common passes: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [00:00<00:00, 112.61 passes/s]\n","Running MIL Clean up passes: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 11/11 [00:00<00:00, 40.19 passes/s]\n","Translating MIL ==> NeuralNetwork Ops:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 603/639 [00:01<00:00, 297.28 ops/s]WARNING:coremltools:Const anchor_points was already added.\n","Translating MIL ==> NeuralNetwork Ops: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 639/639 [00:01<00:00, 356.78 ops/s]\n"]},{"output_type":"stream","name":"stdout","text":["Quantizing using kmeans quantization\n","Optimizing Neural Network before Quantization:\n","Finished optimizing network. Quantizing neural network..\n","Quantizing layer input.1 of type convolution\n","Quantizing layer input.5 of type convolution\n","Quantizing layer input.9 of type convolution\n","Quantizing layer input.13 of type convolution\n","Quantizing layer input.17 of type convolution\n","Quantizing layer input.21 of type convolution\n","Quantizing layer input.25 of type convolution\n","Quantizing layer input.29 of type convolution\n","Quantizing layer input.33 of type convolution\n","Quantizing layer input.37 of type convolution\n","Quantizing layer input.41 of type convolution\n","Quantizing layer input.45 of type convolution\n","Quantizing layer input.49 of type convolution\n","Quantizing layer input.53 of type convolution\n","Quantizing layer input.57 of type convolution\n","Quantizing layer input.61 of type convolution\n","Quantizing layer input.65 of type convolution\n","Quantizing layer input.69 of type convolution\n","Quantizing layer input.73 of type convolution\n","Quantizing layer input.77 of type convolution\n","Quantizing layer input.81 of type convolution\n","Quantizing layer input.85 of type convolution\n","Quantizing layer input.89 of type convolution\n","Quantizing layer input.93 of type convolution\n","Quantizing layer input.97 of type convolution\n","Quantizing layer input.101 of type convolution\n","Quantizing layer input.111 of type convolution\n","Quantizing layer input.117 of type convolution\n","Quantizing layer input.121 of type convolution\n","Quantizing layer input.125 of type convolution\n","Quantizing layer input.129 of type convolution\n","Quantizing layer input.135 of type convolution\n","Quantizing layer input.139 of type convolution\n","Quantizing layer input.143 of type convolution\n","Quantizing layer input.147 of type convolution\n","Quantizing layer input.151 of type convolution\n","Quantizing layer input.155 of type convolution\n","Quantizing layer input.159 of type convolution\n","Quantizing layer input.163 of type convolution\n","Quantizing layer input.167 of type convolution\n","Quantizing layer input.171 of type convolution\n","Quantizing layer input.175 of type convolution\n","Quantizing layer input.179 of type convolution\n","Quantizing layer input.183 of type convolution\n","Quantizing layer input.187 of type convolution\n","Quantizing layer input.189 of type convolution\n","Quantizing layer input.193 of type convolution\n","Quantizing layer 642 of type convolution\n","Quantizing layer input.197 of type convolution\n","Quantizing layer input.201 of type convolution\n","Quantizing layer 670 of type convolution\n","Quantizing layer input.205 of type convolution\n","Quantizing layer input.209 of type convolution\n","Quantizing layer 700 of type convolution\n","Quantizing layer input.213 of type convolution\n","Quantizing layer input.217 of type convolution\n","Quantizing layer 728 of type convolution\n","Quantizing layer input.223 of type convolution\n","Quantizing layer input.227 of type convolution\n","Quantizing layer 758 of type convolution\n","Quantizing layer input.231 of type convolution\n","Quantizing layer input.235 of type convolution\n","Quantizing layer 786 of type convolution\n","Quantizing layer 814 of type convolution\n","\u001b[34m\u001b[1mCoreML Pipeline:\u001b[0m starting pipeline with coremltools 6.2...\n","\u001b[34m\u001b[1mCoreML Pipeline:\u001b[0m pipeline success\n","\u001b[34m\u001b[1mCoreML:\u001b[0m export success ‚úÖ 291.1s, saved as '/content/yolov8s_final.mlmodel' (10.8 MB)\n","\n","Export complete (293.5s)\n","Results saved to \u001b[1m/content\u001b[0m\n","Predict:         yolo predict task=detect model=/content/yolov8s_final.mlmodel imgsz=640 int8 \n","Validate:        yolo val task=detect model=/content/yolov8s_final.mlmodel imgsz=640 data=fine_tuning.yaml int8 \n","Visualize:       https://netron.app\n"]},{"output_type":"execute_result","data":{"text/plain":["'/content/yolov8s_final.mlmodel'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":[],"metadata":{"id":"NROySMZWQ_vO"},"execution_count":null,"outputs":[]}]}